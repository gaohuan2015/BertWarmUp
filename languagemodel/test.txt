{0: 'investigation', 1: 'Monday,', 2: 'line.', 3: 'remove', 4: '0.6', 5: 'I', 6: 'Gamma', 7: 'Regional', 8: 'every', 9: 'Saeima', 10: 'sustainability', 11: 'curb', 12: 'raw', 13: 'Chancellery', 14: '"it', 15: '"One', 16: 'plane', 17: 'philosopher.', 18: 'passed', 19: 'respectable', 20: 'San', 21: '25.', 22: 'customs', 23: 'both', 24: '4,000.', 25: 'economics', 26: 'that,', 27: 'Fijalek/Prudel', 28: 'informed,', 29: 'basis,', 30: 'period', 31: 'compared', 32: 'go', 33: 'Commission', 34: 'downward', 35: 'Institute', 36: 'Baltstor,', 37: 'Latenaite', 38: 'with', 39: 'and', 40: 'and...', 41: 'value', 42: 'turned', 43: 'Transcontainer', 44: 'Phytosanitary', 45: 'favorable', 46: 'Mezeckis', 47: 'ambassador,', 48: 'partner', 49: 'fuel', 50: 'aim', 51: 'provide', 52: 'milk', 53: 'illegal', 54: 'regional', 55: 'downed', 56: 'regions,', 57: 'run', 58: 'aims', 59: 'inspect', 60: 'forces,', 61: 'content', 62: 'Transport', 63: 'used', 64: 'cooperation".', 65: 'Ministry.', 66: 'August', 67: 'diplomatic', 68: 'illegitimate', 69: 'Alliance),', 70: 'solutions', 71: 'Nations,', 72: 'process.', 73: 'remain,', 74: 'Sergio', 75: 'portfolio', 76: 'construction,', 77: 'percent,', 78: 'Eurimages,', 79: '0.1', 80: 'not,', 81: 'stressed', 82: '1,709', 83: 'grow', 84: 'U.S.-led', 85: 'deployment,', 86: 'affirm', 87: 'reduction', 88: '2017.', 89: 'interests', 90: 'Milwaukee', 91: 'in.', 92: 'prostitutes', 93: 'First', 94: 'invitation', 95: 'legislative', 96: 'China', 97: 'Festival,', 98: 'partially', 99: 'planning,', 100: 'borders,', 101: 'industry,', 102: 'featuring', 103: 'change', 104: 'lost', 105: 'weeks', 106: 'Mattarella,', 107: 'percent', 108: 'Rothschild', 109: 'A', 110: 'processes', 111: '1.7', 112: 'authorize', 113: 'annexation', 114: 'Grande,', 115: 'Rail,', 116: "EU's", 117: 'Dzelzcela', 118: 'goals.', 119: 'reading', 120: 'observers', 121: 'collapsed', 122: 'Little', 123: 'That', 124: 'Inga', 125: 'contracts,', 126: 'ambassador', 127: 'electrified', 128: 'standard', 129: 'day', 130: 'including', 131: 'Locomotive', 132: 'could', 133: 'launched', 134: 'half', 135: 'result', 136: 'coming', 137: 'Rosselkhoznadzor', 138: 'transportation', 139: 'co-owners', 140: 'registered', 141: 'Henins', 142: 'first', 143: 'just', 144: '14', 145: 'Of', 146: '20', 147: 'had', 148: 'release', 149: 'Juncker', 150: 'employ', 151: 'Control', 152: 'movement', 153: 'dead', 154: 'provider', 155: 'results', 156: 'Silicon', 157: 'Dutch', 158: 'discuss', 159: "''However,", 160: 'security,', 161: 'lot', 162: 'Mariusz', 163: 'gap', 164: 'telecommunications', 165: 'Citizens', 166: 'feel', 167: 'corridor', 168: 'time', 169: 'lifestyle', 170: 'shows', 171: '5', 172: 'Latvia,', 173: 'circumstances.', 174: 'immigrant,', 175: 'properties', 176: 'grabbed', 177: 'adjust', 178: 'view', 179: 'out.', 180: 'say.', 181: 'post', 182: 'Kaunas,', 183: 'which', 184: 'Luxembourg', 185: 'short', 186: 'project,', 187: 'premiere', 188: 'Friday,', 189: 'salary', 190: 'means', 191: 'Smiltena', 192: 'Since', 193: 'longer', 194: "today's", 195: 'hour.', 196: 'Six', 197: 'salaries,', 198: 'negotiations', 199: 'interested', 200: 'providing', 201: 'London', 202: 'pushed', 203: 'elections', 204: '34', 205: 'impoverished', 206: 'Vilnius', 207: '(0:0,', 208: 'expropriation', 209: 'nature', 210: 'workers', 211: 'Education', 212: '72.8', 213: 'rose', 214: 'necessity', 215: 'whether', 216: '(OPEC)', 217: 'do,', 218: 'purchases', 219: 'shafts', 220: 'Ivars', 221: 'immediately', 222: 'SkenarioLabs', 223: 'van', 224: 'adding', 225: 'October', 226: 'inspections.', 227: 'Officials', 228: 'heat-up', 229: 'meeting,', 230: 'candidacy', 231: 'positions', 232: 'OPEC?', 233: 'support', 234: 'respective', 235: 'reminds', 236: 'LUXEMBOURG,', 237: 'detail', 238: 'unanimity.', 239: 'then', 240: 'asked', 241: 'borders', 242: 'Goldman', 243: 'Irving', 244: 'level', 245: '(Want', 246: 'Commerce', 247: 'million', 248: 'increased', 249: 'confirmed', 250: 'officer.', 251: 'Uldis', 252: 'Cavs', 253: 'Baltic', 254: 'allowed', 255: 'Surveillance', 256: '(Rosselkhoznadzor)', 257: 'sooner', 258: 'Raimonds', 259: 'Donald', 260: 'building', 261: 'registering', 262: 'enterprises', 263: 'economy,', 264: 'effort', 265: 'Praag', 266: 'States', 267: 'fully', 268: "Trump's", 269: 'way', 270: 'Rimsevics', 271: 'opened', 272: 'confident', 273: 'TORONTO,', 274: '"There', 275: 'black', 276: 'volleyball', 277: 'northerly', 278: 'and,', 279: 'beach', 280: 'Steven', 281: 'Nov', 282: 'Service,', 283: 'Sea', 284: 'You', 285: 'structural', 286: 'festival', 287: 'framework', 288: 'jobs,', 289: "Service's", 290: 'Jean-Claude', 291: 'Environment,', 292: 'euro,', 293: 'night,', 294: 'From', 295: 'around', 296: 'deals', 297: 'budget', 298: '"If', 299: 'take', 300: 'circumstances', 301: 'Equity', 302: 'owner', 303: 'Amaq', 304: 'tear', 305: 'childhood', 306: 'Karavela,', 307: 'who', 308: 'remuneration', 309: 'affected', 310: 'consumer', 311: 'Out', 312: 'President-elect', 313: 'rain', 314: 'envisages', 315: 'intermodal', 316: 'fighter', 317: 'caused', 318: 'let', 319: 'interview.', 320: 'matters,', 321: 'halt', 322: 'Meeuwsen,', 323: 'exchange', 324: "Jong-Un's", 325: 'revived,', 326: 'voted', 327: 'led', 328: 'firm', 329: 'worry', 330: 'Foreign', 331: 'Science', 332: 'is', 333: 'economic', 334: 'highly', 335: 'struggling', 336: 'unprecedented', 337: 'allow', 338: 'diaspora', 339: 'painful', 340: 'positive', 341: '3:1', 342: 'expropriated', 343: 'an', 344: 'three', 345: 'growing', 346: 'production,', 347: 'transition', 348: 'Swedish', 349: 'top', 350: 'expanding', 351: 'IKEA', 352: 'League', 353: 'discussed,', 354: 'warships', 355: 'film,', 356: '2007),', 357: 'common', 358: 'on', 359: 'developing', 360: 'completed', 361: 'Stanevics,', 362: 'development.', 363: 'format', 364: 'letters', 365: 'reforms,', 366: 'MPs', 367: 'tomorrow,', 368: 'Brice.', 369: 'Food', 370: '9,000.', 371: 'region.', 372: 'organization', 373: 'bring', 374: 'believing', 375: "state's", 376: 'Kenins', 377: 'assists', 378: 'coalition', 379: 'planes', 380: 'up', 381: 'marks', 382: 'bureaucrats,', 383: "festival's", 384: 'EU', 385: 'good', 386: 'territorial', 387: 'am', 388: 'quite', 389: 'Riga,', 390: 'media', 391: 'transponders', 392: 'July', 393: 'No', 394: 'Murniece', 395: 'tax', 396: '28.5', 397: 'decided', 398: 'Temps', 399: 'Solidarity', 400: 'optimal,', 401: 'conducted', 402: 'reacting', 403: 'areas', 404: 'moving', 405: 'startup', 406: 'proposal', 407: 'company.', 408: 'world.', 409: 'ambitions', 410: 'Russian', 411: 'transportation.', 412: 'less', 413: 'stricter', 414: 'referendum', 415: 'agreed', 416: '2016', 417: 'Valley', 418: 'brands.', 419: '(AFP)', 420: '200', 421: 'were', 422: 'once', 423: 'our', 424: 'salaries', 425: 'Everything', 426: 'delves', 427: 'memories.', 428: 'skill', 429: 'representative', 430: 'foundations', 431: 'winner', 432: 'universities,', 433: 'agrees', 434: 'north', 435: 'brothels,', 436: 'lost.', 437: 'extend', 438: '4.2', 439: 'Economic,', 440: 'helps', 441: '"in', 442: 'qualify', 443: 'residents', 444: '885.', 445: 'Surname', 446: 'temps', 447: 'certified', 448: 'performance.', 449: '168.803', 450: 'periods,"', 451: 'preschools.', 452: 'to', 453: 'level.', 454: '24', 455: 'football', 456: 'community', 457: 'stipulated', 458: 'Edgars', 459: 'upcoming', 460: 'communications', 461: 'drive', 462: 'organized', 463: '0.03', 464: 'give', 465: 'illegally', 466: 'draft', 467: 'Ilze', 468: 'at', 469: 'success', 470: '10,979', 471: 'Janis', 472: 'Samoilovs', 473: 'military', 474: 'authorities,', 475: 'price', 476: '1,', 477: 'business', 478: 'active', 479: 'Finland', 480: 'decisions', 481: 'Andris', 482: 'communique', 483: 'rivals.', 484: 'went', 485: 'turning', 486: 'appointment.', 487: 'amounted', 488: 'over', 489: 'Antetokounmpo,', 490: 'industrial', 491: 'world,', 492: 'sustainable', 493: 'year-round', 494: 'shortages:', 495: 'probe', 496: 'ATHENS,', 497: 'Group', 498: 'Hague,', 499: 'planning', 500: 'U.S.', 501: 'talks', 502: '1.2', 503: 'prospective', 504: 'clean', 505: '2-1', 506: 'ready,', 507: 'domestic', 508: 'Association', 509: 'August,', 510: 'solution', 511: 'material', 512: 'River', 513: 'proportional,', 514: '2012,', 515: 'states', 516: '0.4', 517: 'development', 518: "Eurostat's", 519: 'approach,', 520: '$700', 521: 'Security', 522: 'Driksna,', 523: 'carried', 524: 'complete', 525: 'beginning', 526: 'Revenue', 527: 'Iraqi', 528: 'food', 529: 'opening', 530: 'Lewis,', 531: 'university', 532: 'Cleveland', 533: 'Rosberg', 534: 'economy', 535: 'voluntary', 536: 'wished', 537: 'adding:', 538: '0.3', 539: 'Ilmars', 540: 'inflation', 541: "he's", 542: "Netherlands'", 543: 'needy', 544: 'lack', 545: 'Ambassador', 546: 'reviewed', 547: 'worth', 548: 'provides', 549: 'rail', 550: 'neutral', 551: 'wages', 552: 'Canada', 553: '4,030,', 554: 'depended', 555: 'today.', 556: 'review', 557: 'fight', 558: '13', 559: 'Both', 560: '0:2,', 561: 'According', 562: 'individual', 563: 'congratulated', 564: 'opportunities', 565: 'rights.', 566: 'morning.', 567: 'World', 568: 'further', 569: 'tackling', 570: 'consumers', 571: '21,', 572: 'process', 573: 'national', 574: "countries'", 575: 'someone', 576: 'UEFA', 577: 'closer', 578: '1.', 579: 'increasing', 580: 'governments', 581: '15', 582: 'transport', 583: "Latvia's", 584: 'regard', 585: 'his', 586: 'deflation,', 587: 'retailers', 588: 'occupied', 589: 'supervision', 590: 'schools', 591: 'foreigners.', 592: 'border', 593: 'embark', 594: 'Spain,', 595: 'canneries.', 596: 'modern', 597: 'short-term', 598: 'issues', 599: 'carrying', 600: 'justice,"', 601: 'reading,', 602: 'folly', 603: '"It', 604: 'kilogram.', 605: "Finland's", 606: 'group', 607: 'meteorologists', 608: 'Defense', 609: 'results.', 610: 'sewage', 611: 'flexibly', 612: 'emphasized.', 613: 'B', 614: 'suspicious', 615: 'Langnau', 616: 'dramatically', 617: 'product,', 618: 'million,', 619: 'end', 620: 'analysis', 621: 'programmes,', 622: 'investigations', 623: 'terms"', 624: 'links.', 625: 'presented', 626: 'Vejonis', 627: 'funds', 628: 'Inc', 629: 'ongoing,', 630: 'presence', 631: 'sensitive', 632: 'ascertained', 633: 'cents', 634: '150', 635: 'invest', 636: 'Brouwer', 637: 'he', 638: 'may', 639: 'said', 640: 'Independent', 641: '"catastrophic"', 642: '27', 643: 'money', 644: 'production.', 645: 'survived', 646: 'Riga', 647: 're-established', 648: 'relatively', 649: 'receives', 650: 'synchronization', 651: 'relations', 652: '17', 653: 'protect', 654: 'steeper', 655: 'lived', 656: 'miners', 657: 'facilitate', 658: 'Competition', 659: 'canneries', 660: 'bordering', 661: 'SITE', 662: "''We", 663: 'won', 664: 'Belgium,', 665: 'centennial', 666: 'stops.', 667: '(Unity)', 668: '"He', 669: 'weeks,', 670: 'ensure', 671: 'confidential', 672: 'Tour', 673: 'reformed,', 674: 'century', 675: 'strict', 676: 'Two', 677: 'operates', 678: 'informed', 679: 'sold', 680: 'received', 681: 'provision', 682: 'compromised.', 683: 'SEB', 684: 'suggests', 685: 'meaning', 686: 'two', 687: 'URGENT:', 688: 'help', 689: 'they', 690: 'story,', 691: 'challenges', 692: 'basic', 693: 'today,', 694: 'Tax', 695: 'according', 696: 'animal', 697: '10', 698: '19%', 699: 'these', 700: 'council.', 701: 'target', 702: 'are', 703: 'particularly', 704: 'named', 705: 'Slovakia', 706: 'approaching', 707: 'relationship', 708: 'acquire', 709: "Pyongyang's", 710: 'academic', 711: 'belongs', 712: 'Local', 713: 'came', 714: 'along', 715: 'any', 716: 'Furthermore,', 717: 'month-on-month,', 718: 'there', 719: 'hashtagged', 720: 'talking', 721: 'inform', 722: 'ceremony', 723: 'want.', 724: 'Sept', 725: 'Lita', 726: 'Mohamed', 727: 'presentations', 728: 'coal', 729: 'joined', 730: 'Ross,', 731: 'Rpax', 732: 'freedom,', 733: 'operator', 734: 'anniversary.', 735: 'defend', 736: 'rebounds', 737: 'groups', 738: 'increase', 739: 'language,', 740: "'Mosul", 741: 'Europol', 742: 'Funderful,', 743: 'memorandum', 744: 'declined', 745: 'Tuesday,', 746: 'since', 747: 'current', 748: 'its', 749: 'regulations', 750: 'saying.', 751: 'get', 752: 'service', 753: 'other', 754: 'consolidated', 755: '"disastrous".', 756: '"When', 757: 'offered', 758: 'combined', 759: 'decline.', 760: 'possibility', 761: 'Russia', 762: 'enough', 763: 'Cavaliers.', 764: 'dream,', 765: 'month.', 766: 'finance', 767: '14.3', 768: 'Ieva', 769: 'degrees', 770: 'Euro-Atlantic', 771: 'informs', 772: 'inspections', 773: 'India,', 774: 'aspects', 775: '57%', 776: 'regions', 777: 'homework', 778: 'contact', 779: 'dramatic', 780: 'humanitarian', 781: 'decision', 782: 'September,', 783: 'urgent', 784: 'disputed', 785: 'Elzbieta', 786: 'airspace', 787: 'Budapest.', 788: 'reporting', 789: 'macroeconomic', 790: 'Belarus', 791: 'year', 792: 'risks', 793: 'pitching', 794: 'title', 795: 'collection', 796: 'City', 797: 'poverty', 798: 'pimping', 799: '15:9)', 800: 'milk;', 801: 'LI', 802: 'forwarded', 803: 'partners,', 804: 'potentially', 805: 'Public', 806: 'positive,', 807: 'depend', 808: 'increased.', 809: 'important', 810: 'extended', 811: 'Ozols', 812: "''Little", 813: 'excellent', 814: 'opportunities.', 815: 'prime', 816: 'Baskakov', 817: 'actually', 818: '(out)', 819: 'Productions,', 820: 'education', 821: 'set', 822: 'chain,', 823: "''It", 824: 'crediting', 825: '1:1,', 826: 'upon', 827: 'Rio', 828: 'election', 829: 'team', 830: 'River,', 831: 'euro', 832: 'civil', 833: 'escape.', 834: 'Vienna', 835: 'Baltic-Benelux', 836: 'broke', 837: 'general-secretary', 838: 'water.', 839: 'Welfare', 840: 'Anda', 841: 'technology', 842: 'Some', 843: 'fact', 844: 'Football', 845: 'cooler,', 846: 'Normunds', 847: 'look', 848: 'local', 849: '1,000', 850: 'Tuesday', 851: '9.', 852: 'Western', 853: "Seneca's", 854: 'United', 855: 'finding', 856: 'ball', 857: 'especially', 858: 'new', 859: 'Samoilovs/Smedins', 860: 'Federal', 861: 'Speaking', 862: '17.2', 863: 'Petr', 864: 'Duma', 865: 'billion.', 866: 'guard', 867: 'GribuTeviAtpakal', 868: 'parents,"', 869: 'crash', 870: 'might', 871: 'underground,', 872: 'disturbed', 873: 'international', 874: 'case', 875: 'debts', 876: 'several', 877: 'presents', 878: 'system.', 879: 'transportation,', 880: 'embassy', 881: 'sides', 882: 'Inara', 883: 'contribution', 884: 'system', 885: 'promised', 886: 'permit', 887: 'State', 888: "employees'", 889: 'side', 890: 'find', 891: 'Oxford', 892: 'children,', 893: 'diversification', 894: 'have', 895: 'clients', 896: 'close', 897: 'benefit', 898: 'high', 899: 'Poland', 900: 'postponed', 901: 'technology,', 902: 'Remuneration', 903: 'June,', 904: 'Commonwealth', 905: 'radio', 906: '801', 907: 'Martins', 908: 'submarines', 909: 'Heroes’', 910: 'strengthens', 911: 'Wednesday.', 912: 'percent.', 913: 'speak', 914: "IKEA's", 915: 'Press', 916: 'Mazunas,', 917: 'bankers', 918: 'face', 919: 'planes,', 920: 'collected', 921: 'followed', 922: 'Foundation', 923: 'Exporting', 924: 'later,', 925: 'recent', 926: 'reopened', 927: 'undercut', 928: 'future,"', 929: 'Record,', 930: 'feels', 931: 'She', 932: 'against.', 933: 'are,"', 934: 'total', 935: 'warm', 936: 'Marija', 937: '(dpa)', 938: "ministry's", 939: 'old', 940: '(Hosök', 941: 'coordinator', 942: 'voting', 943: 'extremists.', 944: 'people,', 945: 'strengthening', 946: 'mine', 947: 'goalie', 948: 'efficient.', 949: 'version', 950: 'faster', 951: 'warned', 952: "that's", 953: 'brand.', 954: 'Europe.', 955: 'trade', 956: 'Service.', 957: 'sovereignty', 958: 'Augulis', 959: 'resolve', 960: 'unchanged.', 961: 'Kim,', 962: 'contradiction', 963: 'plan', 964: "Switzerland's", 965: 'soldiers', 966: 'off,', 967: '2016,', 968: 'accidentally', 969: 'Michael', 970: 'political', 971: 'Twenty-two', 972: '622,', 973: 'Europe,', 974: 'solely', 975: 'board', 976: 'Radio', 977: 'Policy', 978: 'should', 979: 'citizens', 980: 'government', 981: 'down', 982: 'billion', 983: "citizens'", 984: 'that"we', 985: 'implement', 986: 'Nationality', 987: 'origin.', 988: 'Iran', 989: 'before', 990: 'Prudel', 991: 'organizations.', 992: 'under', 993: 'August.', 994: 'much', 995: 'countries', 996: 'conditions', 997: 'growth', 998: 'Dainius', 999: 'fix', 1000: 'spent', 1001: 'property,', 1002: 'prove', 1003: 'Organization', 1004: 'head', 1005: 'Russia,', 1006: 'moment,', 1007: 'Funderfun', 1008: 'names', 1009: 'previously', 1010: 'today', 1011: 'possible', 1012: 'eurozone', 1013: 'disastrous,', 1014: 'supervisory', 1015: 'able', 1016: 'amount', 1017: 'Square', 1018: 'norms', 1019: 'Eiropas', 1020: 'if', 1021: 'temperatures', 1022: 'tighten', 1023: 'accelerator', 1024: 'Authorities', 1025: 'public.', 1026: 'railway', 1027: 'Marijus', 1028: 'leads', 1029: 'SkenarioLab', 1030: 'connections', 1031: 'relations.', 1032: 'zero', 1033: 'Kindercatering,', 1034: 'want', 1035: 'procurements.', 1036: 'signed', 1037: 'regarding', 1038: 'regime', 1039: 'milk,', 1040: 'deliberation', 1041: 'Lithuania', 1042: "company's", 1043: 'economy,"', 1044: 'him,"', 1045: '301', 1046: 'Mosul', 1047: 'agreement,"', 1048: 'budgets', 1049: 'official', 1050: 'cut', 1051: 'accepted', 1052: 'was', 1053: 'Banka', 1054: 'Ronalds', 1055: 'served', 1056: 'time,', 1057: 'percent)', 1058: '32', 1059: 'proposals', 1060: 'payment', 1061: 'spokeswoman', 1062: 'remained', 1063: 'electricity.', 1064: 'model', 1065: 'debt', 1066: 'law,"', 1067: 'NATO’s', 1068: 'pace', 1069: '"Latvian".', 1070: 'states,', 1071: 'Over', 1072: 'provided', 1073: 'notches', 1074: 'cable', 1075: 'pharmaceuticals,', 1076: 'against', 1077: '500,000', 1078: 'ran', 1079: '"Nearly', 1080: 'transatlantic', 1081: 'day,', 1082: 'program', 1083: 'adequate', 1084: 'latest', 1085: "Employers'", 1086: 'even', 1087: 'successful', 1088: 'visited', 1089: 'frustrated', 1090: 'certainly', 1091: 'administration', 1092: 'deterrent.', 1093: 'eastern', 1094: 'condition', 1095: 'status', 1096: 'winners', 1097: '11', 1098: '"This', 1099: 'Following', 1100: '"We', 1101: 'indication"', 1102: 'Lise', 1103: 'Studio', 1104: 'Vision', 1105: 'security', 1106: 'when', 1107: 'stunned', 1108: 'reform', 1109: 'monitors', 1110: 'additional', 1111: 'two-lane', 1112: 'chief', 1113: 'expand', 1114: '"key', 1115: 'Manabalss.lv', 1116: 'refugee', 1117: 'one.', 1118: 'late', 1119: 'class,', 1120: 'grocery', 1121: 'per', 1122: 'together', 1123: 'regards', 1124: 'Countries', 1125: '7.3', 1126: 'president,', 1127: 'you', 1128: 'peace', 1129: 'General', 1130: 'begin', 1131: 'suffered', 1132: '31', 1133: 'year;', 1134: 'green-technologies', 1135: 'last"', 1136: '30,', 1137: 'alliance', 1138: 'women', 1139: 'Aiva', 1140: 'production', 1141: 'in-depth', 1142: 'necessary', 1143: 'Gavenonis,', 1144: 'agreement', 1145: 'following', 1146: 'Bucks', 1147: 'remaining', 1148: 'weapons', 1149: 'source', 1150: 'power', 1151: 'general', 1152: 'Mego', 1153: 'output', 1154: 'counterpart', 1155: 'again', 1156: 'benefits', 1157: 'play', 1158: 'cooperation', 1159: 'focus', 1160: 'Tigers', 1161: 'Crimea', 1162: 'battle', 1163: "Punnenovs'", 1164: 'many', 1165: 'work', 1166: 'producers', 1167: 'employees', 1168: 'billion,', 1169: 'growth.', 1170: 'stars', 1171: 'bit,"', 1172: 'Lugano', 1173: 'culture,', 1174: "Korea's", 1175: 'invited', 1176: 'region,"', 1177: 'Agnis', 1178: 'Sachs,', 1179: 'project.', 1180: 'Name,', 1181: 'active,"', 1182: 'methods', 1183: 'Sabiedriba', 1184: 'the', 1185: "Estonia's", 1186: 'explained', 1187: 'compliance', 1188: 'predicting', 1189: 'startups', 1190: 'evaluation', 1191: 'Mnuchin,', 1192: 'signature', 1193: '22:24,', 1194: 'principle', 1195: '1.035', 1196: 'participate', 1197: 'educated', 1198: 'selling', 1199: 'RIGA,', 1200: 'must"come', 1201: 'projects,', 1202: 'agenda', 1203: 'responsibilities', 1204: 'Republic', 1205: 'comments', 1206: 'strategic', 1207: 'having', 1208: "''Yet", 1209: 'Warsaw.', 1210: 'red-faced', 1211: 'implementing', 1212: 'postpones', 1213: 'months', 1214: 'experts', 1215: 'himself', 1216: 'Produced', 1217: 'Internet', 1218: '(LI)', 1219: 'violated', 1220: 'later.', 1221: 'position', 1222: '(EU)', 1223: 'online', 1224: 'Without', 1225: 'un-collectable', 1226: 'Europe', 1227: 'Brazil', 1228: 'but', 1229: "Pandora's", 1230: 'much.', 1231: 'topic', 1232: '(0:1,', 1233: 'Krievins', 1234: 'speed', 1235: 'Due', 1236: 'Eurostat', 1237: "concern's", 1238: 'interesting', 1239: 'now', 1240: 'response', 1241: 'November', 1242: 'stores', 1243: 'hard.', 1244: 'Development', 1245: 'we', 1246: 'assessing', 1247: 'lone', 1248: 'January,', 1249: 'starting', 1250: 'freight', 1251: 'legalization', 1252: 'operating', 1253: 'supports', 1254: 'corvette', 1255: 'condemns', 1256: 'Smedins', 1257: 'Transportation', 1258: 'Signatures', 1259: 'such', 1260: 'Department', 1261: 'ships', 1262: 'earlier.', 1263: 'afternoon,', 1264: 'share', 1265: 'competitive', 1266: 'expressed', 1267: 'learned', 1268: 'innovative', 1269: 'titled', 1270: 'line', 1271: 'this,', 1272: 'use', 1273: 'At', 1274: "nation's", 1275: 'explosion.', 1276: 'relationship.', 1277: 'owned', 1278: 'included', 1279: 'reducing', 1280: 'belonging', 1281: 'six', 1282: '39', 1283: 'believes', 1284: 'representatives', 1285: 'Business', 1286: 'emphasized', 1287: 'deflation', 1288: '"Unfortunately,', 1289: 'President', 1290: 'various', 1291: "Agency's", 1292: 'night', 1293: 'LETA', 1294: 'Digital', 1295: 'east', 1296: 'interests,"', 1297: 'Treasury', 1298: 'wishes.', 1299: 'tested', 1300: 'fish', 1301: 'efficiently', 1302: 'Canadian', 1303: 'however,', 1304: 'Amrion', 1305: 'working', 1306: 'categories', 1307: 'police', 1308: 'productivity', 1309: 'Freedom', 1310: 'noted', 1311: 'wish', 1312: 'universities.', 1313: '1989,', 1314: 'export', 1315: 'least', 1316: 'ago', 1317: 'Uljana', 1318: 'families', 1319: 'compensated.', 1320: 'supply-side', 1321: 'constituencies', 1322: 'distributions', 1323: 'solidarity,', 1324: 'economists', 1325: 'manager', 1326: 'UEFA,', 1327: 'Federation', 1328: 'survey.', 1329: 'do', 1330: 'All', 1331: 'Canadian-led', 1332: 'ZSC', 1333: 'pollution', 1334: 'ensuring', 1335: 'developed', 1336: 'ways', 1337: 'These', 1338: 'Italy', 1339: 'this', 1340: 'CIA', 1341: 'thousands', 1342: 'Muslims', 1343: 'process,', 1344: 'continued', 1345: 'originally', 1346: 'regular', 1347: 'match', 1348: 'Today,', 1349: 'agricultural', 1350: 'Vance,', 1351: 'disillusionment', 1352: 'test', 1353: 'Purchases', 1354: 'film', 1355: 'did', 1356: '"no', 1357: 'container', 1358: 'available', 1359: 'handed', 1360: 'yet', 1361: 'delivery', 1362: 'Nations', 1363: 'well', 1364: 'student,', 1365: 'Merzlikins', 1366: 'oil', 1367: 'member', 1368: '(Greens/Farmers)', 1369: 'bill,', 1370: 'dialogue', 1371: 'restricting', 1372: 'transport,', 1373: 'months,', 1374: 'shot', 1375: 'real-estate', 1376: 'debts,', 1377: 'compatriots', 1378: 'Eurasian', 1379: 'level,', 1380: 'inspectors', 1381: 'different', 1382: 'Vejonis.', 1383: 'correction', 1384: 'months.', 1385: 'Venice.', 1386: '2.3', 1387: 'infrastructure.', 1388: 'place', 1389: 'mainly', 1390: 'still', 1391: 'incident', 1392: 'above,', 1393: 'Firmas.lv.', 1394: 'substantial', 1395: 'However,', 1396: 'endeavours', 1397: '0.5', 1398: 'Karlis', 1399: 'predicts', 1400: 'step', 1401: 'connection', 1402: 'headquartered', 1403: 'catering', 1404: 'On', 1405: 'estimated', 1406: 'priority', 1407: 'institution', 1408: 'year,', 1409: 'below', 1410: 'Roman', 1411: 'CEO', 1412: 'applied', 1413: 'In', 1414: 'Procurement', 1415: 'a', 1416: 'deal', 1417: 'Total', 1418: 'expected.', 1419: 'situation', 1420: 'economy.', 1421: 'highlighted', 1422: 'Zealand', 1423: 'products', 1424: 'while', 1425: 'approved', 1426: 'enough,"', 1427: 'attitude,', 1428: 'it.', 1429: 'recognized,"', 1430: 'that"due', 1431: 'India.', 1432: 'inside', 1433: 'Greece', 1434: 'London,', 1435: 'Hesztera', 1436: 'unity,', 1437: 'wolf', 1438: 'region', 1439: 'manufacturing', 1440: 'Economic', 1441: 'smallest', 1442: 'opened,', 1443: 'Sevastopol', 1444: "That's", 1445: 'far', 1446: 'Juozas', 1447: 'Secretary,', 1448: '"Our', 1449: '7', 1450: 'Krauze', 1451: 'criticism.', 1452: 'paper', 1453: 'emphasize', 1454: 'own', 1455: 'Investments', 1456: 'testing', 1457: 'maker', 1458: 'posted', 1459: 'submission', 1460: 'Luxembourg-registered', 1461: 'UN', 1462: '2:0,', 1463: 'discussions.', 1464: 'central', 1465: '2017,', 1466: 'missions', 1467: 'operational', 1468: 'accordingly.', 1469: 'fourth', 1470: 'Iraq.', 1471: 'expansion', 1472: 'make', 1473: 'NBA:', 1474: 'waters', 1475: 'RB', 1476: 'catastrophic,"', 1477: 'Committee', 1478: 'China.', 1479: 'offer', 1480: 'employers', 1481: 'eight', 1482: '"Regardless', 1483: 'problems', 1484: 'ports,', 1485: 'products,"', 1486: 'uniform', 1487: 'forest', 1488: 'Tirgotajs', 1489: '30', 1490: 'earthquake,"', 1491: 'Rinkevics', 1492: 'urging', 1493: 'tere)', 1494: 'public', 1495: 'North', 1496: 'Latvija,', 1497: '(+4.1', 1498: 'adequately', 1499: 'social', 1500: 'joint', 1501: 'report', 1502: 'one', 1503: 'forces', 1504: 'Dzelzcels', 1505: 'position,', 1506: 'injured', 1507: '--', 1508: 'also', 1509: 'defense.', 1510: 'Latvian', 1511: "n't", 1512: 'school', 1513: 'territories', 1514: 'nation', 1515: 'performance', 1516: 'IMS', 1517: 'stipulating', 1518: 'programme', 1519: 'Edvinds', 1520: 'little', 1521: 'integrity', 1522: 'situation,', 1523: 'crash.', 1524: 'Eurostat.', 1525: '2014', 1526: '(+5', 1527: 'procurement', 1528: 'high-speed', 1529: 'Kucinskis', 1530: 'company,', 1531: 'geographic', 1532: 'Benelux', 1533: 'known', 1534: 'us', 1535: 'submitted', 1536: 'belong', 1537: 'deployed', 1538: 'Mezeckis.', 1539: 'drinking', 1540: 'readings.', 1541: 'valid', 1542: 'five', 1543: 'Fijalek', 1544: 'only', 1545: 'duo', 1546: 'great,', 1547: 'reveal', 1548: 'This', 1549: 'earned', 1550: 'purchase', 1551: 'fear', 1552: 'Malta', 1553: 'solidarity,"', 1554: 'logistics', 1555: 'respect', 1556: '19', 1557: 'hometown', 1558: 'know', 1559: 'Meteorology', 1560: 'We', 1561: 'stake', 1562: 'alternative', 1563: 'interests.', 1564: 'call', 1565: 'hopes', 1566: 'Warsaw', 1567: 'external', 1568: '2015.', 1569: 'Bank', 1570: 'Estonia', 1571: 'Helsinki', 1572: 'fighter,', 1573: 'achieve', 1574: 'placing', 1575: 'air', 1576: 'It', 1577: 'strong', 1578: 'warns', 1579: 'protected', 1580: 'why', 1581: 'reconnaissance', 1582: 'tearing', 1583: 'ally', 1584: 'serve', 1585: '930.226', 1586: 'recorded', 1587: 'whole.', 1588: 'Lake', 1589: 'forecast', 1590: 'salary.', 1591: 'LeBron', 1592: 'John', 1593: 'year.', 1594: 'percent),', 1595: 'must', 1596: "cartel's", 1597: 'Festival', 1598: 'vessels.', 1599: 'Jonathan', 1600: 'exceeding', 1601: 'ripping', 1602: 'information', 1603: 'bringing', 1604: 'store', 1605: 'related', 1606: 'BERN,', 1607: 'part', 1608: 'autumn,', 1609: 'forward', 1610: '69,109', 1611: 'dealing', 1612: '322.259', 1613: 'June', 1614: 'Among', 1615: 'bridge,', 1616: 'Bankis,', 1617: 'Mezeckis,', 1618: 'dairy', 1619: 'needed,', 1620: 'Latvians', 1621: 'challenges,', 1622: 'felt', 1623: 'tech', 1624: 'Kristaps', 1625: 'Soviet', 1626: 'Petroleum', 1627: 'after', 1628: 'monthly', 1629: 'foresee', 1630: 'temperatures.', 1631: 'rise', 1632: 'countries.', 1633: 'turnover', 1634: 'authority', 1635: 'good.', 1636: 'National', 1637: 'join', 1638: 'reforms', 1639: 'diplomatically,', 1640: 'making', 1641: 'Slovenia', 1642: 'taking', 1643: 'aircraft', 1644: 'property', 1645: 'logistics.', 1646: 'Tallinn,', 1647: 'letter.', 1648: 'centers', 1649: 'reason', 1650: '18,', 1651: 'box', 1652: 'Ardian', 1653: '800', 1654: 'created', 1655: 'slows,', 1656: 'survivors', 1657: 'legislation.', 1658: 'contributions', 1659: 'stipulates', 1660: 'Jolanta', 1661: 'data', 1662: 'Center', 1663: 'Servette', 1664: 'billionaire', 1665: 'all', 1666: 'S.A.', 1667: 'seen', 1668: 'illegal,"', 1669: 'check', 1670: 'civilians,', 1671: 'that', 1672: 'consecutive', 1673: 'postponing', 1674: 'solidarity', 1675: 'Meistere,', 1676: 'matter', 1677: 'endorsed', 1678: 'post-war', 1679: 'bill', 1680: 'Lions', 1681: 'Khalil,', 1682: 'fifteen', 1683: 'greater', 1684: 'Antonio', 1685: 'brothels', 1686: 'rebounded', 1687: 'advisor', 1688: 'finances', 1689: 'apparently', 1690: 'proceed', 1691: 'Scandinavia', 1692: 'project,"', 1693: 'Forces.', 1694: 'Bartaite.', 1695: '16.77', 1696: 'everything,"', 1697: 'Thus', 1698: 'about', 1699: 'members', 1700: 'reduced', 1701: 'furniture', 1702: 'predict', 1703: "group's", 1704: 'faster,', 1705: '"I', 1706: 'Kindercatering', 1707: 'limitation', 1708: 'September.', 1709: 'attacks,', 1710: 'divided', 1711: 'person', 1712: 'Brussels,', 1713: '0.15', 1714: 'Colombian', 1715: 'record', 1716: 'Its', 1717: 'as', 1718: 'between', 1719: 'Wednesday', 1720: 'Linija,', 1721: "line's", 1722: 'Lenoka', 1723: 'think', 1724: 'appears', 1725: 'Majesty', 1726: 'sleep', 1727: '(+6.8', 1728: 'integration', 1729: '(similar', 1730: 'accreditation,', 1731: '15.', 1732: 'future', 1733: 'Kyrie', 1734: 'exporting', 1735: 'not', 1736: 'Meanwhile,', 1737: '3.9', 1738: 'annual', 1739: 'experts,', 1740: 'ca', 1741: 'Canada,', 1742: 'Agricultural,', 1743: 'As', 1744: 'Slocene', 1745: 'chain', 1746: 'be', 1747: 'has', 1748: 'stood', 1749: 'India', 1750: 'damage', 1751: 'saying,', 1752: 'experience', 1753: 'products,', 1754: 'If', 1755: 'line,', 1756: 'Slovenia,', 1757: 'third', 1758: 'your', 1759: 'Korea', 1760: '"They', 1761: 'beat', 1762: 'Estonian', 1763: 'School', 1764: 'added.', 1765: 'decide', 1766: 'Berlin', 1767: '#', 1768: 'during', 1769: 'Brennan', 1770: 'does', 1771: 'seminars', 1772: 'Bite', 1773: 'balance', 1774: 'seventh', 1775: 'pimping,', 1776: 'Latvijas', 1777: 'LETA,', 1778: 'mobile', 1779: 'wreath', 1780: 'key', 1781: 'using', 1782: 'defiance.', 1783: 'necessary.', 1784: 'unemployment', 1785: 'Czech', 1786: 'met', 1787: 'assessment', 1788: 'bought', 1789: 'Hungary’s', 1790: 'impact', 1791: '700', 1792: 'tariff', 1793: 'famous', 1794: 'well.', 1795: 'Grzegorz', 1796: 'alliance,', 1797: 'sanctions', 1798: '.""Both', 1799: 'statement.', 1800: 'voiced', 1801: 'conference', 1802: 'prohibit', 1803: 'assist', 1804: 'owing', 1805: '2:0).', 1806: '2014.', 1807: '872.525', 1808: '[IKEA', 1809: 'Criminal', 1810: 'Araja', 1811: "bloc's", 1812: 'Number', 1813: 'winds', 1814: 'betrayed', 1815: 'goods', 1816: 'frigate', 1817: 'test,', 1818: 'shame', 1819: 'adequate,', 1820: 'follow', 1821: '"live', 1822: 'insisted', 1823: '(+3.7', 1824: '(National', 1825: 'haunting', 1826: 'trustworthy', 1827: 'debtors', 1828: 'Kim', 1829: 'history', 1830: 'for', 1831: 'FIVB', 1832: 'competition', 1833: 'Monday', 1834: '4.4-magnitude', 1835: 'sure', 1836: 'steepest', 1837: '"very', 1838: 'thanks', 1839: 'earthquake', 1840: 'Speaker', 1841: 'So', 1842: 'earnings,', 1843: 'Zembla,', 1844: 'ideals', 1845: 'each', 1846: 'resident', 1847: 'sad', 1848: 'Rojas.', 1849: 'detailed', 1850: 'stand', 1851: 'fields,', 1852: 'overcome', 1853: 'Chief', 1854: 'visit', 1855: 'already', 1856: 'understand', 1857: 'in', 1858: 'force,"', 1859: 'Back),', 1860: '25', 1861: 'average', 1862: 'tempo', 1863: 'Vesko', 1864: 'Philippe', 1865: 'Taurina', 1866: 'will', 1867: 'Lithuanian', 1868: 'said.', 1869: 'retail', 1870: 'Veterinary', 1871: 'entrepreneurs', 1872: 'calls', 1873: 'breath', 1874: '1,702', 1875: "we're", 1876: 'special', 1877: '28', 1878: 'Rail', 1879: 'youthful', 1880: 'moment', 1881: 'need', 1882: 'Wiesbaden.', 1883: 'thus', 1884: 'Still', 1885: 'insider', 1886: 'AFP', 1887: 'drainage', 1888: 'safety', 1889: 'legal', 1890: 'higher', 1891: "Poland's", 1892: 'Giannis', 1893: 'final', 1894: 'figure', 1895: 'years,', 1896: '"almost', 1897: 'Police', 1898: 'salmonella', 1899: '-', 1900: 'Television', 1901: '–', 1902: 'But', 1903: 'finally', 1904: 'Cooperation', 1905: 'Sadurskis.', 1906: 'stake.', 1907: 'among', 1908: 'instead', 1909: 'Disease', 1910: 'appeared', 1911: 'association', 1912: 'The', 1913: 'nationality', 1914: 'relations,', 1915: 'called', 1916: 'celebrating', 1917: 'hundreds', 1918: 'persons', 1919: 'structures.', 1920: 'number', 1921: 'concern', 1922: 'aviation', 1923: 'Ukrainian', 1924: 'link', 1925: 'prices', 1926: 'answer', 1927: 'preferable', 1928: 'Cambridge', 1929: 'criminal', 1930: 'fault.', 1931: 'Government', 1932: 'chose', 1933: 'programs', 1934: '(LETA)', 1935: 'services', 1936: "children's", 1937: 'equaled', 1938: 'sending', 1939: 'reside', 1940: 'next', 1941: 'European', 1942: 'failed', 1943: 'week.', 1944: 'Stopini', 1945: 'electrical', 1946: 'letter', 1947: '2005', 1948: 'KGHM,', 1949: 'flight', 1950: 'inspected', 1951: 'venture.', 1952: 'Baghdad,', 1953: 'barrels', 1954: 'residence', 1955: 'EUR', 1956: 'slowed', 1957: 'conflict".', 1958: 'found,', 1959: 'Denmark', 1960: 'defeated', 1961: 'searching', 1962: 'Fellowship,', 1963: 'States,', 1964: 'maintain', 1965: 'word', 1966: 'translation', 1967: 'reads.', 1968: '."', 1969: 'sign', 1970: 'ballistic', 1971: 'entire', 1972: 'urged', 1973: '2013.', 1974: 'water', 1975: 'no', 1976: 'forced', 1977: 'multinational', 1978: 'says.', 1979: 'Resource', 1980: 'authorities', 1981: 'Center.', 1982: '1.4', 1983: 'i.e.', 1984: 'Parliament', 1985: 'Dzelzcels.', 1986: 'job', 1987: 'Set', 1988: 'minister', 1989: 'unless', 1990: '57', 1991: 'win', 1992: 'credentials', 1993: 'then,', 1994: 'future.', 1995: 'ball,"', 1996: 'now.', 1997: 'Netherlands.', 1998: 'Italian', 1999: 'same', 2000: 'summer,', 2001: 'towards', 2002: 'out', 2003: 'ongoing...', 2004: 'grown', 2005: 'endangering', 2006: 'employment', 2007: 'country', 2008: 'research', 2009: 'Memorial', 2010: 'aside', 2011: 'Fribourg-Gotteron', 2012: 'defense', 2013: 'market', 2014: '"Liv"', 2015: 'discussions', 2016: 'helped', 2017: 'vice-president', 2018: 'Ross', 2019: 'Robert', 2020: 'president-elect', 2021: 'from', 2022: 'hard', 2023: 'giving', 2024: 'partners', 2025: 'NBA', 2026: 'discussed', 2027: 'safely', 2028: 'sector.', 2029: 'policy,', 2030: 'established', 2031: 'sector', 2032: 'Ruse', 2033: 'secure', 2034: 'fodder', 2035: 'admitted', 2036: 'place,', 2037: 'responsibility', 2038: 'shortage', 2039: 'cargo', 2040: 'nothing', 2041: 'details', 2042: 'despite', 2043: 'organizations', 2044: 'by', 2045: 'train', 2046: 'revenue', 2047: 'ill-intended,"', 2048: 'brand,', 2049: 'technical', 2050: 'shipments', 2051: 'Baltica', 2052: 'pose', 2053: 'way,"', 2054: 'LFF', 2055: 'Zug', 2056: 'Law,', 2057: 'president', 2058: 'non-governmental', 2059: 'permanent', 2060: 'director', 2061: '400', 2062: 'competitiveness', 2063: 'Somali', 2064: 'her', 2065: 'stimulate', 2066: 'stick', 2067: 'Therefore', 2068: 'reports', 2069: 'Slokenbeka', 2070: 'speech', 2071: 'company', 2072: 'mean', 2073: 'Employees', 2074: 'Sevastopol,', 2075: 'political,', 2076: 'foreigners', 2077: 'BBC,', 2078: 'crises,', 2079: 'Sadurskis', 2080: 'whole', 2081: 'terror', 2082: 'second', 2083: "face'catastrophic", 2084: 'collapse,', 2085: 'Colombia', 2086: 'see', 2087: 'founded', 2088: 'policing', 2089: 'it', 2090: 'Kingdom,', 2091: 'sometime', 2092: 'gross', 2093: 'control,', 2094: '2004,', 2095: 'mission.', 2096: 'structure', 2097: 'reduce', 2098: 'Iraqis', 2099: 'Change', 2100: 'contracts', 2101: 'Geology', 2102: 'demonstrate', 2103: 'Ceferin', 2104: 'Angeles,', 2105: 'initiative', 2106: 'Partners.', 2107: 'being', 2108: 'added', 2109: 'James', 2110: 'world', 2111: '0:1).', 2112: 'comprised', 2113: 'can', 2114: 'capital', 2115: 'Celsius,', 2116: 'Asia,', 2117: 'city,', 2118: 'He', 2119: 'Investigation', 2120: 'reasons,', 2121: 'TV', 2122: 'Ohio', 2123: 'history,', 2124: 'planned', 2125: 'put', 2126: 'Northern', 2127: 'stronger', 2128: 'Los', 2129: 'breach', 2130: 'formed', 2131: 'hand,', 2132: 'miraculously', 2133: 'project', 2134: 'companies', 2135: 'days,', 2136: '2000.', 2137: 'reported.', 2138: '"Europol', 2139: 'Law', 2140: 'Affairs', 2141: 'activities', 2142: 'acquisition', 2143: 'transit', 2144: 'Riga.', 2145: 'Up', 2146: 'point', 2147: 'vote', 2148: 'LETA.', 2149: 'Islamic', 2150: 'thankful', 2151: 'fire.', 2152: 'global', 2153: 'raise', 2154: '(21:17,', 2155: 'Sevastopol.', 2156: 'instances', 2157: 'quoted', 2158: 'each),', 2159: 'New', 2160: 'meantime,', 2161: 'Trump', 2162: 'registers', 2163: 'address.', 2164: 'statute', 2165: 'construction', 2166: 'people', 2167: 'butter', 2168: 'near', 2169: 'campaign,', 2170: 'markets,', 2171: 'night.', 2172: 'month', 2173: 'Hungary', 2174: 'another', 2175: 'minus', 2176: 'praised', 2177: 'cap', 2178: 'advance', 2179: 'bonuses', 2180: 'Announcing', 2181: 'ask', 2182: 'Necessary', 2183: 'Global', 2184: 'needs', 2185: 'ethnic', 2186: 'she', 2187: 'reinforcing', 2188: 'private', 2189: '1.9', 2190: 'Eduardo', 2191: 'resolution', 2192: 'calculated', 2193: 'become', 2194: '(+7.4', 2195: '501', 2196: 'south.', 2197: '"Latvian"', 2198: 'invested', 2199: 'pace,', 2200: 'western', 2201: 'prostitution', 2202: 'law,', 2203: 'cooperation,', 2204: 'pages', 2205: 'Member', 2206: 'indicating', 2207: 'border.', 2208: 'feed', 2209: 'believe', 2210: '"We\'re', 2211: 'Latvians,', 2212: 'so', 2213: 'Prevention', 2214: 'order', 2215: 'meeting', 2216: '2.2', 2217: '12', 2218: 'markets', 2219: 'Black', 2220: 'Industrial', 2221: 'Director', 2222: 'cultural', 2223: 'Bergmanis', 2224: 'web-site', 2225: 'Ministry', 2226: 'Finals', 2227: 'upsets', 2228: 'Ireland', 2229: "alliance's", 2230: 'issues.', 2231: 'state', 2232: 'showed', 2233: '1.421', 2234: 'argument', 2235: 'heart".', 2236: 'without', 2237: 'Krasnopjorovs', 2238: 'knowledge', 2239: 'Unda,', 2240: 'Aleksander', 2241: 'regularly', 2242: 'Lithuania,', 2243: 'capacities', 2244: 'route', 2245: 'reported,', 2246: 'unprecedented"', 2247: 'battalion', 2248: 'controls', 2249: 'fines', 2250: 'Latvian-Italian', 2251: 'strongest', 2252: 'favor', 2253: 'Lielais', 2254: '60', 2255: 'MEPs.', 2256: "we've", 2257: 'really', 2258: 'potential', 2259: 'Belgium', 2260: 'Olympic', 2261: 'During', 2262: 'resuming', 2263: 'profit', 2264: 'Driksna', 2265: 'IT', 2266: 'Environmental', 2267: 'Upcoming', 2268: 'account', 2269: 'personally', 2270: 'investment', 2271: 'ex-employee', 2272: 'more.', 2273: 'totaled', 2274: 'via', 2275: 'stores.', 2276: 'Latvia.', 2277: 'petitions', 2278: "operator's", 2279: 'past', 2280: 'weapons.', 2281: 'civilians', 2282: 'read', 2283: 'expected', 2284: 'increases', 2285: 'NATO', 2286: 'foreign', 2287: 'Geneva', 2288: 'released', 2289: 'countries,', 2290: 'killed', 2291: 'deal,', 2292: 'news', 2293: 'Finals.', 2294: 'Service', 2295: 'Firmas.lv,', 2296: 'center', 2297: 'infrastructure,', 2298: 'moved', 2299: 'quarter', 2300: 'requirements', 2301: 'based', 2302: 'data,', 2303: 'defeat', 2304: 'prepared', 2305: 'include', 2306: 'passenger', 2307: 'strongly', 2308: 'lead', 2309: 'fresh', 2310: 'Last', 2311: 'armed', 2312: 'Salmonellosis', 2313: 'January', 2314: 'stipulate', 2315: 'endorses', 2316: 'rise,', 2317: 'explain', 2318: 'leading', 2319: 'flow', 2320: 'online,', 2321: 'Armed', 2322: 'foresees', 2323: 'states.', 2324: 'wage', 2325: 'continue', 2326: 'Miracle', 2327: 'overdue', 2328: 'points', 2329: '29', 2330: 'Elvis', 2331: 'receiving', 2332: 'made', 2333: 'store]', 2334: 'amendments,', 2335: 'Bauskas', 2336: 'serious', 2337: 'law', 2338: 'than', 2339: 'very', 2340: 'early', 2341: 'countries,"', 2342: 'question,"', 2343: 'filthy', 2344: 'Washington', 2345: 'stop', 2346: 'US', 2347: '1:1).', 2348: 'rule,', 2349: "Praag's", 2350: 'operation', 2351: 'killed.', 2352: 'pilot', 2353: 'bilateral', 2354: "center's", 2355: 'historical', 2356: '10,366', 2357: 'Games.', 2358: 'friends', 2359: '"A', 2360: 'living', 2361: 'days', 2362: 'Latvia', 2363: 'done', 2364: 'nuclear', 2365: 'because', 2366: 'AFP:', 2367: '1,300', 2368: 'venture', 2369: '7.6', 2370: 'assessed', 2371: 'unanimously', 2372: 'connecting', 2373: 'associations', 2374: 'legislation,', 2375: 'USD', 2376: 'values', 2377: 'Juberte-Krumina,', 2378: 'height', 2379: 'convenient', 2380: 'September', 2381: 'implementation', 2382: 'amendments', 2383: 'post-Brexit,', 2384: 'crisis', 2385: 'heated', 2386: 'officials', 2387: 'significant', 2388: 'net', 2389: 'institute', 2390: 'years', 2391: 'what', 2392: 'Brice', 2393: 'threatening', 2394: 'former', 2395: 'halted', 2396: 'connected', 2397: 'into', 2398: 'complementary', 2399: 'idea', 2400: 'police.', 2401: 'people"', 2402: '(NLA)', 2403: 'waters.', 2404: 'Presidential', 2405: 'laid', 2406: 'logistical,', 2407: 'office', 2408: 'aviation.', 2409: 'improve', 2410: 'HQ', 2411: 'more', 2412: 'contributed', 2413: 'open', 2414: 'Baltcom', 2415: 'Thursday', 2416: '828,', 2417: 'told', 2418: 'Partners,', 2419: 'contacted', 2420: 'envisage', 2421: 'Rozenberga', 2422: 'wealthy', 2423: 'Summit', 2424: 'procurements,', 2425: 'University', 2426: 'reporters', 2427: 'crossing', 2428: 'exports', 2429: 'institutions.', 2430: 'of', 2431: 'order.', 2432: 'barrels;', 2433: 'always', 2434: '1.425', 2435: 'found', 2436: 'supported', 2437: 'bronze', 2438: 'Our', 2439: 'opportunity', 2440: 'Jorge', 2441: '(but)', 2442: 'hope', 2443: 'themselves', 2444: "Chancellery's", 2445: 'satisfied', 2446: 'natural', 2447: 'employees.', 2448: 'speculated', 2449: 'where', 2450: 'Alexander', 2451: 'balance:', 2452: 'interview', 2453: 'losses', 2454: 'pimps.', 2455: 'His', 2456: 'weeks.', 2457: 'last', 2458: 'assess', 2459: "prosecutor's", 2460: 'approximately', 2461: 'Seima', 2462: 'weekend.', 2463: 'Average', 2464: '14-4', 2465: 'west,', 2466: 'traditionally', 2467: "Lithuania's", 2468: 'most', 2469: 'Confederation', 2470: 'capabilities', 2471: 'deemed', 2472: 'Providence', 2473: 'pointed', 2474: 'express', 2475: 'School,', 2476: 'return', 2477: 'life,', 2478: 'Council', 2479: 'teenage', 2480: 'reiterates', 2481: 'festival.', 2482: 'rate', 2483: 'King', 2484: '18', 2485: 'Aleksandrs', 2486: 'cases', 2487: 'through', 2488: 'Hungarian', 2489: 'Millennium', 2490: 'simply', 2491: 'Russia.', 2492: 'Piatek,', 2493: 'coordination', 2494: 'Ina', 2495: 'mourning.', 2496: 'investments', 2497: 'dynamics,', 2498: 'Given', 2499: 'powder', 2500: 'dry,', 2501: 'sees', 2502: 'budget,', 2503: 'remain', 2504: '2018,', 2505: 'investigative', 2506: 'One', 2507: 'kindergartens', 2508: 'Olekas', 2509: 'previous', 2510: "''In", 2511: 'Minister', 2512: 'young', 2513: 'say', 2514: 'Region,', 2515: 'reported', 2516: '1:0,', 2517: 'already.', 2518: 'Investment', 2519: 'indicate', 2520: 'visits', 2521: 'funding', 2522: 'credence', 2523: 'medal', 2524: 'fly', 2525: 'offensive', 2526: 'sends', 2527: 'increasingly', 2528: 'reasons"', 2529: 'press', 2530: 'cooler', 2531: 'Union', 2532: 'difficult', 2533: 'would', 2534: 'Justice', 2535: 'owners', 2536: 'critically', 2537: 'their', 2538: 'been', 2539: 'peace,"', 2540: 'Antetokounmpo', 2541: 'STRASBOURG,', 2542: 'jets,', 2543: 'Berzins', 2544: 'principles', 2545: '2:3', 2546: 'those', 2547: 'Fridenberga-Kalnina,', 2548: 'conversation', 2549: 'loss.', 2550: 'communication', 2551: 'couple', 2552: 'Wilbur', 2553: 'Startups', 2554: 'gradually', 2555: 'legalize', 2556: 'or', 2557: 'psychology.', 2558: 'turn', 2559: '500', 2560: 'land', 2561: 'access', 2562: 'slipped'}
{'investigation': 0, 'Monday,': 1, 'line.': 2, 'remove': 3, '0.6': 4, 'I': 5, 'Gamma': 6, 'Regional': 7, 'every': 8, 'Saeima': 9, 'sustainability': 10, 'curb': 11, 'raw': 12, 'Chancellery': 13, '"it': 14, '"One': 15, 'plane': 16, 'philosopher.': 17, 'passed': 18, 'respectable': 19, 'San': 20, '25.': 21, 'customs': 22, 'both': 23, '4,000.': 24, 'economics': 25, 'that,': 26, 'Fijalek/Prudel': 27, 'informed,': 28, 'basis,': 29, 'period': 30, 'compared': 31, 'go': 32, 'Commission': 33, 'downward': 34, 'Institute': 35, 'Baltstor,': 36, 'Latenaite': 37, 'with': 38, 'and': 39, 'and...': 40, 'value': 41, 'turned': 42, 'Transcontainer': 43, 'Phytosanitary': 44, 'favorable': 45, 'Mezeckis': 46, 'ambassador,': 47, 'partner': 48, 'fuel': 49, 'aim': 50, 'provide': 51, 'milk': 52, 'illegal': 53, 'regional': 54, 'downed': 55, 'regions,': 56, 'run': 57, 'aims': 58, 'inspect': 59, 'forces,': 60, 'content': 61, 'Transport': 62, 'used': 63, 'cooperation".': 64, 'Ministry.': 65, 'August': 66, 'diplomatic': 67, 'illegitimate': 68, 'Alliance),': 69, 'solutions': 70, 'Nations,': 71, 'process.': 72, 'remain,': 73, 'Sergio': 74, 'portfolio': 75, 'construction,': 76, 'percent,': 77, 'Eurimages,': 78, '0.1': 79, 'not,': 80, 'stressed': 81, '1,709': 82, 'grow': 83, 'U.S.-led': 84, 'deployment,': 85, 'affirm': 86, 'reduction': 87, '2017.': 88, 'interests': 89, 'Milwaukee': 90, 'in.': 91, 'prostitutes': 92, 'First': 93, 'invitation': 94, 'legislative': 95, 'China': 96, 'Festival,': 97, 'partially': 98, 'planning,': 99, 'borders,': 100, 'industry,': 101, 'featuring': 102, 'change': 103, 'lost': 104, 'weeks': 105, 'Mattarella,': 106, 'percent': 107, 'Rothschild': 108, 'A': 109, 'processes': 110, '1.7': 111, 'authorize': 112, 'annexation': 113, 'Grande,': 114, 'Rail,': 115, "EU's": 116, 'Dzelzcela': 117, 'goals.': 118, 'reading': 119, 'observers': 120, 'collapsed': 121, 'Little': 122, 'That': 123, 'Inga': 124, 'contracts,': 125, 'ambassador': 126, 'electrified': 127, 'standard': 128, 'day': 129, 'including': 130, 'Locomotive': 131, 'could': 132, 'launched': 133, 'half': 134, 'result': 135, 'coming': 136, 'Rosselkhoznadzor': 137, 'transportation': 138, 'co-owners': 139, 'registered': 140, 'Henins': 141, 'first': 142, 'just': 143, '14': 144, 'Of': 145, '20': 146, 'had': 147, 'release': 148, 'Juncker': 149, 'employ': 150, 'Control': 151, 'movement': 152, 'dead': 153, 'provider': 154, 'results': 155, 'Silicon': 156, 'Dutch': 157, 'discuss': 158, "''However,": 159, 'security,': 160, 'lot': 161, 'Mariusz': 162, 'gap': 163, 'telecommunications': 164, 'Citizens': 165, 'feel': 166, 'corridor': 167, 'time': 168, 'lifestyle': 169, 'shows': 170, '5': 171, 'Latvia,': 172, 'circumstances.': 173, 'immigrant,': 174, 'properties': 175, 'grabbed': 176, 'adjust': 177, 'view': 178, 'out.': 179, 'say.': 180, 'post': 181, 'Kaunas,': 182, 'which': 183, 'Luxembourg': 184, 'short': 185, 'project,': 186, 'premiere': 187, 'Friday,': 188, 'salary': 189, 'means': 190, 'Smiltena': 191, 'Since': 192, 'longer': 193, "today's": 194, 'hour.': 195, 'Six': 196, 'salaries,': 197, 'negotiations': 198, 'interested': 199, 'providing': 200, 'London': 201, 'pushed': 202, 'elections': 203, '34': 204, 'impoverished': 205, 'Vilnius': 206, '(0:0,': 207, 'expropriation': 208, 'nature': 209, 'workers': 210, 'Education': 211, '72.8': 212, 'rose': 213, 'necessity': 214, 'whether': 215, '(OPEC)': 216, 'do,': 217, 'purchases': 218, 'shafts': 219, 'Ivars': 220, 'immediately': 221, 'SkenarioLabs': 222, 'van': 223, 'adding': 224, 'October': 225, 'inspections.': 226, 'Officials': 227, 'heat-up': 228, 'meeting,': 229, 'candidacy': 230, 'positions': 231, 'OPEC?': 232, 'support': 233, 'respective': 234, 'reminds': 235, 'LUXEMBOURG,': 236, 'detail': 237, 'unanimity.': 238, 'then': 239, 'asked': 240, 'borders': 241, 'Goldman': 242, 'Irving': 243, 'level': 244, '(Want': 245, 'Commerce': 246, 'million': 247, 'increased': 248, 'confirmed': 249, 'officer.': 250, 'Uldis': 251, 'Cavs': 252, 'Baltic': 253, 'allowed': 254, 'Surveillance': 255, '(Rosselkhoznadzor)': 256, 'sooner': 257, 'Raimonds': 258, 'Donald': 259, 'building': 260, 'registering': 261, 'enterprises': 262, 'economy,': 263, 'effort': 264, 'Praag': 265, 'States': 266, 'fully': 267, "Trump's": 268, 'way': 269, 'Rimsevics': 270, 'opened': 271, 'confident': 272, 'TORONTO,': 273, '"There': 274, 'black': 275, 'volleyball': 276, 'northerly': 277, 'and,': 278, 'beach': 279, 'Steven': 280, 'Nov': 281, 'Service,': 282, 'Sea': 283, 'You': 284, 'structural': 285, 'festival': 286, 'framework': 287, 'jobs,': 288, "Service's": 289, 'Jean-Claude': 290, 'Environment,': 291, 'euro,': 292, 'night,': 293, 'From': 294, 'around': 295, 'deals': 296, 'budget': 297, '"If': 298, 'take': 299, 'circumstances': 300, 'Equity': 301, 'owner': 302, 'Amaq': 303, 'tear': 304, 'childhood': 305, 'Karavela,': 306, 'who': 307, 'remuneration': 308, 'affected': 309, 'consumer': 310, 'Out': 311, 'President-elect': 312, 'rain': 313, 'envisages': 314, 'intermodal': 315, 'fighter': 316, 'caused': 317, 'let': 318, 'interview.': 319, 'matters,': 320, 'halt': 321, 'Meeuwsen,': 322, 'exchange': 323, "Jong-Un's": 324, 'revived,': 325, 'voted': 326, 'led': 327, 'firm': 328, 'worry': 329, 'Foreign': 330, 'Science': 331, 'is': 332, 'economic': 333, 'highly': 334, 'struggling': 335, 'unprecedented': 336, 'allow': 337, 'diaspora': 338, 'painful': 339, 'positive': 340, '3:1': 341, 'expropriated': 342, 'an': 343, 'three': 344, 'growing': 345, 'production,': 346, 'transition': 347, 'Swedish': 348, 'top': 349, 'expanding': 350, 'IKEA': 351, 'League': 352, 'discussed,': 353, 'warships': 354, 'film,': 355, '2007),': 356, 'common': 357, 'on': 358, 'developing': 359, 'completed': 360, 'Stanevics,': 361, 'development.': 362, 'format': 363, 'letters': 364, 'reforms,': 365, 'MPs': 366, 'tomorrow,': 367, 'Brice.': 368, 'Food': 369, '9,000.': 370, 'region.': 371, 'organization': 372, 'bring': 373, 'believing': 374, "state's": 375, 'Kenins': 376, 'assists': 377, 'coalition': 378, 'planes': 379, 'up': 380, 'marks': 381, 'bureaucrats,': 382, "festival's": 383, 'EU': 384, 'good': 385, 'territorial': 386, 'am': 387, 'quite': 388, 'Riga,': 389, 'media': 390, 'transponders': 391, 'July': 392, 'No': 393, 'Murniece': 394, 'tax': 395, '28.5': 396, 'decided': 397, 'Temps': 398, 'Solidarity': 399, 'optimal,': 400, 'conducted': 401, 'reacting': 402, 'areas': 403, 'moving': 404, 'startup': 405, 'proposal': 406, 'company.': 407, 'world.': 408, 'ambitions': 409, 'Russian': 410, 'transportation.': 411, 'less': 412, 'stricter': 413, 'referendum': 414, 'agreed': 415, '2016': 416, 'Valley': 417, 'brands.': 418, '(AFP)': 419, '200': 420, 'were': 421, 'once': 422, 'our': 423, 'salaries': 424, 'Everything': 425, 'delves': 426, 'memories.': 427, 'skill': 428, 'representative': 429, 'foundations': 430, 'winner': 431, 'universities,': 432, 'agrees': 433, 'north': 434, 'brothels,': 435, 'lost.': 436, 'extend': 437, '4.2': 438, 'Economic,': 439, 'helps': 440, '"in': 441, 'qualify': 442, 'residents': 443, '885.': 444, 'Surname': 445, 'temps': 446, 'certified': 447, 'performance.': 448, '168.803': 449, 'periods,"': 450, 'preschools.': 451, 'to': 452, 'level.': 453, '24': 454, 'football': 455, 'community': 456, 'stipulated': 457, 'Edgars': 458, 'upcoming': 459, 'communications': 460, 'drive': 461, 'organized': 462, '0.03': 463, 'give': 464, 'illegally': 465, 'draft': 466, 'Ilze': 467, 'at': 468, 'success': 469, '10,979': 470, 'Janis': 471, 'Samoilovs': 472, 'military': 473, 'authorities,': 474, 'price': 475, '1,': 476, 'business': 477, 'active': 478, 'Finland': 479, 'decisions': 480, 'Andris': 481, 'communique': 482, 'rivals.': 483, 'went': 484, 'turning': 485, 'appointment.': 486, 'amounted': 487, 'over': 488, 'Antetokounmpo,': 489, 'industrial': 490, 'world,': 491, 'sustainable': 492, 'year-round': 493, 'shortages:': 494, 'probe': 495, 'ATHENS,': 496, 'Group': 497, 'Hague,': 498, 'planning': 499, 'U.S.': 500, 'talks': 501, '1.2': 502, 'prospective': 503, 'clean': 504, '2-1': 505, 'ready,': 506, 'domestic': 507, 'Association': 508, 'August,': 509, 'solution': 510, 'material': 511, 'River': 512, 'proportional,': 513, '2012,': 514, 'states': 515, '0.4': 516, 'development': 517, "Eurostat's": 518, 'approach,': 519, '$700': 520, 'Security': 521, 'Driksna,': 522, 'carried': 523, 'complete': 524, 'beginning': 525, 'Revenue': 526, 'Iraqi': 527, 'food': 528, 'opening': 529, 'Lewis,': 530, 'university': 531, 'Cleveland': 532, 'Rosberg': 533, 'economy': 534, 'voluntary': 535, 'wished': 536, 'adding:': 537, '0.3': 538, 'Ilmars': 539, 'inflation': 540, "he's": 541, "Netherlands'": 542, 'needy': 543, 'lack': 544, 'Ambassador': 545, 'reviewed': 546, 'worth': 547, 'provides': 548, 'rail': 549, 'neutral': 550, 'wages': 551, 'Canada': 552, '4,030,': 553, 'depended': 554, 'today.': 555, 'review': 556, 'fight': 557, '13': 558, 'Both': 559, '0:2,': 560, 'According': 561, 'individual': 562, 'congratulated': 563, 'opportunities': 564, 'rights.': 565, 'morning.': 566, 'World': 567, 'further': 568, 'tackling': 569, 'consumers': 570, '21,': 571, 'process': 572, 'national': 573, "countries'": 574, 'someone': 575, 'UEFA': 576, 'closer': 577, '1.': 578, 'increasing': 579, 'governments': 580, '15': 581, 'transport': 582, "Latvia's": 583, 'regard': 584, 'his': 585, 'deflation,': 586, 'retailers': 587, 'occupied': 588, 'supervision': 589, 'schools': 590, 'foreigners.': 591, 'border': 592, 'embark': 593, 'Spain,': 594, 'canneries.': 595, 'modern': 596, 'short-term': 597, 'issues': 598, 'carrying': 599, 'justice,"': 600, 'reading,': 601, 'folly': 602, '"It': 603, 'kilogram.': 604, "Finland's": 605, 'group': 606, 'meteorologists': 607, 'Defense': 608, 'results.': 609, 'sewage': 610, 'flexibly': 611, 'emphasized.': 612, 'B': 613, 'suspicious': 614, 'Langnau': 615, 'dramatically': 616, 'product,': 617, 'million,': 618, 'end': 619, 'analysis': 620, 'programmes,': 621, 'investigations': 622, 'terms"': 623, 'links.': 624, 'presented': 625, 'Vejonis': 626, 'funds': 627, 'Inc': 628, 'ongoing,': 629, 'presence': 630, 'sensitive': 631, 'ascertained': 632, 'cents': 633, '150': 634, 'invest': 635, 'Brouwer': 636, 'he': 637, 'may': 638, 'said': 639, 'Independent': 640, '"catastrophic"': 641, '27': 642, 'money': 643, 'production.': 644, 'survived': 645, 'Riga': 646, 're-established': 647, 'relatively': 648, 'receives': 649, 'synchronization': 650, 'relations': 651, '17': 652, 'protect': 653, 'steeper': 654, 'lived': 655, 'miners': 656, 'facilitate': 657, 'Competition': 658, 'canneries': 659, 'bordering': 660, 'SITE': 661, "''We": 662, 'won': 663, 'Belgium,': 664, 'centennial': 665, 'stops.': 666, '(Unity)': 667, '"He': 668, 'weeks,': 669, 'ensure': 670, 'confidential': 671, 'Tour': 672, 'reformed,': 673, 'century': 674, 'strict': 675, 'Two': 676, 'operates': 677, 'informed': 678, 'sold': 679, 'received': 680, 'provision': 681, 'compromised.': 682, 'SEB': 683, 'suggests': 684, 'meaning': 685, 'two': 686, 'URGENT:': 687, 'help': 688, 'they': 689, 'story,': 690, 'challenges': 691, 'basic': 692, 'today,': 693, 'Tax': 694, 'according': 695, 'animal': 696, '10': 697, '19%': 698, 'these': 699, 'council.': 700, 'target': 701, 'are': 702, 'particularly': 703, 'named': 704, 'Slovakia': 705, 'approaching': 706, 'relationship': 707, 'acquire': 708, "Pyongyang's": 709, 'academic': 710, 'belongs': 711, 'Local': 712, 'came': 713, 'along': 714, 'any': 715, 'Furthermore,': 716, 'month-on-month,': 717, 'there': 718, 'hashtagged': 719, 'talking': 720, 'inform': 721, 'ceremony': 722, 'want.': 723, 'Sept': 724, 'Lita': 725, 'Mohamed': 726, 'presentations': 727, 'coal': 728, 'joined': 729, 'Ross,': 730, 'Rpax': 731, 'freedom,': 732, 'operator': 733, 'anniversary.': 734, 'defend': 735, 'rebounds': 736, 'groups': 737, 'increase': 738, 'language,': 739, "'Mosul": 740, 'Europol': 741, 'Funderful,': 742, 'memorandum': 743, 'declined': 744, 'Tuesday,': 745, 'since': 746, 'current': 747, 'its': 748, 'regulations': 749, 'saying.': 750, 'get': 751, 'service': 752, 'other': 753, 'consolidated': 754, '"disastrous".': 755, '"When': 756, 'offered': 757, 'combined': 758, 'decline.': 759, 'possibility': 760, 'Russia': 761, 'enough': 762, 'Cavaliers.': 763, 'dream,': 764, 'month.': 765, 'finance': 766, '14.3': 767, 'Ieva': 768, 'degrees': 769, 'Euro-Atlantic': 770, 'informs': 771, 'inspections': 772, 'India,': 773, 'aspects': 774, '57%': 775, 'regions': 776, 'homework': 777, 'contact': 778, 'dramatic': 779, 'humanitarian': 780, 'decision': 781, 'September,': 782, 'urgent': 783, 'disputed': 784, 'Elzbieta': 785, 'airspace': 786, 'Budapest.': 787, 'reporting': 788, 'macroeconomic': 789, 'Belarus': 790, 'year': 791, 'risks': 792, 'pitching': 793, 'title': 794, 'collection': 795, 'City': 796, 'poverty': 797, 'pimping': 798, '15:9)': 799, 'milk;': 800, 'LI': 801, 'forwarded': 802, 'partners,': 803, 'potentially': 804, 'Public': 805, 'positive,': 806, 'depend': 807, 'increased.': 808, 'important': 809, 'extended': 810, 'Ozols': 811, "''Little": 812, 'excellent': 813, 'opportunities.': 814, 'prime': 815, 'Baskakov': 816, 'actually': 817, '(out)': 818, 'Productions,': 819, 'education': 820, 'set': 821, 'chain,': 822, "''It": 823, 'crediting': 824, '1:1,': 825, 'upon': 826, 'Rio': 827, 'election': 828, 'team': 829, 'River,': 830, 'euro': 831, 'civil': 832, 'escape.': 833, 'Vienna': 834, 'Baltic-Benelux': 835, 'broke': 836, 'general-secretary': 837, 'water.': 838, 'Welfare': 839, 'Anda': 840, 'technology': 841, 'Some': 842, 'fact': 843, 'Football': 844, 'cooler,': 845, 'Normunds': 846, 'look': 847, 'local': 848, '1,000': 849, 'Tuesday': 850, '9.': 851, 'Western': 852, "Seneca's": 853, 'United': 854, 'finding': 855, 'ball': 856, 'especially': 857, 'new': 858, 'Samoilovs/Smedins': 859, 'Federal': 860, 'Speaking': 861, '17.2': 862, 'Petr': 863, 'Duma': 864, 'billion.': 865, 'guard': 866, 'GribuTeviAtpakal': 867, 'parents,"': 868, 'crash': 869, 'might': 870, 'underground,': 871, 'disturbed': 872, 'international': 873, 'case': 874, 'debts': 875, 'several': 876, 'presents': 877, 'system.': 878, 'transportation,': 879, 'embassy': 880, 'sides': 881, 'Inara': 882, 'contribution': 883, 'system': 884, 'promised': 885, 'permit': 886, 'State': 887, "employees'": 888, 'side': 889, 'find': 890, 'Oxford': 891, 'children,': 892, 'diversification': 893, 'have': 894, 'clients': 895, 'close': 896, 'benefit': 897, 'high': 898, 'Poland': 899, 'postponed': 900, 'technology,': 901, 'Remuneration': 902, 'June,': 903, 'Commonwealth': 904, 'radio': 905, '801': 906, 'Martins': 907, 'submarines': 908, 'Heroes’': 909, 'strengthens': 910, 'Wednesday.': 911, 'percent.': 912, 'speak': 913, "IKEA's": 914, 'Press': 915, 'Mazunas,': 916, 'bankers': 917, 'face': 918, 'planes,': 919, 'collected': 920, 'followed': 921, 'Foundation': 922, 'Exporting': 923, 'later,': 924, 'recent': 925, 'reopened': 926, 'undercut': 927, 'future,"': 928, 'Record,': 929, 'feels': 930, 'She': 931, 'against.': 932, 'are,"': 933, 'total': 934, 'warm': 935, 'Marija': 936, '(dpa)': 937, "ministry's": 938, 'old': 939, '(Hosök': 940, 'coordinator': 941, 'voting': 942, 'extremists.': 943, 'people,': 944, 'strengthening': 945, 'mine': 946, 'goalie': 947, 'efficient.': 948, 'version': 949, 'faster': 950, 'warned': 951, "that's": 952, 'brand.': 953, 'Europe.': 954, 'trade': 955, 'Service.': 956, 'sovereignty': 957, 'Augulis': 958, 'resolve': 959, 'unchanged.': 960, 'Kim,': 961, 'contradiction': 962, 'plan': 963, "Switzerland's": 964, 'soldiers': 965, 'off,': 966, '2016,': 967, 'accidentally': 968, 'Michael': 969, 'political': 970, 'Twenty-two': 971, '622,': 972, 'Europe,': 973, 'solely': 974, 'board': 975, 'Radio': 976, 'Policy': 977, 'should': 978, 'citizens': 979, 'government': 980, 'down': 981, 'billion': 982, "citizens'": 983, 'that"we': 984, 'implement': 985, 'Nationality': 986, 'origin.': 987, 'Iran': 988, 'before': 989, 'Prudel': 990, 'organizations.': 991, 'under': 992, 'August.': 993, 'much': 994, 'countries': 995, 'conditions': 996, 'growth': 997, 'Dainius': 998, 'fix': 999, 'spent': 1000, 'property,': 1001, 'prove': 1002, 'Organization': 1003, 'head': 1004, 'Russia,': 1005, 'moment,': 1006, 'Funderfun': 1007, 'names': 1008, 'previously': 1009, 'today': 1010, 'possible': 1011, 'eurozone': 1012, 'disastrous,': 1013, 'supervisory': 1014, 'able': 1015, 'amount': 1016, 'Square': 1017, 'norms': 1018, 'Eiropas': 1019, 'if': 1020, 'temperatures': 1021, 'tighten': 1022, 'accelerator': 1023, 'Authorities': 1024, 'public.': 1025, 'railway': 1026, 'Marijus': 1027, 'leads': 1028, 'SkenarioLab': 1029, 'connections': 1030, 'relations.': 1031, 'zero': 1032, 'Kindercatering,': 1033, 'want': 1034, 'procurements.': 1035, 'signed': 1036, 'regarding': 1037, 'regime': 1038, 'milk,': 1039, 'deliberation': 1040, 'Lithuania': 1041, "company's": 1042, 'economy,"': 1043, 'him,"': 1044, '301': 1045, 'Mosul': 1046, 'agreement,"': 1047, 'budgets': 1048, 'official': 1049, 'cut': 1050, 'accepted': 1051, 'was': 1052, 'Banka': 1053, 'Ronalds': 1054, 'served': 1055, 'time,': 1056, 'percent)': 1057, '32': 1058, 'proposals': 1059, 'payment': 1060, 'spokeswoman': 1061, 'remained': 1062, 'electricity.': 1063, 'model': 1064, 'debt': 1065, 'law,"': 1066, 'NATO’s': 1067, 'pace': 1068, '"Latvian".': 1069, 'states,': 1070, 'Over': 1071, 'provided': 1072, 'notches': 1073, 'cable': 1074, 'pharmaceuticals,': 1075, 'against': 1076, '500,000': 1077, 'ran': 1078, '"Nearly': 1079, 'transatlantic': 1080, 'day,': 1081, 'program': 1082, 'adequate': 1083, 'latest': 1084, "Employers'": 1085, 'even': 1086, 'successful': 1087, 'visited': 1088, 'frustrated': 1089, 'certainly': 1090, 'administration': 1091, 'deterrent.': 1092, 'eastern': 1093, 'condition': 1094, 'status': 1095, 'winners': 1096, '11': 1097, '"This': 1098, 'Following': 1099, '"We': 1100, 'indication"': 1101, 'Lise': 1102, 'Studio': 1103, 'Vision': 1104, 'security': 1105, 'when': 1106, 'stunned': 1107, 'reform': 1108, 'monitors': 1109, 'additional': 1110, 'two-lane': 1111, 'chief': 1112, 'expand': 1113, '"key': 1114, 'Manabalss.lv': 1115, 'refugee': 1116, 'one.': 1117, 'late': 1118, 'class,': 1119, 'grocery': 1120, 'per': 1121, 'together': 1122, 'regards': 1123, 'Countries': 1124, '7.3': 1125, 'president,': 1126, 'you': 1127, 'peace': 1128, 'General': 1129, 'begin': 1130, 'suffered': 1131, '31': 1132, 'year;': 1133, 'green-technologies': 1134, 'last"': 1135, '30,': 1136, 'alliance': 1137, 'women': 1138, 'Aiva': 1139, 'production': 1140, 'in-depth': 1141, 'necessary': 1142, 'Gavenonis,': 1143, 'agreement': 1144, 'following': 1145, 'Bucks': 1146, 'remaining': 1147, 'weapons': 1148, 'source': 1149, 'power': 1150, 'general': 1151, 'Mego': 1152, 'output': 1153, 'counterpart': 1154, 'again': 1155, 'benefits': 1156, 'play': 1157, 'cooperation': 1158, 'focus': 1159, 'Tigers': 1160, 'Crimea': 1161, 'battle': 1162, "Punnenovs'": 1163, 'many': 1164, 'work': 1165, 'producers': 1166, 'employees': 1167, 'billion,': 1168, 'growth.': 1169, 'stars': 1170, 'bit,"': 1171, 'Lugano': 1172, 'culture,': 1173, "Korea's": 1174, 'invited': 1175, 'region,"': 1176, 'Agnis': 1177, 'Sachs,': 1178, 'project.': 1179, 'Name,': 1180, 'active,"': 1181, 'methods': 1182, 'Sabiedriba': 1183, 'the': 1184, "Estonia's": 1185, 'explained': 1186, 'compliance': 1187, 'predicting': 1188, 'startups': 1189, 'evaluation': 1190, 'Mnuchin,': 1191, 'signature': 1192, '22:24,': 1193, 'principle': 1194, '1.035': 1195, 'participate': 1196, 'educated': 1197, 'selling': 1198, 'RIGA,': 1199, 'must"come': 1200, 'projects,': 1201, 'agenda': 1202, 'responsibilities': 1203, 'Republic': 1204, 'comments': 1205, 'strategic': 1206, 'having': 1207, "''Yet": 1208, 'Warsaw.': 1209, 'red-faced': 1210, 'implementing': 1211, 'postpones': 1212, 'months': 1213, 'experts': 1214, 'himself': 1215, 'Produced': 1216, 'Internet': 1217, '(LI)': 1218, 'violated': 1219, 'later.': 1220, 'position': 1221, '(EU)': 1222, 'online': 1223, 'Without': 1224, 'un-collectable': 1225, 'Europe': 1226, 'Brazil': 1227, 'but': 1228, "Pandora's": 1229, 'much.': 1230, 'topic': 1231, '(0:1,': 1232, 'Krievins': 1233, 'speed': 1234, 'Due': 1235, 'Eurostat': 1236, "concern's": 1237, 'interesting': 1238, 'now': 1239, 'response': 1240, 'November': 1241, 'stores': 1242, 'hard.': 1243, 'Development': 1244, 'we': 1245, 'assessing': 1246, 'lone': 1247, 'January,': 1248, 'starting': 1249, 'freight': 1250, 'legalization': 1251, 'operating': 1252, 'supports': 1253, 'corvette': 1254, 'condemns': 1255, 'Smedins': 1256, 'Transportation': 1257, 'Signatures': 1258, 'such': 1259, 'Department': 1260, 'ships': 1261, 'earlier.': 1262, 'afternoon,': 1263, 'share': 1264, 'competitive': 1265, 'expressed': 1266, 'learned': 1267, 'innovative': 1268, 'titled': 1269, 'line': 1270, 'this,': 1271, 'use': 1272, 'At': 1273, "nation's": 1274, 'explosion.': 1275, 'relationship.': 1276, 'owned': 1277, 'included': 1278, 'reducing': 1279, 'belonging': 1280, 'six': 1281, '39': 1282, 'believes': 1283, 'representatives': 1284, 'Business': 1285, 'emphasized': 1286, 'deflation': 1287, '"Unfortunately,': 1288, 'President': 1289, 'various': 1290, "Agency's": 1291, 'night': 1292, 'LETA': 1293, 'Digital': 1294, 'east': 1295, 'interests,"': 1296, 'Treasury': 1297, 'wishes.': 1298, 'tested': 1299, 'fish': 1300, 'efficiently': 1301, 'Canadian': 1302, 'however,': 1303, 'Amrion': 1304, 'working': 1305, 'categories': 1306, 'police': 1307, 'productivity': 1308, 'Freedom': 1309, 'noted': 1310, 'wish': 1311, 'universities.': 1312, '1989,': 1313, 'export': 1314, 'least': 1315, 'ago': 1316, 'Uljana': 1317, 'families': 1318, 'compensated.': 1319, 'supply-side': 1320, 'constituencies': 1321, 'distributions': 1322, 'solidarity,': 1323, 'economists': 1324, 'manager': 1325, 'UEFA,': 1326, 'Federation': 1327, 'survey.': 1328, 'do': 1329, 'All': 1330, 'Canadian-led': 1331, 'ZSC': 1332, 'pollution': 1333, 'ensuring': 1334, 'developed': 1335, 'ways': 1336, 'These': 1337, 'Italy': 1338, 'this': 1339, 'CIA': 1340, 'thousands': 1341, 'Muslims': 1342, 'process,': 1343, 'continued': 1344, 'originally': 1345, 'regular': 1346, 'match': 1347, 'Today,': 1348, 'agricultural': 1349, 'Vance,': 1350, 'disillusionment': 1351, 'test': 1352, 'Purchases': 1353, 'film': 1354, 'did': 1355, '"no': 1356, 'container': 1357, 'available': 1358, 'handed': 1359, 'yet': 1360, 'delivery': 1361, 'Nations': 1362, 'well': 1363, 'student,': 1364, 'Merzlikins': 1365, 'oil': 1366, 'member': 1367, '(Greens/Farmers)': 1368, 'bill,': 1369, 'dialogue': 1370, 'restricting': 1371, 'transport,': 1372, 'months,': 1373, 'shot': 1374, 'real-estate': 1375, 'debts,': 1376, 'compatriots': 1377, 'Eurasian': 1378, 'level,': 1379, 'inspectors': 1380, 'different': 1381, 'Vejonis.': 1382, 'correction': 1383, 'months.': 1384, 'Venice.': 1385, '2.3': 1386, 'infrastructure.': 1387, 'place': 1388, 'mainly': 1389, 'still': 1390, 'incident': 1391, 'above,': 1392, 'Firmas.lv.': 1393, 'substantial': 1394, 'However,': 1395, 'endeavours': 1396, '0.5': 1397, 'Karlis': 1398, 'predicts': 1399, 'step': 1400, 'connection': 1401, 'headquartered': 1402, 'catering': 1403, 'On': 1404, 'estimated': 1405, 'priority': 1406, 'institution': 1407, 'year,': 1408, 'below': 1409, 'Roman': 1410, 'CEO': 1411, 'applied': 1412, 'In': 1413, 'Procurement': 1414, 'a': 1415, 'deal': 1416, 'Total': 1417, 'expected.': 1418, 'situation': 1419, 'economy.': 1420, 'highlighted': 1421, 'Zealand': 1422, 'products': 1423, 'while': 1424, 'approved': 1425, 'enough,"': 1426, 'attitude,': 1427, 'it.': 1428, 'recognized,"': 1429, 'that"due': 1430, 'India.': 1431, 'inside': 1432, 'Greece': 1433, 'London,': 1434, 'Hesztera': 1435, 'unity,': 1436, 'wolf': 1437, 'region': 1438, 'manufacturing': 1439, 'Economic': 1440, 'smallest': 1441, 'opened,': 1442, 'Sevastopol': 1443, "That's": 1444, 'far': 1445, 'Juozas': 1446, 'Secretary,': 1447, '"Our': 1448, '7': 1449, 'Krauze': 1450, 'criticism.': 1451, 'paper': 1452, 'emphasize': 1453, 'own': 1454, 'Investments': 1455, 'testing': 1456, 'maker': 1457, 'posted': 1458, 'submission': 1459, 'Luxembourg-registered': 1460, 'UN': 1461, '2:0,': 1462, 'discussions.': 1463, 'central': 1464, '2017,': 1465, 'missions': 1466, 'operational': 1467, 'accordingly.': 1468, 'fourth': 1469, 'Iraq.': 1470, 'expansion': 1471, 'make': 1472, 'NBA:': 1473, 'waters': 1474, 'RB': 1475, 'catastrophic,"': 1476, 'Committee': 1477, 'China.': 1478, 'offer': 1479, 'employers': 1480, 'eight': 1481, '"Regardless': 1482, 'problems': 1483, 'ports,': 1484, 'products,"': 1485, 'uniform': 1486, 'forest': 1487, 'Tirgotajs': 1488, '30': 1489, 'earthquake,"': 1490, 'Rinkevics': 1491, 'urging': 1492, 'tere)': 1493, 'public': 1494, 'North': 1495, 'Latvija,': 1496, '(+4.1': 1497, 'adequately': 1498, 'social': 1499, 'joint': 1500, 'report': 1501, 'one': 1502, 'forces': 1503, 'Dzelzcels': 1504, 'position,': 1505, 'injured': 1506, '--': 1507, 'also': 1508, 'defense.': 1509, 'Latvian': 1510, "n't": 1511, 'school': 1512, 'territories': 1513, 'nation': 1514, 'performance': 1515, 'IMS': 1516, 'stipulating': 1517, 'programme': 1518, 'Edvinds': 1519, 'little': 1520, 'integrity': 1521, 'situation,': 1522, 'crash.': 1523, 'Eurostat.': 1524, '2014': 1525, '(+5': 1526, 'procurement': 1527, 'high-speed': 1528, 'Kucinskis': 1529, 'company,': 1530, 'geographic': 1531, 'Benelux': 1532, 'known': 1533, 'us': 1534, 'submitted': 1535, 'belong': 1536, 'deployed': 1537, 'Mezeckis.': 1538, 'drinking': 1539, 'readings.': 1540, 'valid': 1541, 'five': 1542, 'Fijalek': 1543, 'only': 1544, 'duo': 1545, 'great,': 1546, 'reveal': 1547, 'This': 1548, 'earned': 1549, 'purchase': 1550, 'fear': 1551, 'Malta': 1552, 'solidarity,"': 1553, 'logistics': 1554, 'respect': 1555, '19': 1556, 'hometown': 1557, 'know': 1558, 'Meteorology': 1559, 'We': 1560, 'stake': 1561, 'alternative': 1562, 'interests.': 1563, 'call': 1564, 'hopes': 1565, 'Warsaw': 1566, 'external': 1567, '2015.': 1568, 'Bank': 1569, 'Estonia': 1570, 'Helsinki': 1571, 'fighter,': 1572, 'achieve': 1573, 'placing': 1574, 'air': 1575, 'It': 1576, 'strong': 1577, 'warns': 1578, 'protected': 1579, 'why': 1580, 'reconnaissance': 1581, 'tearing': 1582, 'ally': 1583, 'serve': 1584, '930.226': 1585, 'recorded': 1586, 'whole.': 1587, 'Lake': 1588, 'forecast': 1589, 'salary.': 1590, 'LeBron': 1591, 'John': 1592, 'year.': 1593, 'percent),': 1594, 'must': 1595, "cartel's": 1596, 'Festival': 1597, 'vessels.': 1598, 'Jonathan': 1599, 'exceeding': 1600, 'ripping': 1601, 'information': 1602, 'bringing': 1603, 'store': 1604, 'related': 1605, 'BERN,': 1606, 'part': 1607, 'autumn,': 1608, 'forward': 1609, '69,109': 1610, 'dealing': 1611, '322.259': 1612, 'June': 1613, 'Among': 1614, 'bridge,': 1615, 'Bankis,': 1616, 'Mezeckis,': 1617, 'dairy': 1618, 'needed,': 1619, 'Latvians': 1620, 'challenges,': 1621, 'felt': 1622, 'tech': 1623, 'Kristaps': 1624, 'Soviet': 1625, 'Petroleum': 1626, 'after': 1627, 'monthly': 1628, 'foresee': 1629, 'temperatures.': 1630, 'rise': 1631, 'countries.': 1632, 'turnover': 1633, 'authority': 1634, 'good.': 1635, 'National': 1636, 'join': 1637, 'reforms': 1638, 'diplomatically,': 1639, 'making': 1640, 'Slovenia': 1641, 'taking': 1642, 'aircraft': 1643, 'property': 1644, 'logistics.': 1645, 'Tallinn,': 1646, 'letter.': 1647, 'centers': 1648, 'reason': 1649, '18,': 1650, 'box': 1651, 'Ardian': 1652, '800': 1653, 'created': 1654, 'slows,': 1655, 'survivors': 1656, 'legislation.': 1657, 'contributions': 1658, 'stipulates': 1659, 'Jolanta': 1660, 'data': 1661, 'Center': 1662, 'Servette': 1663, 'billionaire': 1664, 'all': 1665, 'S.A.': 1666, 'seen': 1667, 'illegal,"': 1668, 'check': 1669, 'civilians,': 1670, 'that': 1671, 'consecutive': 1672, 'postponing': 1673, 'solidarity': 1674, 'Meistere,': 1675, 'matter': 1676, 'endorsed': 1677, 'post-war': 1678, 'bill': 1679, 'Lions': 1680, 'Khalil,': 1681, 'fifteen': 1682, 'greater': 1683, 'Antonio': 1684, 'brothels': 1685, 'rebounded': 1686, 'advisor': 1687, 'finances': 1688, 'apparently': 1689, 'proceed': 1690, 'Scandinavia': 1691, 'project,"': 1692, 'Forces.': 1693, 'Bartaite.': 1694, '16.77': 1695, 'everything,"': 1696, 'Thus': 1697, 'about': 1698, 'members': 1699, 'reduced': 1700, 'furniture': 1701, 'predict': 1702, "group's": 1703, 'faster,': 1704, '"I': 1705, 'Kindercatering': 1706, 'limitation': 1707, 'September.': 1708, 'attacks,': 1709, 'divided': 1710, 'person': 1711, 'Brussels,': 1712, '0.15': 1713, 'Colombian': 1714, 'record': 1715, 'Its': 1716, 'as': 1717, 'between': 1718, 'Wednesday': 1719, 'Linija,': 1720, "line's": 1721, 'Lenoka': 1722, 'think': 1723, 'appears': 1724, 'Majesty': 1725, 'sleep': 1726, '(+6.8': 1727, 'integration': 1728, '(similar': 1729, 'accreditation,': 1730, '15.': 1731, 'future': 1732, 'Kyrie': 1733, 'exporting': 1734, 'not': 1735, 'Meanwhile,': 1736, '3.9': 1737, 'annual': 1738, 'experts,': 1739, 'ca': 1740, 'Canada,': 1741, 'Agricultural,': 1742, 'As': 1743, 'Slocene': 1744, 'chain': 1745, 'be': 1746, 'has': 1747, 'stood': 1748, 'India': 1749, 'damage': 1750, 'saying,': 1751, 'experience': 1752, 'products,': 1753, 'If': 1754, 'line,': 1755, 'Slovenia,': 1756, 'third': 1757, 'your': 1758, 'Korea': 1759, '"They': 1760, 'beat': 1761, 'Estonian': 1762, 'School': 1763, 'added.': 1764, 'decide': 1765, 'Berlin': 1766, '#': 1767, 'during': 1768, 'Brennan': 1769, 'does': 1770, 'seminars': 1771, 'Bite': 1772, 'balance': 1773, 'seventh': 1774, 'pimping,': 1775, 'Latvijas': 1776, 'LETA,': 1777, 'mobile': 1778, 'wreath': 1779, 'key': 1780, 'using': 1781, 'defiance.': 1782, 'necessary.': 1783, 'unemployment': 1784, 'Czech': 1785, 'met': 1786, 'assessment': 1787, 'bought': 1788, 'Hungary’s': 1789, 'impact': 1790, '700': 1791, 'tariff': 1792, 'famous': 1793, 'well.': 1794, 'Grzegorz': 1795, 'alliance,': 1796, 'sanctions': 1797, '.""Both': 1798, 'statement.': 1799, 'voiced': 1800, 'conference': 1801, 'prohibit': 1802, 'assist': 1803, 'owing': 1804, '2:0).': 1805, '2014.': 1806, '872.525': 1807, '[IKEA': 1808, 'Criminal': 1809, 'Araja': 1810, "bloc's": 1811, 'Number': 1812, 'winds': 1813, 'betrayed': 1814, 'goods': 1815, 'frigate': 1816, 'test,': 1817, 'shame': 1818, 'adequate,': 1819, 'follow': 1820, '"live': 1821, 'insisted': 1822, '(+3.7': 1823, '(National': 1824, 'haunting': 1825, 'trustworthy': 1826, 'debtors': 1827, 'Kim': 1828, 'history': 1829, 'for': 1830, 'FIVB': 1831, 'competition': 1832, 'Monday': 1833, '4.4-magnitude': 1834, 'sure': 1835, 'steepest': 1836, '"very': 1837, 'thanks': 1838, 'earthquake': 1839, 'Speaker': 1840, 'So': 1841, 'earnings,': 1842, 'Zembla,': 1843, 'ideals': 1844, 'each': 1845, 'resident': 1846, 'sad': 1847, 'Rojas.': 1848, 'detailed': 1849, 'stand': 1850, 'fields,': 1851, 'overcome': 1852, 'Chief': 1853, 'visit': 1854, 'already': 1855, 'understand': 1856, 'in': 1857, 'force,"': 1858, 'Back),': 1859, '25': 1860, 'average': 1861, 'tempo': 1862, 'Vesko': 1863, 'Philippe': 1864, 'Taurina': 1865, 'will': 1866, 'Lithuanian': 1867, 'said.': 1868, 'retail': 1869, 'Veterinary': 1870, 'entrepreneurs': 1871, 'calls': 1872, 'breath': 1873, '1,702': 1874, "we're": 1875, 'special': 1876, '28': 1877, 'Rail': 1878, 'youthful': 1879, 'moment': 1880, 'need': 1881, 'Wiesbaden.': 1882, 'thus': 1883, 'Still': 1884, 'insider': 1885, 'AFP': 1886, 'drainage': 1887, 'safety': 1888, 'legal': 1889, 'higher': 1890, "Poland's": 1891, 'Giannis': 1892, 'final': 1893, 'figure': 1894, 'years,': 1895, '"almost': 1896, 'Police': 1897, 'salmonella': 1898, '-': 1899, 'Television': 1900, '–': 1901, 'But': 1902, 'finally': 1903, 'Cooperation': 1904, 'Sadurskis.': 1905, 'stake.': 1906, 'among': 1907, 'instead': 1908, 'Disease': 1909, 'appeared': 1910, 'association': 1911, 'The': 1912, 'nationality': 1913, 'relations,': 1914, 'called': 1915, 'celebrating': 1916, 'hundreds': 1917, 'persons': 1918, 'structures.': 1919, 'number': 1920, 'concern': 1921, 'aviation': 1922, 'Ukrainian': 1923, 'link': 1924, 'prices': 1925, 'answer': 1926, 'preferable': 1927, 'Cambridge': 1928, 'criminal': 1929, 'fault.': 1930, 'Government': 1931, 'chose': 1932, 'programs': 1933, '(LETA)': 1934, 'services': 1935, "children's": 1936, 'equaled': 1937, 'sending': 1938, 'reside': 1939, 'next': 1940, 'European': 1941, 'failed': 1942, 'week.': 1943, 'Stopini': 1944, 'electrical': 1945, 'letter': 1946, '2005': 1947, 'KGHM,': 1948, 'flight': 1949, 'inspected': 1950, 'venture.': 1951, 'Baghdad,': 1952, 'barrels': 1953, 'residence': 1954, 'EUR': 1955, 'slowed': 1956, 'conflict".': 1957, 'found,': 1958, 'Denmark': 1959, 'defeated': 1960, 'searching': 1961, 'Fellowship,': 1962, 'States,': 1963, 'maintain': 1964, 'word': 1965, 'translation': 1966, 'reads.': 1967, '."': 1968, 'sign': 1969, 'ballistic': 1970, 'entire': 1971, 'urged': 1972, '2013.': 1973, 'water': 1974, 'no': 1975, 'forced': 1976, 'multinational': 1977, 'says.': 1978, 'Resource': 1979, 'authorities': 1980, 'Center.': 1981, '1.4': 1982, 'i.e.': 1983, 'Parliament': 1984, 'Dzelzcels.': 1985, 'job': 1986, 'Set': 1987, 'minister': 1988, 'unless': 1989, '57': 1990, 'win': 1991, 'credentials': 1992, 'then,': 1993, 'future.': 1994, 'ball,"': 1995, 'now.': 1996, 'Netherlands.': 1997, 'Italian': 1998, 'same': 1999, 'summer,': 2000, 'towards': 2001, 'out': 2002, 'ongoing...': 2003, 'grown': 2004, 'endangering': 2005, 'employment': 2006, 'country': 2007, 'research': 2008, 'Memorial': 2009, 'aside': 2010, 'Fribourg-Gotteron': 2011, 'defense': 2012, 'market': 2013, '"Liv"': 2014, 'discussions': 2015, 'helped': 2016, 'vice-president': 2017, 'Ross': 2018, 'Robert': 2019, 'president-elect': 2020, 'from': 2021, 'hard': 2022, 'giving': 2023, 'partners': 2024, 'NBA': 2025, 'discussed': 2026, 'safely': 2027, 'sector.': 2028, 'policy,': 2029, 'established': 2030, 'sector': 2031, 'Ruse': 2032, 'secure': 2033, 'fodder': 2034, 'admitted': 2035, 'place,': 2036, 'responsibility': 2037, 'shortage': 2038, 'cargo': 2039, 'nothing': 2040, 'details': 2041, 'despite': 2042, 'organizations': 2043, 'by': 2044, 'train': 2045, 'revenue': 2046, 'ill-intended,"': 2047, 'brand,': 2048, 'technical': 2049, 'shipments': 2050, 'Baltica': 2051, 'pose': 2052, 'way,"': 2053, 'LFF': 2054, 'Zug': 2055, 'Law,': 2056, 'president': 2057, 'non-governmental': 2058, 'permanent': 2059, 'director': 2060, '400': 2061, 'competitiveness': 2062, 'Somali': 2063, 'her': 2064, 'stimulate': 2065, 'stick': 2066, 'Therefore': 2067, 'reports': 2068, 'Slokenbeka': 2069, 'speech': 2070, 'company': 2071, 'mean': 2072, 'Employees': 2073, 'Sevastopol,': 2074, 'political,': 2075, 'foreigners': 2076, 'BBC,': 2077, 'crises,': 2078, 'Sadurskis': 2079, 'whole': 2080, 'terror': 2081, 'second': 2082, "face'catastrophic": 2083, 'collapse,': 2084, 'Colombia': 2085, 'see': 2086, 'founded': 2087, 'policing': 2088, 'it': 2089, 'Kingdom,': 2090, 'sometime': 2091, 'gross': 2092, 'control,': 2093, '2004,': 2094, 'mission.': 2095, 'structure': 2096, 'reduce': 2097, 'Iraqis': 2098, 'Change': 2099, 'contracts': 2100, 'Geology': 2101, 'demonstrate': 2102, 'Ceferin': 2103, 'Angeles,': 2104, 'initiative': 2105, 'Partners.': 2106, 'being': 2107, 'added': 2108, 'James': 2109, 'world': 2110, '0:1).': 2111, 'comprised': 2112, 'can': 2113, 'capital': 2114, 'Celsius,': 2115, 'Asia,': 2116, 'city,': 2117, 'He': 2118, 'Investigation': 2119, 'reasons,': 2120, 'TV': 2121, 'Ohio': 2122, 'history,': 2123, 'planned': 2124, 'put': 2125, 'Northern': 2126, 'stronger': 2127, 'Los': 2128, 'breach': 2129, 'formed': 2130, 'hand,': 2131, 'miraculously': 2132, 'project': 2133, 'companies': 2134, 'days,': 2135, '2000.': 2136, 'reported.': 2137, '"Europol': 2138, 'Law': 2139, 'Affairs': 2140, 'activities': 2141, 'acquisition': 2142, 'transit': 2143, 'Riga.': 2144, 'Up': 2145, 'point': 2146, 'vote': 2147, 'LETA.': 2148, 'Islamic': 2149, 'thankful': 2150, 'fire.': 2151, 'global': 2152, 'raise': 2153, '(21:17,': 2154, 'Sevastopol.': 2155, 'instances': 2156, 'quoted': 2157, 'each),': 2158, 'New': 2159, 'meantime,': 2160, 'Trump': 2161, 'registers': 2162, 'address.': 2163, 'statute': 2164, 'construction': 2165, 'people': 2166, 'butter': 2167, 'near': 2168, 'campaign,': 2169, 'markets,': 2170, 'night.': 2171, 'month': 2172, 'Hungary': 2173, 'another': 2174, 'minus': 2175, 'praised': 2176, 'cap': 2177, 'advance': 2178, 'bonuses': 2179, 'Announcing': 2180, 'ask': 2181, 'Necessary': 2182, 'Global': 2183, 'needs': 2184, 'ethnic': 2185, 'she': 2186, 'reinforcing': 2187, 'private': 2188, '1.9': 2189, 'Eduardo': 2190, 'resolution': 2191, 'calculated': 2192, 'become': 2193, '(+7.4': 2194, '501': 2195, 'south.': 2196, '"Latvian"': 2197, 'invested': 2198, 'pace,': 2199, 'western': 2200, 'prostitution': 2201, 'law,': 2202, 'cooperation,': 2203, 'pages': 2204, 'Member': 2205, 'indicating': 2206, 'border.': 2207, 'feed': 2208, 'believe': 2209, '"We\'re': 2210, 'Latvians,': 2211, 'so': 2212, 'Prevention': 2213, 'order': 2214, 'meeting': 2215, '2.2': 2216, '12': 2217, 'markets': 2218, 'Black': 2219, 'Industrial': 2220, 'Director': 2221, 'cultural': 2222, 'Bergmanis': 2223, 'web-site': 2224, 'Ministry': 2225, 'Finals': 2226, 'upsets': 2227, 'Ireland': 2228, "alliance's": 2229, 'issues.': 2230, 'state': 2231, 'showed': 2232, '1.421': 2233, 'argument': 2234, 'heart".': 2235, 'without': 2236, 'Krasnopjorovs': 2237, 'knowledge': 2238, 'Unda,': 2239, 'Aleksander': 2240, 'regularly': 2241, 'Lithuania,': 2242, 'capacities': 2243, 'route': 2244, 'reported,': 2245, 'unprecedented"': 2246, 'battalion': 2247, 'controls': 2248, 'fines': 2249, 'Latvian-Italian': 2250, 'strongest': 2251, 'favor': 2252, 'Lielais': 2253, '60': 2254, 'MEPs.': 2255, "we've": 2256, 'really': 2257, 'potential': 2258, 'Belgium': 2259, 'Olympic': 2260, 'During': 2261, 'resuming': 2262, 'profit': 2263, 'Driksna': 2264, 'IT': 2265, 'Environmental': 2266, 'Upcoming': 2267, 'account': 2268, 'personally': 2269, 'investment': 2270, 'ex-employee': 2271, 'more.': 2272, 'totaled': 2273, 'via': 2274, 'stores.': 2275, 'Latvia.': 2276, 'petitions': 2277, "operator's": 2278, 'past': 2279, 'weapons.': 2280, 'civilians': 2281, 'read': 2282, 'expected': 2283, 'increases': 2284, 'NATO': 2285, 'foreign': 2286, 'Geneva': 2287, 'released': 2288, 'countries,': 2289, 'killed': 2290, 'deal,': 2291, 'news': 2292, 'Finals.': 2293, 'Service': 2294, 'Firmas.lv,': 2295, 'center': 2296, 'infrastructure,': 2297, 'moved': 2298, 'quarter': 2299, 'requirements': 2300, 'based': 2301, 'data,': 2302, 'defeat': 2303, 'prepared': 2304, 'include': 2305, 'passenger': 2306, 'strongly': 2307, 'lead': 2308, 'fresh': 2309, 'Last': 2310, 'armed': 2311, 'Salmonellosis': 2312, 'January': 2313, 'stipulate': 2314, 'endorses': 2315, 'rise,': 2316, 'explain': 2317, 'leading': 2318, 'flow': 2319, 'online,': 2320, 'Armed': 2321, 'foresees': 2322, 'states.': 2323, 'wage': 2324, 'continue': 2325, 'Miracle': 2326, 'overdue': 2327, 'points': 2328, '29': 2329, 'Elvis': 2330, 'receiving': 2331, 'made': 2332, 'store]': 2333, 'amendments,': 2334, 'Bauskas': 2335, 'serious': 2336, 'law': 2337, 'than': 2338, 'very': 2339, 'early': 2340, 'countries,"': 2341, 'question,"': 2342, 'filthy': 2343, 'Washington': 2344, 'stop': 2345, 'US': 2346, '1:1).': 2347, 'rule,': 2348, "Praag's": 2349, 'operation': 2350, 'killed.': 2351, 'pilot': 2352, 'bilateral': 2353, "center's": 2354, 'historical': 2355, '10,366': 2356, 'Games.': 2357, 'friends': 2358, '"A': 2359, 'living': 2360, 'days': 2361, 'Latvia': 2362, 'done': 2363, 'nuclear': 2364, 'because': 2365, 'AFP:': 2366, '1,300': 2367, 'venture': 2368, '7.6': 2369, 'assessed': 2370, 'unanimously': 2371, 'connecting': 2372, 'associations': 2373, 'legislation,': 2374, 'USD': 2375, 'values': 2376, 'Juberte-Krumina,': 2377, 'height': 2378, 'convenient': 2379, 'September': 2380, 'implementation': 2381, 'amendments': 2382, 'post-Brexit,': 2383, 'crisis': 2384, 'heated': 2385, 'officials': 2386, 'significant': 2387, 'net': 2388, 'institute': 2389, 'years': 2390, 'what': 2391, 'Brice': 2392, 'threatening': 2393, 'former': 2394, 'halted': 2395, 'connected': 2396, 'into': 2397, 'complementary': 2398, 'idea': 2399, 'police.': 2400, 'people"': 2401, '(NLA)': 2402, 'waters.': 2403, 'Presidential': 2404, 'laid': 2405, 'logistical,': 2406, 'office': 2407, 'aviation.': 2408, 'improve': 2409, 'HQ': 2410, 'more': 2411, 'contributed': 2412, 'open': 2413, 'Baltcom': 2414, 'Thursday': 2415, '828,': 2416, 'told': 2417, 'Partners,': 2418, 'contacted': 2419, 'envisage': 2420, 'Rozenberga': 2421, 'wealthy': 2422, 'Summit': 2423, 'procurements,': 2424, 'University': 2425, 'reporters': 2426, 'crossing': 2427, 'exports': 2428, 'institutions.': 2429, 'of': 2430, 'order.': 2431, 'barrels;': 2432, 'always': 2433, '1.425': 2434, 'found': 2435, 'supported': 2436, 'bronze': 2437, 'Our': 2438, 'opportunity': 2439, 'Jorge': 2440, '(but)': 2441, 'hope': 2442, 'themselves': 2443, "Chancellery's": 2444, 'satisfied': 2445, 'natural': 2446, 'employees.': 2447, 'speculated': 2448, 'where': 2449, 'Alexander': 2450, 'balance:': 2451, 'interview': 2452, 'losses': 2453, 'pimps.': 2454, 'His': 2455, 'weeks.': 2456, 'last': 2457, 'assess': 2458, "prosecutor's": 2459, 'approximately': 2460, 'Seima': 2461, 'weekend.': 2462, 'Average': 2463, '14-4': 2464, 'west,': 2465, 'traditionally': 2466, "Lithuania's": 2467, 'most': 2468, 'Confederation': 2469, 'capabilities': 2470, 'deemed': 2471, 'Providence': 2472, 'pointed': 2473, 'express': 2474, 'School,': 2475, 'return': 2476, 'life,': 2477, 'Council': 2478, 'teenage': 2479, 'reiterates': 2480, 'festival.': 2481, 'rate': 2482, 'King': 2483, '18': 2484, 'Aleksandrs': 2485, 'cases': 2486, 'through': 2487, 'Hungarian': 2488, 'Millennium': 2489, 'simply': 2490, 'Russia.': 2491, 'Piatek,': 2492, 'coordination': 2493, 'Ina': 2494, 'mourning.': 2495, 'investments': 2496, 'dynamics,': 2497, 'Given': 2498, 'powder': 2499, 'dry,': 2500, 'sees': 2501, 'budget,': 2502, 'remain': 2503, '2018,': 2504, 'investigative': 2505, 'One': 2506, 'kindergartens': 2507, 'Olekas': 2508, 'previous': 2509, "''In": 2510, 'Minister': 2511, 'young': 2512, 'say': 2513, 'Region,': 2514, 'reported': 2515, '1:0,': 2516, 'already.': 2517, 'Investment': 2518, 'indicate': 2519, 'visits': 2520, 'funding': 2521, 'credence': 2522, 'medal': 2523, 'fly': 2524, 'offensive': 2525, 'sends': 2526, 'increasingly': 2527, 'reasons"': 2528, 'press': 2529, 'cooler': 2530, 'Union': 2531, 'difficult': 2532, 'would': 2533, 'Justice': 2534, 'owners': 2535, 'critically': 2536, 'their': 2537, 'been': 2538, 'peace,"': 2539, 'Antetokounmpo': 2540, 'STRASBOURG,': 2541, 'jets,': 2542, 'Berzins': 2543, 'principles': 2544, '2:3': 2545, 'those': 2546, 'Fridenberga-Kalnina,': 2547, 'conversation': 2548, 'loss.': 2549, 'communication': 2550, 'couple': 2551, 'Wilbur': 2552, 'Startups': 2553, 'gradually': 2554, 'legalize': 2555, 'or': 2556, 'psychology.': 2557, 'turn': 2558, '500': 2559, 'land': 2560, 'access': 2561, 'slipped': 2562}
investigationtensor([[ 0.0315,  0.1440, -0.8504, -0.0444, -0.8842,  1.2785, -0.3498, -0.1719,
          0.3069,  0.1299]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Monday,tensor([[-0.3826, -1.3752, -0.2096,  1.0880, -0.9071, -0.0386,  0.1765, -0.4004,
          1.1758, -0.5937]], device='cuda:0', grad_fn=<EmbeddingBackward>)
line.tensor([[-0.2406,  0.0562, -0.1601, -0.1191, -1.0954, -1.3811, -0.3658,  1.2601,
         -1.6104,  0.8778]], device='cuda:0', grad_fn=<EmbeddingBackward>)
removetensor([[-1.1554,  2.0619, -0.6415,  0.5426,  0.6768,  0.2515,  0.0068,  1.1464,
          1.1227,  0.6776]], device='cuda:0', grad_fn=<EmbeddingBackward>)
0.6tensor([[-1.3213,  0.5240, -0.9036,  0.9377, -0.6821, -1.4408, -0.4077, -1.8821,
         -0.8046, -0.8093]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Itensor([[-0.4753, -0.4129, -1.1583, -0.0468, -1.9242,  0.7668,  3.2052, -1.6441,
          0.3328, -1.0180]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Gammatensor([[ 0.8649,  0.8288,  0.1135, -1.2345,  0.9228,  2.1398,  0.6509,  0.4597,
         -0.4889, -0.3323]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Regionaltensor([[ 0.6474,  0.5447, -1.3387,  0.6286,  0.0712,  0.0279, -0.7149, -1.6426,
          0.3768,  0.3353]], device='cuda:0', grad_fn=<EmbeddingBackward>)
everytensor([[ 0.1341,  0.9924,  1.0507, -0.3143, -0.1375,  0.2111,  0.0401,  0.5834,
         -0.2829,  0.5288]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Saeimatensor([[ 1.2131, -0.6174, -1.3526, -0.6755,  0.2619, -0.8449,  0.1167,  0.8077,
          2.1407, -0.2860]], device='cuda:0', grad_fn=<EmbeddingBackward>)
sustainabilitytensor([[ 1.0203,  2.4579,  0.4483, -0.0716, -0.7761, -0.1511, -1.1573, -1.0199,
          0.5450,  1.5059]], device='cuda:0', grad_fn=<EmbeddingBackward>)
curbtensor([[-0.5940,  1.6676,  0.2722,  0.8243, -0.4846, -1.3722, -0.0093,  1.5948,
         -1.2817, -0.1127]], device='cuda:0', grad_fn=<EmbeddingBackward>)
rawtensor([[ 0.1259, -1.9940, -2.1163,  0.3810, -0.2707, -0.0919,  2.5726,  2.2096,
          0.1009, -0.9098]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Chancellerytensor([[ 1.4910,  0.6585,  0.8722,  0.5241,  0.2496,  0.1329, -0.8440,  0.8058,
         -0.2992, -0.0301]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"ittensor([[-1.2116, -0.5983, -0.2903,  0.3825, -0.1768, -0.6284, -0.9773,  0.9401,
          0.3389, -0.5043]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"Onetensor([[-1.2186, -0.6737, -1.0119, -1.1509, -0.6480, -0.0903, -1.1811, -0.1789,
         -0.3910, -1.4027]], device='cuda:0', grad_fn=<EmbeddingBackward>)
planetensor([[ 0.2754,  0.2399,  0.5999, -0.1407, -0.0369,  0.0283,  0.8494,  1.7360,
          0.0712, -1.0050]], device='cuda:0', grad_fn=<EmbeddingBackward>)
philosopher.tensor([[ 1.2406, -0.0449,  3.4449, -0.2871, -0.3647,  1.5570,  0.3047, -0.3519,
          0.7756, -0.9170]], device='cuda:0', grad_fn=<EmbeddingBackward>)
passedtensor([[ 0.0312, -1.3546,  0.5956, -0.5032,  0.2791, -1.0259, -0.4444, -1.2909,
          1.5013, -0.0815]], device='cuda:0', grad_fn=<EmbeddingBackward>)
respectabletensor([[ 0.3531, -0.4995, -0.4609,  0.9743, -0.0098,  1.3671, -1.0007, -0.7601,
          1.1325,  2.4280]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Santensor([[ 0.4339,  0.6800, -0.4143, -0.7742, -0.5342,  0.1426,  0.3906, -0.1493,
          0.7886,  0.2767]], device='cuda:0', grad_fn=<EmbeddingBackward>)
25.tensor([[ 0.9997, -0.7840,  0.6183, -0.3313,  0.3999,  0.2942, -0.2099,  0.9712,
          0.0055, -1.2385]], device='cuda:0', grad_fn=<EmbeddingBackward>)
customstensor([[-0.2934,  0.0439,  1.8762,  1.3171,  0.6648,  0.0894,  1.6473, -0.2421,
          0.7782,  0.6367]], device='cuda:0', grad_fn=<EmbeddingBackward>)
bothtensor([[-1.4708,  1.4659,  0.5453,  0.4206,  0.9646, -1.7570, -0.1300, -0.6807,
         -0.0379,  0.0639]], device='cuda:0', grad_fn=<EmbeddingBackward>)
4,000.tensor([[-0.0276,  2.0360,  0.5203,  0.0353,  0.7804,  0.0443, -0.5730, -0.7362,
         -0.2059, -0.3361]], device='cuda:0', grad_fn=<EmbeddingBackward>)
economicstensor([[ 0.9959, -0.5635,  1.8945, -0.6279,  0.4728, -1.2711,  0.8724,  0.8144,
         -1.0168, -1.0681]], device='cuda:0', grad_fn=<EmbeddingBackward>)
that,tensor([[ 0.0839,  0.5204,  0.4235, -0.8297,  0.6352,  1.0506,  0.4105,  1.0241,
         -0.8411, -0.6421]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Fijalek/Prudeltensor([[ 0.0246, -2.0957,  1.0287, -0.4401,  1.2857,  0.3607, -1.3997,  0.5225,
         -0.7530,  1.2331]], device='cuda:0', grad_fn=<EmbeddingBackward>)
informed,tensor([[ 0.8210,  0.8181, -0.2313,  0.7081,  1.1881,  0.7126, -1.3136,  0.6849,
         -0.0861, -0.6855]], device='cuda:0', grad_fn=<EmbeddingBackward>)
basis,tensor([[ 0.1350,  0.0192, -0.3180, -2.1799,  0.1925,  0.5866, -1.4012, -0.4185,
          0.8877, -0.0938]], device='cuda:0', grad_fn=<EmbeddingBackward>)
periodtensor([[-1.3803,  0.3091,  2.8341, -0.9402, -0.4151, -0.2252, -1.4411,  0.5600,
          0.6218,  0.1281]], device='cuda:0', grad_fn=<EmbeddingBackward>)
comparedtensor([[ 0.1885, -3.3211, -0.4908, -1.2958,  1.3733, -0.6922, -0.5298, -0.1426,
          1.7414,  0.5102]], device='cuda:0', grad_fn=<EmbeddingBackward>)
gotensor([[ 0.0782,  0.3402, -0.8597, -0.1247,  1.4136,  0.1254,  0.5060, -0.5545,
          0.8281, -0.1828]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Commissiontensor([[ 0.2364, -1.0919,  1.3638,  0.8057,  0.1942,  1.3765, -0.8083, -0.8722,
         -0.7094,  0.5402]], device='cuda:0', grad_fn=<EmbeddingBackward>)
downwardtensor([[-0.5024, -0.5122,  1.7506, -2.1247, -0.5882,  0.1594,  0.8279, -0.4822,
          0.3611,  0.5183]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Institutetensor([[ 1.2900,  2.3638,  1.9005, -0.7778,  0.3001,  0.2207,  0.2141, -1.1718,
         -0.6232, -0.1951]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Baltstor,tensor([[ 0.2079,  0.2372,  0.1221, -0.8501, -2.1996,  1.1257,  0.2942,  0.6585,
          0.4151, -0.6517]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Latenaitetensor([[ 1.4765,  0.6004,  1.4676, -0.6759,  2.2918,  0.6099, -1.3193, -2.1862,
         -1.1494,  0.8780]], device='cuda:0', grad_fn=<EmbeddingBackward>)
withtensor([[-0.9554,  0.3034, -0.7651,  0.9186, -2.7368, -1.7410, -0.5348, -2.3933,
         -1.5722,  0.5031]], device='cuda:0', grad_fn=<EmbeddingBackward>)
andtensor([[ 1.4304, -0.6623, -0.1518,  0.6579,  0.7075, -0.6142,  1.1656,  2.6523,
         -1.2505, -1.0020]], device='cuda:0', grad_fn=<EmbeddingBackward>)
and...tensor([[ 1.3155,  1.6382,  0.7227, -0.1415,  1.4994,  0.4928, -1.4593, -0.9339,
         -0.5966,  0.2992]], device='cuda:0', grad_fn=<EmbeddingBackward>)
valuetensor([[-0.4972, -0.6812,  0.5191,  0.6439,  0.2434, -0.6793, -0.5099,  0.1707,
          0.4200,  1.8595]], device='cuda:0', grad_fn=<EmbeddingBackward>)
turnedtensor([[ 1.1691,  0.1999,  0.8812,  0.2804,  0.3692, -0.3627,  1.4432,  1.4570,
          0.1137, -0.8775]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Transcontainertensor([[-1.7565,  1.7438, -1.5963,  0.8288, -0.3965, -0.0153,  0.5054, -2.2788,
         -0.6511,  0.7760]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Phytosanitarytensor([[ 0.2794, -1.4539, -0.5242,  0.1938, -1.2189,  1.4167, -0.8740,  1.5137,
         -1.5267, -0.0103]], device='cuda:0', grad_fn=<EmbeddingBackward>)
favorabletensor([[-1.2061,  0.3943, -2.2335,  0.2615, -1.2455,  0.2797, -0.5920, -0.7132,
          1.1996,  0.1091]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Mezeckistensor([[ 2.1953,  0.6862, -1.6654, -0.2721, -0.2396, -0.0686, -0.9745,  0.1514,
         -0.2522,  1.0790]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ambassador,tensor([[-1.0497, -1.9370, -0.1516,  0.0203, -1.4273, -1.3317, -0.6794, -0.0102,
         -0.0802,  0.5642]], device='cuda:0', grad_fn=<EmbeddingBackward>)
partnertensor([[ 1.1571,  0.8272,  0.4062, -2.9544, -0.9066, -2.3814,  0.0815, -0.9964,
          1.0287,  0.6454]], device='cuda:0', grad_fn=<EmbeddingBackward>)
fueltensor([[-0.7197, -0.9233,  0.0168,  1.8232, -1.3884, -0.7803, -1.4889, -0.9170,
         -1.2089, -1.5625]], device='cuda:0', grad_fn=<EmbeddingBackward>)
aimtensor([[ 0.3119, -0.7402,  0.9061, -0.7403, -1.4331,  0.4022, -1.5938, -0.2909,
         -1.5342, -0.1546]], device='cuda:0', grad_fn=<EmbeddingBackward>)
providetensor([[-0.2058, -0.1343, -1.6167, -1.1068, -0.4750,  0.9353, -0.6642, -0.1687,
          1.8827, -0.6322]], device='cuda:0', grad_fn=<EmbeddingBackward>)
milktensor([[-1.2044, -1.1046, -1.3950,  1.1974,  0.6018,  0.5900, -0.7743, -0.8371,
         -1.4986, -0.1568]], device='cuda:0', grad_fn=<EmbeddingBackward>)
illegaltensor([[ 0.6581, -0.2776, -0.9527, -1.1149,  0.0359,  1.1249,  0.6069,  0.6649,
          0.8231, -0.9725]], device='cuda:0', grad_fn=<EmbeddingBackward>)
regionaltensor([[-0.9987,  0.9050,  1.6259,  0.4135, -1.0338,  1.1800,  0.9677,  0.8114,
          0.0390,  2.0634]], device='cuda:0', grad_fn=<EmbeddingBackward>)
downedtensor([[-0.6233,  0.9449,  1.0629,  0.5187, -0.8813, -0.3766, -1.2232,  0.9445,
          0.1014,  0.7403]], device='cuda:0', grad_fn=<EmbeddingBackward>)
regions,tensor([[-0.9094, -0.4160,  1.5833,  0.4810,  0.7554, -1.3971,  0.4161,  0.7929,
         -0.8515, -0.9326]], device='cuda:0', grad_fn=<EmbeddingBackward>)
runtensor([[ 1.3424,  0.0773, -0.1912,  0.2264, -0.4611, -1.0019, -0.0634,  1.5232,
         -3.2098,  0.0034]], device='cuda:0', grad_fn=<EmbeddingBackward>)
aimstensor([[-1.0358,  0.3752,  2.1073,  2.0208, -0.0734, -0.9839,  0.9111, -0.2624,
          0.7964, -0.1042]], device='cuda:0', grad_fn=<EmbeddingBackward>)
inspecttensor([[-0.5965,  0.2726, -0.4795,  1.6451,  0.5047, -0.3826, -1.3826, -0.0165,
         -0.1228,  0.2640]], device='cuda:0', grad_fn=<EmbeddingBackward>)
forces,tensor([[-0.5910,  2.5253,  0.6594,  1.5812, -1.0765, -1.5990,  2.4017, -0.7259,
          0.2179, -0.1262]], device='cuda:0', grad_fn=<EmbeddingBackward>)
contenttensor([[ 1.2271,  0.5540,  0.0817, -0.6830, -0.3935, -0.2906,  1.5062, -0.8651,
          0.8890,  1.0415]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Transporttensor([[-1.4033, -0.7345, -0.6624,  0.1280, -0.3338, -2.4297, -1.4845,  0.5580,
         -2.6287,  0.5526]], device='cuda:0', grad_fn=<EmbeddingBackward>)
usedtensor([[ 0.5532,  1.6026,  1.9471, -1.8444, -0.6752,  0.6617, -1.0558,  0.6567,
          0.6051, -0.2933]], device='cuda:0', grad_fn=<EmbeddingBackward>)
cooperation".tensor([[ 0.4615,  1.9055,  0.5704,  0.2182, -0.8009,  1.1405, -0.1467, -0.3362,
         -0.7151, -0.5117]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ministry.tensor([[-1.2528,  0.5386,  0.8669,  1.7818,  1.1677, -0.7579, -0.5040, -0.1868,
         -0.3764, -1.0586]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Augusttensor([[ 0.9638,  0.1314,  1.7540, -0.3858,  0.0586, -2.7983,  1.2191,  2.4183,
         -0.5667, -0.5216]], device='cuda:0', grad_fn=<EmbeddingBackward>)
diplomatictensor([[-0.1905,  2.1297, -0.9458,  0.0267, -0.0182, -0.4439,  0.6920, -0.0309,
         -0.1695,  0.6211]], device='cuda:0', grad_fn=<EmbeddingBackward>)
illegitimatetensor([[-0.1863,  0.3391, -0.7026,  0.5978, -0.0740,  0.1751, -1.1854,  0.1930,
         -1.9831,  0.5377]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Alliance),tensor([[ 1.8327,  0.3271,  2.0134, -0.5811, -0.8376, -1.6098, -1.6121, -0.8769,
          0.8642,  0.8941]], device='cuda:0', grad_fn=<EmbeddingBackward>)
solutionstensor([[ 2.2669e+00,  5.8122e-04,  1.6999e-01, -2.3230e-02,  7.3866e-01,
         -2.9883e-02,  3.3003e-01, -9.5353e-01,  1.0357e+00,  2.4900e-01]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
Nations,tensor([[-1.5156,  1.4995, -1.8280,  1.2054,  1.5543, -0.4051, -0.8621, -0.4882,
         -0.1709, -0.2635]], device='cuda:0', grad_fn=<EmbeddingBackward>)
process.tensor([[-2.7207,  0.2117, -0.4690,  1.0133, -0.6644,  1.0003, -1.9315, -0.4581,
         -1.1630, -0.2631]], device='cuda:0', grad_fn=<EmbeddingBackward>)
remain,tensor([[ 0.5156, -0.0855, -0.1465,  0.0676, -0.0460, -1.1209,  0.0672,  0.8456,
         -0.9667,  0.0031]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Sergiotensor([[ 0.9156, -0.1122, -0.8487,  0.7473, -0.4583, -1.0603, -0.2973,  1.0980,
          1.1734, -0.1350]], device='cuda:0', grad_fn=<EmbeddingBackward>)
portfoliotensor([[-0.7320,  1.8209, -0.1899, -0.9772, -0.2602,  0.4683,  0.0499, -1.1167,
         -0.8189,  0.9344]], device='cuda:0', grad_fn=<EmbeddingBackward>)
construction,tensor([[ 1.5510, -2.0162,  0.0023,  0.2761,  0.5196,  0.3034, -0.4896,  0.6193,
          0.0609, -1.5572]], device='cuda:0', grad_fn=<EmbeddingBackward>)
percent,tensor([[-0.1776, -0.1564, -0.5708, -0.9908,  0.3578, -2.2704, -0.1242,  0.8562,
         -1.9979, -1.0671]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Eurimages,tensor([[-1.2314, -0.9928,  0.0793, -0.0533, -0.0023,  0.4787,  0.0506, -2.1038,
          1.4406, -0.6014]], device='cuda:0', grad_fn=<EmbeddingBackward>)
0.1tensor([[ 0.5343, -1.1933,  0.1667,  0.8155, -1.4547, -0.6666,  0.1917, -0.3887,
          0.3195,  1.6582]], device='cuda:0', grad_fn=<EmbeddingBackward>)
not,tensor([[-1.1521, -1.1790, -0.6343, -0.6017,  2.1669,  1.2097,  0.0272, -0.2759,
         -1.0517,  0.0503]], device='cuda:0', grad_fn=<EmbeddingBackward>)
stressedtensor([[-0.9070, -0.7753,  0.5278, -0.7119,  0.5762, -1.1341, -1.9264, -0.2387,
          0.2265, -0.6936]], device='cuda:0', grad_fn=<EmbeddingBackward>)
1,709tensor([[ 0.5655, -0.6732,  0.3856,  0.4615,  1.3943, -0.3522,  2.6721, -0.7640,
          0.2303,  0.2132]], device='cuda:0', grad_fn=<EmbeddingBackward>)
growtensor([[ 0.8104,  1.9757,  0.1010, -1.5636,  1.4363, -0.4473, -1.9346, -0.7155,
         -1.2444,  0.0778]], device='cuda:0', grad_fn=<EmbeddingBackward>)
U.S.-ledtensor([[-0.1401,  1.1780, -0.2954, -0.4152,  0.2274,  0.8228,  0.0894, -2.4378,
         -0.5629, -0.0463]], device='cuda:0', grad_fn=<EmbeddingBackward>)
deployment,tensor([[-0.1855,  0.4005, -0.1668, -1.5222,  0.3131, -0.2092,  1.7686, -0.7738,
          0.7068, -0.2054]], device='cuda:0', grad_fn=<EmbeddingBackward>)
affirmtensor([[-1.5770,  1.0892,  0.2301,  1.5245,  0.3512, -1.1892,  1.7876,  0.5071,
         -0.0888, -2.8248]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reductiontensor([[ 1.0975,  0.0740,  0.7598, -0.0141, -0.5208,  1.2396, -2.1888, -1.4171,
          0.8162, -0.7425]], device='cuda:0', grad_fn=<EmbeddingBackward>)
2017.tensor([[-0.1869,  1.5217,  1.1410,  0.7580,  2.0451,  0.2629, -0.8686, -1.1512,
         -0.9080,  0.3535]], device='cuda:0', grad_fn=<EmbeddingBackward>)
intereststensor([[ 0.1308,  1.8924,  0.4706, -0.0450,  1.4672,  0.0069,  0.5729, -0.0900,
          0.8989,  1.0731]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Milwaukeetensor([[ 0.5953,  1.1230, -1.0176,  0.0805, -0.3519, -0.0601,  0.9405, -0.2690,
          0.6270,  0.0573]], device='cuda:0', grad_fn=<EmbeddingBackward>)
in.tensor([[-1.2943,  0.3547, -0.5947, -0.9214,  0.3160,  0.1866, -0.8709,  0.0206,
          1.1597, -0.8589]], device='cuda:0', grad_fn=<EmbeddingBackward>)
prostitutestensor([[-0.9027,  0.3561,  0.4707, -0.0525, -0.2944, -1.1066,  0.5297, -0.0668,
          1.3803, -1.5222]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Firsttensor([[ 0.4557, -0.1519, -0.5455, -1.1369,  0.4115, -1.5806, -1.2896,  1.9881,
          1.4526, -0.1341]], device='cuda:0', grad_fn=<EmbeddingBackward>)
invitationtensor([[-0.3870,  0.6678, -0.2867, -1.1916,  1.0505,  1.9679,  0.2775,  1.0524,
         -0.6305, -1.0720]], device='cuda:0', grad_fn=<EmbeddingBackward>)
legislativetensor([[-1.9859, -2.4493,  1.1093, -0.2653,  1.6929,  1.1424, -1.4805,  0.6211,
          1.5444,  0.6204]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Chinatensor([[-0.2060, -0.3887, -1.7755,  0.3149,  1.7752, -2.2620, -1.7192, -0.2469,
          0.7348, -0.6461]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Festival,tensor([[-1.6228, -0.3871, -0.5875, -0.6598, -0.5579,  0.3240,  0.6845,  0.2068,
          0.1360, -0.5721]], device='cuda:0', grad_fn=<EmbeddingBackward>)
partiallytensor([[ 0.5206,  1.7813, -2.0202,  0.4921,  0.2978,  0.5158,  0.1566, -0.7938,
         -0.7886,  0.0714]], device='cuda:0', grad_fn=<EmbeddingBackward>)
planning,tensor([[ 1.6051,  0.6904, -1.1289,  0.0819,  1.2582, -0.4985,  0.3984, -0.8884,
         -0.7046,  0.3776]], device='cuda:0', grad_fn=<EmbeddingBackward>)
borders,tensor([[-1.0136, -0.3436, -1.5829, -0.0394,  1.8518,  0.5679,  1.4207,  0.5614,
         -0.0423, -1.4545]], device='cuda:0', grad_fn=<EmbeddingBackward>)
industry,tensor([[ 1.0307,  1.4638,  0.6272, -0.2110, -0.6403,  0.6499, -1.8835,  0.7972,
          0.5568,  0.3600]], device='cuda:0', grad_fn=<EmbeddingBackward>)
featuringtensor([[-0.9728, -0.1853,  0.9560,  0.2354,  0.7880,  0.2184, -1.9768, -0.8700,
          0.4060, -0.7808]], device='cuda:0', grad_fn=<EmbeddingBackward>)
changetensor([[ 0.3397,  0.4021, -0.8938,  0.5178,  0.0245, -1.6449, -1.9399,  0.3057,
         -0.1492, -0.2437]], device='cuda:0', grad_fn=<EmbeddingBackward>)
losttensor([[ 1.3624,  0.6165, -1.0501,  0.0277, -1.4814, -1.0213,  1.0740,  0.2439,
          1.1463, -1.8480]], device='cuda:0', grad_fn=<EmbeddingBackward>)
weekstensor([[-1.0913, -0.4685, -0.4305,  2.0070,  0.0983,  0.3618,  0.2013, -1.3022,
         -0.6604,  0.5396]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Mattarella,tensor([[-0.9171, -0.5140,  0.9694, -1.1925,  1.1958,  0.9446,  2.0739, -0.1650,
         -0.5662,  1.5753]], device='cuda:0', grad_fn=<EmbeddingBackward>)
percenttensor([[-0.0176, -0.8857, -0.5049,  0.1472,  3.0791, -0.3880,  0.3090, -0.1338,
          0.5531,  1.6421]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Rothschildtensor([[-0.2262, -0.2028,  1.5568,  0.1576, -1.2374, -0.1134,  0.8050, -1.5809,
          1.0318, -0.4388]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Atensor([[ 0.1107,  0.7241,  1.1419,  0.5238, -0.4722, -1.0456,  2.0650,  1.7078,
         -1.1509,  0.2262]], device='cuda:0', grad_fn=<EmbeddingBackward>)
processestensor([[ 0.5431,  1.6924,  2.1057,  1.6513,  0.7272, -2.7826, -1.0582, -1.2577,
          0.5253, -0.7448]], device='cuda:0', grad_fn=<EmbeddingBackward>)
1.7tensor([[ 0.5008, -0.9379, -1.8816, -1.1867, -0.6618,  0.9241, -1.5539,  0.5623,
          0.9864,  0.0345]], device='cuda:0', grad_fn=<EmbeddingBackward>)
authorizetensor([[ 1.6192, -0.9430,  0.2214,  2.1075, -0.3078,  0.1004, -0.1853, -0.3668,
         -0.4858, -1.7285]], device='cuda:0', grad_fn=<EmbeddingBackward>)
annexationtensor([[-0.1990,  3.3724, -1.0590, -0.5427,  0.9306,  0.6933,  0.0147, -0.3003,
         -0.1357,  3.1007]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Grande,tensor([[ 0.5159,  0.5372,  0.5428,  1.9546,  0.2401,  0.6143, -0.3704,  0.1360,
          0.9999, -0.0399]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Rail,tensor([[ 1.7581, -0.4999, -0.8072, -0.6665, -0.4357,  0.4257, -2.2719, -1.9667,
          0.0194,  0.5826]], device='cuda:0', grad_fn=<EmbeddingBackward>)
EU'stensor([[ 0.3926,  0.9087,  0.2635, -1.9802,  0.0943, -1.6748,  1.2764, -1.1191,
         -1.3729, -1.0167]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Dzelzcelatensor([[ 0.0348, -1.1273, -0.1699,  0.2951,  0.0500, -1.2351, -0.8637,  0.4807,
          0.1621,  1.5325]], device='cuda:0', grad_fn=<EmbeddingBackward>)
goals.tensor([[-0.8269,  1.3104, -0.0488, -1.3221, -0.6260,  0.2699,  0.2034, -0.3075,
          0.1562, -0.6253]], device='cuda:0', grad_fn=<EmbeddingBackward>)
readingtensor([[ 2.3196,  0.7595,  0.0540,  0.5386,  1.3719, -0.8474, -1.7107,  1.7135,
         -0.7087,  1.4893]], device='cuda:0', grad_fn=<EmbeddingBackward>)
observerstensor([[-0.1924, -0.2418,  0.5872, -1.0580,  0.8585,  1.3584, -0.7725,  1.0231,
          0.4109, -1.1035]], device='cuda:0', grad_fn=<EmbeddingBackward>)
collapsedtensor([[-2.6681,  1.0113,  0.0542, -0.1913, -1.2607,  0.3883,  0.1843, -0.7742,
          0.2946,  0.3433]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Littletensor([[ 0.7149, -0.1362,  1.1134, -0.6463,  0.0419,  0.0625, -0.2026,  1.3060,
          1.2947, -0.0040]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Thattensor([[ 0.0900, -1.5280, -0.8927,  0.2393, -1.9023, -0.5390, -1.0382,  1.2249,
         -1.4551, -0.7394]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ingatensor([[ 0.5681, -0.0756, -0.3815,  1.0225,  1.4559, -1.1144,  1.4714, -0.1073,
         -0.4706,  0.9269]], device='cuda:0', grad_fn=<EmbeddingBackward>)
contracts,tensor([[-0.7979,  0.5496, -0.0373, -0.4000,  0.7077, -1.2253,  0.4151, -0.2982,
         -0.9700, -0.0290]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ambassadortensor([[-0.6090,  1.2978, -0.1751,  2.1209, -0.6633,  1.7193, -0.0688,  0.6644,
         -1.5327,  2.0547]], device='cuda:0', grad_fn=<EmbeddingBackward>)
electrifiedtensor([[-0.0801, -0.3084,  0.7841, -1.0580, -0.9913,  1.6854, -1.8305, -0.0478,
          0.4082,  0.2642]], device='cuda:0', grad_fn=<EmbeddingBackward>)
standardtensor([[-1.6138,  0.8328, -0.4704, -0.2903,  2.5784, -1.7478,  1.4172,  0.2994,
          0.6446, -0.6910]], device='cuda:0', grad_fn=<EmbeddingBackward>)
daytensor([[ 1.7893, -1.0717, -0.0608,  0.4382,  0.4668, -0.8035, -1.5137, -2.5404,
         -1.1297, -1.2465]], device='cuda:0', grad_fn=<EmbeddingBackward>)
includingtensor([[ 0.5984,  2.2951,  0.2539,  0.8932,  0.3967, -0.8646,  1.7803,  0.1870,
         -1.2003,  1.0389]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Locomotivetensor([[ 1.2434, -0.9392, -0.3140, -0.7074, -0.2026,  0.4838,  1.2567,  1.2390,
          0.8268, -2.1909]], device='cuda:0', grad_fn=<EmbeddingBackward>)
couldtensor([[-2.0011,  1.2419,  0.6664,  0.2818, -0.1189,  0.2842,  0.8762, -1.3603,
          1.6550, -0.2598]], device='cuda:0', grad_fn=<EmbeddingBackward>)
launchedtensor([[ 0.1153, -0.2298,  0.3708,  0.5169,  0.9888, -0.7685,  1.3496, -0.4670,
          0.4058, -0.8899]], device='cuda:0', grad_fn=<EmbeddingBackward>)
halftensor([[-0.2286, -1.1469,  1.2848, -0.2569,  0.2834,  0.6460,  1.0898,  1.5414,
         -0.8891, -1.0248]], device='cuda:0', grad_fn=<EmbeddingBackward>)
resulttensor([[ 0.6611,  0.6241, -1.8658,  0.2236, -0.9455,  0.4035, -1.9434,  0.7732,
          1.0069,  0.5545]], device='cuda:0', grad_fn=<EmbeddingBackward>)
comingtensor([[ 1.4253,  1.2626,  1.1918, -0.7133, -0.0780,  0.6941, -0.9523, -1.3160,
          1.6190,  0.9290]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Rosselkhoznadzortensor([[-0.4528,  0.3869, -0.4722, -0.0383, -0.3164,  2.0078, -0.7423, -1.1893,
          0.9081, -0.6567]], device='cuda:0', grad_fn=<EmbeddingBackward>)
transportationtensor([[ 1.7010e+00,  7.7356e-01, -6.9903e-01,  3.1368e-01,  6.3827e-01,
         -6.3423e-01,  9.8701e-04, -1.8004e+00,  5.2845e-01, -6.9269e-01]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
co-ownerstensor([[ 0.3336,  1.3441,  0.4066,  1.4983,  0.0128,  2.2324,  1.4879, -0.5415,
         -2.9010,  0.0659]], device='cuda:0', grad_fn=<EmbeddingBackward>)
registeredtensor([[ 0.3284, -0.2895,  1.4406,  1.0837, -0.8711,  0.2082, -2.5507,  0.8189,
         -0.0322,  0.8512]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Heninstensor([[ 0.1846,  1.8294, -0.2946,  0.9247,  0.5228, -1.0866,  0.0465, -0.9728,
         -0.5664,  1.0955]], device='cuda:0', grad_fn=<EmbeddingBackward>)
firsttensor([[ 0.0256,  0.3324,  1.6273, -2.5983,  1.0598,  0.4740, -0.3274,  2.3650,
          1.0861, -1.0057]], device='cuda:0', grad_fn=<EmbeddingBackward>)
justtensor([[ 0.4008, -0.4150,  0.0610,  0.7469,  0.0715,  0.4226, -0.4988, -1.1381,
         -0.8212, -0.0512]], device='cuda:0', grad_fn=<EmbeddingBackward>)
14tensor([[ 0.8572,  0.8724, -0.4225, -0.5392,  0.3297, -1.3832, -0.6408, -1.2379,
          1.4660, -0.4941]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Oftensor([[-0.4862,  0.0637,  0.6749, -1.0783, -0.3741, -1.8632,  0.0836, -0.8716,
          0.5115, -1.2227]], device='cuda:0', grad_fn=<EmbeddingBackward>)
20tensor([[-0.0041, -0.3959,  0.6672, -0.6983, -0.6394, -2.1273, -0.5502, -0.9241,
         -1.6096,  0.4676]], device='cuda:0', grad_fn=<EmbeddingBackward>)
hadtensor([[ 0.7233, -0.9776,  0.5363,  1.6847,  0.9459,  0.5012, -0.3762,  0.9419,
          0.3314,  0.9774]], device='cuda:0', grad_fn=<EmbeddingBackward>)
releasetensor([[ 2.2532, -0.5587, -0.3669, -0.3843,  0.9234, -2.2746, -1.9470, -1.0999,
          0.4305, -0.0517]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Junckertensor([[ 0.3312,  2.2128,  0.0040, -1.3615,  0.1383,  1.3166,  1.8429, -1.2275,
         -0.6194,  0.7264]], device='cuda:0', grad_fn=<EmbeddingBackward>)
employtensor([[ 0.1602, -0.6413,  0.3250,  1.1882,  3.1824, -0.1376, -0.4191,  0.6080,
         -1.4828,  1.2734]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Controltensor([[ 0.6635,  0.4297,  0.5450,  1.3484,  0.1751,  0.7247,  0.0225, -0.8274,
          0.8446,  0.4460]], device='cuda:0', grad_fn=<EmbeddingBackward>)
movementtensor([[ 1.0587, -0.7333,  0.4207,  0.1685, -1.2893,  0.3683, -0.8045, -1.1313,
         -0.0570, -0.0825]], device='cuda:0', grad_fn=<EmbeddingBackward>)
deadtensor([[ 0.0029, -0.4001,  1.3733, -0.6276, -0.2165,  0.2769, -1.4109,  2.2356,
         -0.0042, -0.5011]], device='cuda:0', grad_fn=<EmbeddingBackward>)
providertensor([[ 0.7532, -0.8605,  0.4532,  1.9647, -0.1240,  0.9367,  0.5420,  1.5524,
          0.5789,  0.3088]], device='cuda:0', grad_fn=<EmbeddingBackward>)
resultstensor([[-0.0340, -0.1977, -1.4798,  1.8553, -0.2698,  1.6493, -1.9383,  0.5468,
          0.3426,  0.7957]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Silicontensor([[ 0.7740, -0.2783, -0.1303,  0.0888, -0.5981,  0.6569, -0.4184, -0.2831,
         -0.0127, -1.1805]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Dutchtensor([[-0.6344,  0.8657, -0.5320,  0.7210,  1.8327,  0.1016,  0.1180,  0.1007,
         -0.3070,  0.3770]], device='cuda:0', grad_fn=<EmbeddingBackward>)
discusstensor([[-0.1259,  1.2685,  0.1067, -0.8041,  1.1631, -0.5925,  2.6520,  0.0116,
         -0.2116, -0.3897]], device='cuda:0', grad_fn=<EmbeddingBackward>)
''However,tensor([[-0.5271,  1.4608, -1.2440, -0.1366,  0.0181,  1.6795,  0.4363, -1.4887,
          0.0759, -0.7551]], device='cuda:0', grad_fn=<EmbeddingBackward>)
security,tensor([[ 1.6867, -0.7036,  0.0479, -0.1068, -0.7687, -0.6114, -0.9102,  0.8983,
         -0.1261,  2.0630]], device='cuda:0', grad_fn=<EmbeddingBackward>)
lottensor([[-2.2686,  1.2878,  0.4840, -0.0049,  1.7393,  0.2717, -0.7847, -0.9047,
          1.2540, -1.1079]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Mariusztensor([[-0.1381,  0.5527,  1.4027, -0.2301, -0.2362,  0.6763, -0.5303, -0.7606,
         -0.1424,  0.5650]], device='cuda:0', grad_fn=<EmbeddingBackward>)
gaptensor([[-1.1794,  0.4686, -0.2492,  0.8654,  1.1593, -1.6789, -0.5691,  1.3250,
         -1.9636, -1.9188]], device='cuda:0', grad_fn=<EmbeddingBackward>)
telecommunicationstensor([[ 0.2708,  1.5190,  1.1119, -0.6391,  2.2602, -0.0221, -0.1901,  0.7730,
         -0.2657,  0.7313]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Citizenstensor([[-1.3334, -0.0257, -2.0144,  0.6843, -0.8313, -1.4669, -0.0150,  0.7387,
         -0.7177, -0.0895]], device='cuda:0', grad_fn=<EmbeddingBackward>)
feeltensor([[ 0.2357,  0.8511, -1.3918,  0.2418,  1.4991,  0.5212,  0.1773,  0.4236,
         -0.9671, -0.9347]], device='cuda:0', grad_fn=<EmbeddingBackward>)
corridortensor([[ 0.1855, -1.0736,  2.3509,  0.5571, -0.0945,  1.0720,  2.2417,  0.8854,
          0.4310,  0.2339]], device='cuda:0', grad_fn=<EmbeddingBackward>)
timetensor([[ 1.0559,  1.9799, -0.9923,  0.1953,  0.9601, -1.3248,  2.1833, -1.9767,
          1.0669, -0.3174]], device='cuda:0', grad_fn=<EmbeddingBackward>)
lifestyletensor([[-0.0257, -1.3263,  0.5769, -0.5550,  0.4453,  0.0722, -0.5045,  1.0735,
         -0.2510,  0.6315]], device='cuda:0', grad_fn=<EmbeddingBackward>)
showstensor([[ 1.3981,  1.2987,  1.0151, -0.7130, -0.7129,  0.0901,  0.2099,  1.6753,
         -1.1847, -0.7365]], device='cuda:0', grad_fn=<EmbeddingBackward>)
5tensor([[ 4.6702e-01,  2.1336e+00,  1.1773e+00,  7.4862e-02, -1.4358e-04,
          2.1390e+00, -8.6283e-01,  5.9310e-01,  1.6464e+00, -5.5924e-01]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
Latvia,tensor([[ 0.5501,  0.4226, -1.2157, -1.5880,  2.0195,  0.2656, -0.4874, -1.4864,
         -0.6971, -0.6793]], device='cuda:0', grad_fn=<EmbeddingBackward>)
circumstances.tensor([[-1.8200, -0.1322, -0.0380, -1.8499, -0.7856, -2.0417,  0.2530, -0.0845,
         -1.2777, -0.8433]], device='cuda:0', grad_fn=<EmbeddingBackward>)
immigrant,tensor([[ 1.1446, -0.4063,  0.0181,  0.4701,  0.6567,  0.1151, -0.4147,  0.4568,
         -0.3031,  0.3211]], device='cuda:0', grad_fn=<EmbeddingBackward>)
propertiestensor([[ 1.8677,  0.2154,  1.2968,  0.2615, -0.2559,  1.0952,  0.9454,  0.4155,
          0.5489,  0.5141]], device='cuda:0', grad_fn=<EmbeddingBackward>)
grabbedtensor([[-0.1808, -0.4979, -0.9779,  0.2988,  0.5169, -0.1877, -1.6087,  0.2737,
         -0.7697, -0.3007]], device='cuda:0', grad_fn=<EmbeddingBackward>)
adjusttensor([[ 0.6534,  2.0570,  0.4961,  2.0126,  0.0935,  0.0920, -2.0739, -0.8138,
         -1.0632, -0.1146]], device='cuda:0', grad_fn=<EmbeddingBackward>)
viewtensor([[-1.7518, -0.4068,  0.2656, -1.1949, -0.2992,  0.4513, -1.0015,  0.8070,
          0.8114, -0.9602]], device='cuda:0', grad_fn=<EmbeddingBackward>)
out.tensor([[ 0.2639,  0.7580, -0.0016, -0.9057, -0.5989,  0.4765,  0.8055, -0.4690,
         -0.2931, -0.2135]], device='cuda:0', grad_fn=<EmbeddingBackward>)
say.tensor([[-0.0753,  0.6770, -0.4509,  0.6662,  0.3906,  0.8172, -0.2664, -0.3108,
         -0.0977, -0.5897]], device='cuda:0', grad_fn=<EmbeddingBackward>)
posttensor([[-0.4052,  0.0290,  0.2407, -1.1076,  0.4370, -1.1004,  0.0706, -0.3634,
          0.1527, -2.1395]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Kaunas,tensor([[-1.7892, -0.8227, -0.5048, -0.9904, -0.8089,  0.3222,  2.0762,  0.3848,
          1.7574, -0.4539]], device='cuda:0', grad_fn=<EmbeddingBackward>)
whichtensor([[ 0.1813,  0.3582,  0.2184,  0.8292,  0.2884,  1.7440,  2.9896, -0.1607,
          1.2807,  0.7786]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Luxembourgtensor([[-0.7727,  0.0331, -0.5395,  0.9970, -1.5864, -1.1061, -0.0183, -0.8763,
         -0.9902,  0.9123]], device='cuda:0', grad_fn=<EmbeddingBackward>)
shorttensor([[-0.0060,  0.1032, -0.1651, -0.2366, -0.3649, -0.2049,  0.6528, -0.8871,
          1.0575, -1.1964]], device='cuda:0', grad_fn=<EmbeddingBackward>)
project,tensor([[-1.1814,  0.1417, -2.0144,  0.9548,  0.1626,  0.3243, -0.0599, -1.4727,
          0.7678,  0.1484]], device='cuda:0', grad_fn=<EmbeddingBackward>)
premieretensor([[-1.0777, -1.0693, -0.0352, -0.1159,  0.6411,  0.7999, -0.2972, -0.3978,
         -0.6537, -1.0495]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Friday,tensor([[-1.1261,  0.5394,  0.4231,  1.1100,  0.2372,  1.7288, -0.7125, -0.5814,
         -0.4347, -1.4570]], device='cuda:0', grad_fn=<EmbeddingBackward>)
salarytensor([[ 1.8556,  0.3158, -1.6416, -0.3551, -1.8665, -0.7650,  0.8396,  0.0966,
         -2.5815,  1.6930]], device='cuda:0', grad_fn=<EmbeddingBackward>)
meanstensor([[ 0.4587, -1.4998,  0.9145,  1.0873, -1.2564,  1.0356,  0.7529, -0.5648,
         -0.4581, -0.5058]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Smiltenatensor([[-0.8652,  1.1803, -1.4339,  2.0076, -0.6357, -0.3858, -0.0316, -0.7367,
          1.0807,  0.2215]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Sincetensor([[-0.6300,  1.3158,  0.4926, -0.4325, -0.0257, -1.2330,  0.1720,  0.5478,
          0.2188,  0.2468]], device='cuda:0', grad_fn=<EmbeddingBackward>)
longertensor([[-1.1265,  0.9941, -1.4396, -1.1327, -0.6172, -1.0982, -0.2047,  0.0189,
         -1.3559,  0.7039]], device='cuda:0', grad_fn=<EmbeddingBackward>)
today'stensor([[-0.2487,  0.5871, -0.8623,  1.0378,  0.9458, -0.2778, -0.6884,  0.5901,
          0.9015, -0.3088]], device='cuda:0', grad_fn=<EmbeddingBackward>)
hour.tensor([[ 0.2245, -0.2857, -1.0665,  0.0223, -0.0061,  0.9946,  0.2094,  0.3029,
          0.1856,  0.4020]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Sixtensor([[ 0.9797, -0.8705,  0.1095, -0.2527,  0.6166, -2.6091,  0.0259,  1.0521,
          0.3480,  0.7790]], device='cuda:0', grad_fn=<EmbeddingBackward>)
salaries,tensor([[-0.2571,  0.5740, -1.6851,  1.7085, -0.7366,  1.4081,  0.3014, -0.4463,
         -0.5970,  1.9893]], device='cuda:0', grad_fn=<EmbeddingBackward>)
negotiationstensor([[ 0.9197, -1.7719,  0.5783,  0.2078,  1.3193,  0.2216,  0.7062,  1.7534,
          0.6857, -0.7356]], device='cuda:0', grad_fn=<EmbeddingBackward>)
interestedtensor([[ 0.8642,  1.0151, -2.3323,  0.8425, -0.4094, -1.1286,  0.6623, -0.4854,
          1.1850, -0.4269]], device='cuda:0', grad_fn=<EmbeddingBackward>)
providingtensor([[-0.7793,  0.4917, -1.9000,  1.2106,  0.8024,  0.3064, -0.4835, -0.5875,
          0.3075, -0.4680]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Londontensor([[ 0.0516, -1.2811, -0.0620, -1.2216,  1.3667,  0.8490, -0.1715, -0.7362,
          1.3234,  1.0496]], device='cuda:0', grad_fn=<EmbeddingBackward>)
pushedtensor([[ 0.7939, -1.3287,  1.1754, -0.9361,  1.2806, -1.7041,  0.6453, -0.4998,
          0.4384, -0.6538]], device='cuda:0', grad_fn=<EmbeddingBackward>)
electionstensor([[ 0.2780,  1.3859,  1.7865, -1.3384, -0.2918,  1.8841,  0.7906, -0.4461,
          0.3042,  1.4739]], device='cuda:0', grad_fn=<EmbeddingBackward>)
34tensor([[ 1.0397,  0.8644, -0.3088, -0.2677, -1.5392,  0.2895, -0.4474, -1.7852,
          0.3926, -1.1652]], device='cuda:0', grad_fn=<EmbeddingBackward>)
impoverishedtensor([[-2.8649, -0.3890,  0.7267,  1.1886, -0.6352, -0.8059,  1.6784, -2.1872,
         -0.4799,  0.7263]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Vilniustensor([[ 0.0262,  1.4152,  1.0697, -0.8165, -2.4711,  0.6389,  1.3016, -1.4958,
         -1.6406, -0.8886]], device='cuda:0', grad_fn=<EmbeddingBackward>)
(0:0,tensor([[-2.9457, -0.1494,  0.1934, -1.1713, -0.6561,  0.5912, -1.9608, -0.1036,
         -0.0560, -0.9357]], device='cuda:0', grad_fn=<EmbeddingBackward>)
expropriationtensor([[-0.0296,  1.1096, -1.7710,  0.5938,  2.2870, -0.1890, -0.7772,  0.3196,
          0.9946, -0.0448]], device='cuda:0', grad_fn=<EmbeddingBackward>)
naturetensor([[ 0.0445,  0.5078, -0.5732,  0.8137, -2.0702,  1.0160,  1.0319,  0.6478,
          0.6370,  1.0586]], device='cuda:0', grad_fn=<EmbeddingBackward>)
workerstensor([[ 0.1965, -0.6854,  0.4051, -0.2098,  0.9803, -0.2359, -0.9825,  0.2465,
          0.8458, -0.3877]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Educationtensor([[ 0.4996, -0.6242,  1.2786,  0.8726, -1.6985, -0.3364, -1.8929,  0.3141,
          0.4817, -0.5340]], device='cuda:0', grad_fn=<EmbeddingBackward>)
72.8tensor([[-1.2629,  0.3321,  0.2939,  0.9251, -0.9454, -0.7123, -0.9258,  0.6970,
         -0.2276,  1.1710]], device='cuda:0', grad_fn=<EmbeddingBackward>)
rosetensor([[ 0.9210, -0.4369, -1.7849, -0.8544, -1.8602, -0.3661, -0.1864, -0.9634,
          1.4363, -1.2856]], device='cuda:0', grad_fn=<EmbeddingBackward>)
necessitytensor([[-0.3475, -0.7211,  0.7522,  0.6350, -0.5199,  0.0099, -0.6888, -0.1161,
          0.1706, -0.0735]], device='cuda:0', grad_fn=<EmbeddingBackward>)
whethertensor([[ 1.0055e+00, -1.3913e-03, -6.6693e-02,  2.4514e+00,  8.2523e-01,
         -9.6310e-01, -9.7463e-01, -1.5241e+00, -1.6797e+00,  2.1276e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
(OPEC)tensor([[-0.7048,  0.1517,  0.5505,  0.1588, -0.6114,  2.1109,  1.0373, -0.5513,
          0.5194,  0.4987]], device='cuda:0', grad_fn=<EmbeddingBackward>)
do,tensor([[ 0.6462,  0.3409,  0.3037,  0.7722,  0.0311,  0.1110,  1.4765, -0.9427,
         -0.6906,  0.4390]], device='cuda:0', grad_fn=<EmbeddingBackward>)
purchasestensor([[-1.3154, -0.3830, -0.7346,  0.6502,  0.1366, -0.2206,  0.6577, -1.2375,
         -1.2996,  0.4037]], device='cuda:0', grad_fn=<EmbeddingBackward>)
shaftstensor([[-2.1417,  1.4281,  0.3304, -0.1146,  0.7798,  0.0364, -0.5562,  0.6983,
          0.5754, -0.3588]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ivarstensor([[ 1.5659,  1.1815,  0.5243, -1.1328, -0.5001,  1.2608, -2.0912,  0.2079,
          0.9438,  1.0537]], device='cuda:0', grad_fn=<EmbeddingBackward>)
immediatelytensor([[ 1.4173,  0.4594,  1.5239, -0.9504,  0.8422, -0.1258, -0.0469,  0.1063,
          1.0262,  0.6246]], device='cuda:0', grad_fn=<EmbeddingBackward>)
SkenarioLabstensor([[ 1.4722, -1.2995,  0.2403, -0.3938, -0.8918,  0.1713, -1.1707,  0.0517,
          0.0277,  0.2929]], device='cuda:0', grad_fn=<EmbeddingBackward>)
vantensor([[ 1.5653e-01, -9.1852e-04, -3.7390e-01, -3.4866e-01,  5.8370e-01,
          4.7884e-01, -8.8512e-01, -3.3106e-01, -6.0571e-01,  1.0903e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
addingtensor([[-1.3216,  0.3790,  0.2541, -0.4631, -0.7038,  0.2282,  0.6800, -0.2426,
         -0.8996,  1.7873]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Octobertensor([[-0.7599, -0.0444, -0.5691, -1.5992, -0.9669, -0.8528, -2.4849, -1.8025,
         -0.9926,  0.0408]], device='cuda:0', grad_fn=<EmbeddingBackward>)
inspections.tensor([[-1.1209, -0.4067,  1.3448, -0.1734, -0.4572,  0.6346,  1.5518, -0.3963,
          1.2110,  1.8514]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Officialstensor([[-0.4931, -0.1726, -1.0295, -0.4078, -1.2258, -1.7251,  0.1157,  1.2288,
          1.2555, -0.7638]], device='cuda:0', grad_fn=<EmbeddingBackward>)
heat-uptensor([[ 0.1073,  1.1825,  0.1061, -0.5335, -0.6862,  1.6245, -0.0868,  1.1156,
         -0.6692,  0.2210]], device='cuda:0', grad_fn=<EmbeddingBackward>)
meeting,tensor([[-2.0529, -0.8938, -1.6674, -0.0546,  0.5168, -0.2058, -0.8844,  0.8800,
         -0.0876, -0.5682]], device='cuda:0', grad_fn=<EmbeddingBackward>)
candidacytensor([[-0.2957, -1.0052,  1.1001,  0.2404, -0.4845, -1.3936, -1.4678, -1.0902,
          2.1304, -1.8845]], device='cuda:0', grad_fn=<EmbeddingBackward>)
positionstensor([[-1.7565, -0.9187,  1.2475, -0.5908,  0.8332, -0.3406,  2.0135,  0.4749,
          0.0884, -0.7918]], device='cuda:0', grad_fn=<EmbeddingBackward>)
OPEC?tensor([[ 1.6281, -1.4473,  0.1482, -0.1310,  0.5273, -1.2127,  1.3338, -1.0557,
         -0.2307,  1.1032]], device='cuda:0', grad_fn=<EmbeddingBackward>)
supporttensor([[ 1.5109, -0.3645, -0.9423, -0.5835, -0.8803, -0.3026, -0.7706,  1.6833,
         -0.8088,  0.9609]], device='cuda:0', grad_fn=<EmbeddingBackward>)
respectivetensor([[ 0.9436,  0.0576, -0.8663,  1.1032, -0.4773,  1.8299, -0.2516, -0.1353,
          0.0326,  0.6357]], device='cuda:0', grad_fn=<EmbeddingBackward>)
remindstensor([[-0.4340,  0.7968,  0.8549,  0.6102,  1.0329, -1.0987,  0.1592,  0.2036,
         -0.1000, -0.7119]], device='cuda:0', grad_fn=<EmbeddingBackward>)
LUXEMBOURG,tensor([[ 1.3102,  1.0007, -1.2243,  0.5061,  1.0954, -0.4117, -0.1706, -1.1732,
         -0.9884, -0.3642]], device='cuda:0', grad_fn=<EmbeddingBackward>)
detailtensor([[-0.5621, -0.3997,  1.2971,  0.4431, -0.0372,  1.2837,  1.0679,  2.2857,
          0.5854, -0.3279]], device='cuda:0', grad_fn=<EmbeddingBackward>)
unanimity.tensor([[ 0.8340,  0.6636,  2.2695,  0.2170, -0.1125, -0.7843,  0.4695, -0.3311,
          0.0083, -0.8096]], device='cuda:0', grad_fn=<EmbeddingBackward>)
thentensor([[-0.1935,  1.8802, -1.3687,  0.8197, -0.1544, -0.1552, -0.5897, -0.6609,
         -0.1422,  0.5768]], device='cuda:0', grad_fn=<EmbeddingBackward>)
askedtensor([[ 0.1032, -1.5620,  0.2973, -0.4031, -0.0785,  0.9850,  1.2500, -1.3778,
         -0.1173, -0.8077]], device='cuda:0', grad_fn=<EmbeddingBackward>)
borderstensor([[ 0.0869,  0.4569, -0.0424,  1.5033, -0.5837,  1.2736, -0.3342,  0.2329,
         -0.9918, -0.5532]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Goldmantensor([[ 0.9107,  0.1909,  2.7075,  2.5589, -1.7871,  0.4946,  1.8931, -0.4823,
         -1.7314,  0.4050]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Irvingtensor([[-0.8338,  0.8101,  0.8542, -1.6134, -0.6974,  0.2328,  0.3455,  0.0182,
         -0.5531,  0.6373]], device='cuda:0', grad_fn=<EmbeddingBackward>)
leveltensor([[-0.2711, -0.8920,  2.1378,  0.5541, -2.0681, -1.0603,  0.8702, -0.3241,
         -0.2828,  1.3118]], device='cuda:0', grad_fn=<EmbeddingBackward>)
(Wanttensor([[ 0.0091,  1.6709,  0.1268, -1.4528, -0.7442,  0.8754,  0.8941,  1.2831,
         -1.6622, -0.4470]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Commercetensor([[ 1.0156,  1.2465, -0.0447, -0.7868, -1.3475, -1.1642,  0.3262, -0.5831,
          0.5604, -1.6460]], device='cuda:0', grad_fn=<EmbeddingBackward>)
milliontensor([[ 6.2149e-01, -7.0981e-01, -6.5752e-01,  3.1054e-01,  2.2360e+00,
          9.6758e-01,  2.1592e-01, -1.7312e+00, -1.1050e+00,  8.3834e-04]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
increasedtensor([[ 0.1470,  0.8253, -0.3501,  0.2611, -0.7533, -0.5312, -0.4973,  1.5875,
          0.9391, -1.1060]], device='cuda:0', grad_fn=<EmbeddingBackward>)
confirmedtensor([[ 0.1447,  0.4943,  0.1901, -0.3718, -0.1410, -0.0836, -0.0636,  0.0798,
         -0.5679, -0.2021]], device='cuda:0', grad_fn=<EmbeddingBackward>)
officer.tensor([[-0.4675, -0.3814,  0.6729, -0.3387,  0.8015, -0.5231, -0.2234, -1.8087,
          0.0947, -0.6863]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Uldistensor([[ 1.6490, -1.6169, -0.2957, -0.6554, -0.3788, -0.7470, -0.8694, -1.2448,
         -0.2215,  0.2480]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Cavstensor([[ 0.4435, -1.6612, -0.0088,  1.0745, -0.7654,  0.3727, -0.6925, -0.1749,
          1.6500, -1.6541]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Baltictensor([[-1.6121, -0.5092,  1.6139,  0.2468, -1.2830, -2.2190,  0.3122, -0.8506,
         -2.3860,  1.2629]], device='cuda:0', grad_fn=<EmbeddingBackward>)
allowedtensor([[ 0.5195,  0.8080, -1.2601, -2.1389,  0.3312,  0.3640,  0.7606, -0.4995,
          0.6785,  0.8378]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Surveillancetensor([[ 0.9855,  1.3301, -2.2028, -0.1004,  0.7047, -0.4760, -0.6913, -2.0481,
          1.8303, -0.5998]], device='cuda:0', grad_fn=<EmbeddingBackward>)
(Rosselkhoznadzor)tensor([[ 0.9324, -2.1777, -0.4058,  0.2392, -1.8268, -0.0351, -1.8506, -0.4695,
          0.3264,  1.5843]], device='cuda:0', grad_fn=<EmbeddingBackward>)
soonertensor([[-0.9449, -0.0106,  0.4955,  0.0025,  0.1496, -1.0441,  0.1864,  0.1129,
          1.4924,  0.5421]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Raimondstensor([[-0.3867,  0.8098,  0.9870,  2.8662,  0.5231, -0.8734,  0.7476,  0.9557,
         -0.9890, -0.2348]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Donaldtensor([[ 1.2194, -1.1836,  1.6830,  1.3791,  2.1351,  0.8127, -0.8715, -0.1246,
          0.4098, -2.0436]], device='cuda:0', grad_fn=<EmbeddingBackward>)
buildingtensor([[-0.8516, -1.6901, -1.0386,  1.2908, -0.2793,  0.6903,  0.3583, -0.2355,
          1.1487,  0.3921]], device='cuda:0', grad_fn=<EmbeddingBackward>)
registeringtensor([[-0.6042, -1.7689,  1.9263, -0.0546, -0.1046, -0.0057, -0.7534, -0.6941,
          0.8935,  0.8867]], device='cuda:0', grad_fn=<EmbeddingBackward>)
enterprisestensor([[-0.1490,  0.0728,  1.5585,  0.4312,  0.0206,  1.3717, -1.9315,  0.5597,
         -1.2132, -1.5579]], device='cuda:0', grad_fn=<EmbeddingBackward>)
economy,tensor([[-1.2119, -0.6536, -0.0600,  1.0556,  0.3886, -0.6886, -0.0194, -0.3995,
         -0.7067, -1.1573]], device='cuda:0', grad_fn=<EmbeddingBackward>)
efforttensor([[ 0.2194,  0.4364,  0.8497,  1.2230,  1.1974, -0.1840, -0.1914, -2.1598,
          0.1888,  1.0803]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Praagtensor([[-0.5560, -0.2869, -0.0172, -0.2434,  2.0536,  0.7102,  0.5468, -0.6652,
          0.1155,  0.3839]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Statestensor([[-0.2859, -1.0380, -1.0485,  0.2704,  0.0029,  0.5819, -0.2365, -1.0202,
          0.4183, -1.4175]], device='cuda:0', grad_fn=<EmbeddingBackward>)
fullytensor([[-1.1408, -0.3055,  0.4060,  0.4986,  0.2182,  1.5525, -0.5824, -0.2608,
          0.9430, -0.1745]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Trump'stensor([[-0.6910,  0.0575, -0.2358,  1.3182,  1.0461, -0.7426, -0.7640, -1.4141,
         -0.7800,  1.4042]], device='cuda:0', grad_fn=<EmbeddingBackward>)
waytensor([[-0.5350,  0.3870, -0.3434, -0.4890, -0.6249,  1.7052,  0.0929,  0.2459,
          0.1271, -0.3145]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Rimsevicstensor([[-0.7248, -0.3365,  1.0994, -1.3442, -1.0461, -0.4667, -0.5483, -2.0502,
          1.7350,  0.1144]], device='cuda:0', grad_fn=<EmbeddingBackward>)
openedtensor([[ 1.3639, -0.7704,  1.3790, -0.2296, -1.0910,  0.4866, -1.6241,  0.5265,
          0.2168, -1.4787]], device='cuda:0', grad_fn=<EmbeddingBackward>)
confidenttensor([[ 1.4597, -0.9791,  0.7290, -0.7016, -1.1458,  1.4787,  0.2229, -0.6811,
          0.8857,  0.4845]], device='cuda:0', grad_fn=<EmbeddingBackward>)
TORONTO,tensor([[-0.5482,  0.8166,  0.2426,  0.0869,  1.8146,  0.7715, -2.1253, -0.8373,
         -0.6513, -0.0810]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"Theretensor([[-1.2518, -1.2423,  0.2006, -1.6584, -0.2111,  1.1429, -2.5227,  0.7548,
          1.4465, -1.3341]], device='cuda:0', grad_fn=<EmbeddingBackward>)
blacktensor([[ 0.2858, -0.1458,  0.4254,  0.0279,  1.0920,  0.7945, -0.1426, -1.1585,
         -0.1654, -1.1365]], device='cuda:0', grad_fn=<EmbeddingBackward>)
volleyballtensor([[-0.2343, -0.6525, -0.4942, -0.2782,  0.2266, -0.1988,  1.0663, -1.2868,
         -0.5402,  1.2906]], device='cuda:0', grad_fn=<EmbeddingBackward>)
northerlytensor([[ 1.0901, -0.9411,  2.1763, -1.0364,  1.4105,  1.1651,  0.3019, -0.6191,
         -0.2794, -0.8185]], device='cuda:0', grad_fn=<EmbeddingBackward>)
and,tensor([[ 0.4319,  0.0966,  2.0927, -0.4480, -0.2215,  1.4124,  0.1593,  0.5986,
          1.2580, -1.5281]], device='cuda:0', grad_fn=<EmbeddingBackward>)
beachtensor([[ 0.9782, -0.6080, -0.0141, -0.6037,  0.2967, -0.5127, -0.1591, -0.1021,
          0.2743,  2.2444]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Steventensor([[ 1.6500,  1.6947, -0.9469,  1.5119, -1.4244, -0.2876, -0.1942,  1.4728,
         -0.8375, -0.2199]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Novtensor([[-1.2975, -0.5130, -0.5839, -0.9741, -0.0813,  0.0223, -1.2114, -0.2707,
         -0.1638, -0.4714]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Service,tensor([[ 0.0654, -1.1221, -1.1977,  0.6601, -0.7962,  2.0924,  1.9884,  1.4150,
         -0.5980, -0.2016]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Seatensor([[ 1.1631,  0.4766,  1.3181, -0.7746,  1.2720, -0.8685,  0.3825,  1.8079,
         -0.9895, -0.0199]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Youtensor([[ 0.7083,  0.7677, -1.6390,  0.1559,  0.2117,  0.1454, -1.8449,  1.3225,
          0.2283, -0.0501]], device='cuda:0', grad_fn=<EmbeddingBackward>)
structuraltensor([[-0.3213,  2.0055,  0.7049, -0.3970,  1.3756, -0.4452,  0.1685,  0.2131,
         -0.4847,  1.1345]], device='cuda:0', grad_fn=<EmbeddingBackward>)
festivaltensor([[ 1.1299, -0.8577, -0.7684,  1.3222,  0.3142,  1.9468, -1.2065, -0.2426,
          1.7344,  0.1623]], device='cuda:0', grad_fn=<EmbeddingBackward>)
frameworktensor([[-2.3229,  1.6082,  0.3088, -0.4649, -0.2612,  0.3619,  0.2303, -0.0566,
          3.5208, -0.4289]], device='cuda:0', grad_fn=<EmbeddingBackward>)
jobs,tensor([[ 0.5622,  0.8880, -0.5038, -1.4468,  0.5810,  0.0244, -0.0687,  0.6949,
          0.6170, -0.9862]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Service'stensor([[-0.8926, -0.5909,  2.2013, -0.0875,  2.8346,  0.4857,  0.5972, -0.9445,
         -0.5427, -1.7813]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Jean-Claudetensor([[ 0.6681,  1.2964, -1.1539,  1.4751,  1.4986, -0.0112, -2.0173,  1.2736,
          0.0939,  0.8064]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Environment,tensor([[ 0.8018,  0.3210, -1.1412, -0.4234,  0.8460, -0.7617, -0.4502, -0.6046,
         -0.9741,  0.1010]], device='cuda:0', grad_fn=<EmbeddingBackward>)
euro,tensor([[ 1.0189, -1.0803,  0.3977, -0.8400, -0.8864, -0.7448, -1.3181,  0.3810,
          0.3065,  0.5798]], device='cuda:0', grad_fn=<EmbeddingBackward>)
night,tensor([[ 0.4423,  1.4436, -0.0334, -0.3110,  0.0162, -1.2104,  2.3015, -1.2182,
          0.6443,  0.2955]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Fromtensor([[-0.5877, -0.7741,  0.7071, -0.8922, -0.9061,  0.8697,  1.6590,  1.5271,
         -0.5590, -0.4464]], device='cuda:0', grad_fn=<EmbeddingBackward>)
aroundtensor([[-1.0215, -1.8409, -0.1602,  2.0295,  0.7625, -0.0935, -1.6323,  0.6575,
         -1.1955, -1.8792]], device='cuda:0', grad_fn=<EmbeddingBackward>)
dealstensor([[-1.6871,  0.8716, -1.4299,  0.9673,  0.5998,  1.2214,  0.1038,  0.1062,
         -0.2883, -0.4745]], device='cuda:0', grad_fn=<EmbeddingBackward>)
budgettensor([[-0.3804, -0.7135, -0.0218, -0.1458,  0.7707, -2.1162,  0.2075, -1.2198,
          0.6689, -0.4462]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"Iftensor([[-0.9168,  0.4432,  0.7284, -0.4466, -2.0973,  0.4481,  1.0030, -0.0435,
         -0.0062,  0.2761]], device='cuda:0', grad_fn=<EmbeddingBackward>)
taketensor([[ 0.1469,  0.1019, -1.0417, -0.7993,  0.5227,  1.1389, -0.7293, -0.0377,
          2.3553,  0.2711]], device='cuda:0', grad_fn=<EmbeddingBackward>)
circumstancestensor([[-1.1879,  1.1432, -0.4249,  0.5872,  1.4577,  0.0190,  0.8158, -0.2390,
          1.5796, -1.0530]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Equitytensor([[ 1.1525,  0.0144, -0.0704,  1.0033, -1.8318, -1.3562,  1.5632,  1.3957,
         -1.0393, -1.5158]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ownertensor([[-0.3112,  0.0309, -0.0560,  0.3006,  0.5081,  1.3437,  0.2885,  0.2469,
          0.8750,  0.0517]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Amaqtensor([[-1.1291, -1.9542,  1.5831,  0.1178, -1.2808,  0.9121, -0.4343, -0.6677,
          0.6194,  1.8354]], device='cuda:0', grad_fn=<EmbeddingBackward>)
teartensor([[-0.0836,  2.4356, -1.3117, -0.9748, -0.7419,  0.7632,  0.5069, -0.3833,
         -0.5628,  1.0584]], device='cuda:0', grad_fn=<EmbeddingBackward>)
childhoodtensor([[-0.1259, -0.4779, -3.3430, -0.3856, -0.3011, -0.5564, -0.1148,  0.6320,
          0.0666, -1.2562]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Karavela,tensor([[-0.2075, -0.1850,  1.0154,  0.5785,  3.0830,  0.0298, -1.0476,  1.0446,
          1.1128, -1.8854]], device='cuda:0', grad_fn=<EmbeddingBackward>)
whotensor([[ 0.6053,  0.5949, -0.9633, -1.0786,  1.0752, -0.0057,  0.1496,  0.3222,
          1.6292,  0.4844]], device='cuda:0', grad_fn=<EmbeddingBackward>)
remunerationtensor([[ 0.9803, -0.4996, -0.1057, -0.0684, -0.3454, -0.7242,  1.5546, -1.9147,
          0.5193,  1.1362]], device='cuda:0', grad_fn=<EmbeddingBackward>)
affectedtensor([[ 1.2853, -2.6277,  1.2458,  0.8164, -0.7909,  0.1934, -0.3535, -0.0243,
          1.0137, -0.0702]], device='cuda:0', grad_fn=<EmbeddingBackward>)
consumertensor([[-0.0026, -0.9004, -0.8324,  0.9348,  0.5784,  0.0178,  0.8703, -1.9662,
          0.9809,  0.7796]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Outtensor([[-0.5990,  0.8528,  0.3170,  1.0737, -0.8564, -0.4915,  0.2092, -1.3973,
         -0.7354, -0.3717]], device='cuda:0', grad_fn=<EmbeddingBackward>)
President-electtensor([[ 2.4887, -0.3562, -0.4192, -1.4939,  0.7431, -0.1809, -0.9333, -0.0724,
          0.2115, -0.1971]], device='cuda:0', grad_fn=<EmbeddingBackward>)
raintensor([[ 0.4893, -2.0510,  0.1323,  0.3412,  0.1690,  1.3778,  1.8280,  1.2158,
          0.6473, -0.7890]], device='cuda:0', grad_fn=<EmbeddingBackward>)
envisagestensor([[-0.2815, -0.8791,  0.2681, -0.6996, -0.3780, -0.9519, -2.1826, -0.4084,
          0.5770, -0.6447]], device='cuda:0', grad_fn=<EmbeddingBackward>)
intermodaltensor([[-0.1847, -1.6673,  0.1744, -0.4756, -1.5148, -0.3823,  1.6374,  0.1288,
          0.7051,  1.4651]], device='cuda:0', grad_fn=<EmbeddingBackward>)
fightertensor([[ 0.8151, -2.4349,  2.3134, -2.0544,  0.5851,  0.8226,  0.6901,  1.4414,
         -0.6940, -1.6266]], device='cuda:0', grad_fn=<EmbeddingBackward>)
causedtensor([[-0.6337, -0.9215,  0.2700, -1.6476, -1.1037,  1.4112, -0.6909, -1.7495,
          0.1612,  0.6615]], device='cuda:0', grad_fn=<EmbeddingBackward>)
lettensor([[-0.5071, -0.2092, -0.3929, -0.8270,  0.8592,  1.2720,  1.4014, -0.2505,
          0.2152, -1.8228]], device='cuda:0', grad_fn=<EmbeddingBackward>)
interview.tensor([[ 0.1991,  0.9279, -2.0357,  0.3880,  0.4383,  0.1405,  2.4703, -1.0816,
          1.4729,  1.2574]], device='cuda:0', grad_fn=<EmbeddingBackward>)
matters,tensor([[ 0.3513,  1.6514,  0.3503,  1.0009,  1.1145, -0.0099,  0.0189, -0.1477,
         -0.3991,  0.8587]], device='cuda:0', grad_fn=<EmbeddingBackward>)
halttensor([[-0.6191,  0.6580, -0.6273, -0.0025,  0.1073,  0.8398, -1.1727,  0.4241,
         -0.4408, -1.0387]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Meeuwsen,tensor([[-2.2281,  0.8669,  0.7642,  0.0241, -0.6131,  1.1904,  0.6635,  2.0181,
          1.0718,  1.3371]], device='cuda:0', grad_fn=<EmbeddingBackward>)
exchangetensor([[-0.3034, -0.1720, -0.4170,  0.2054, -2.1786,  0.0614, -0.0907, -0.7614,
         -1.9558, -0.6916]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Jong-Un'stensor([[ 1.4938, -1.3938, -0.0416, -0.4724,  1.0918,  0.9748,  0.5404,  0.3971,
         -1.3062,  0.1530]], device='cuda:0', grad_fn=<EmbeddingBackward>)
revived,tensor([[-0.5972,  0.4820,  0.4481, -0.2931, -0.0134,  0.3339,  0.2985,  2.5749,
          1.3809,  0.5422]], device='cuda:0', grad_fn=<EmbeddingBackward>)
votedtensor([[ 1.0730,  0.4270,  0.4082, -0.9184,  0.3854,  0.2967,  0.7113, -0.1459,
          0.6425, -2.4101]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ledtensor([[-0.0099, -0.5325,  0.0057,  0.9881,  0.0024, -1.4556, -1.2573, -0.8278,
          0.5176,  0.8740]], device='cuda:0', grad_fn=<EmbeddingBackward>)
firmtensor([[-6.4056e-01, -5.1448e-01,  2.0258e-04,  1.1602e+00,  1.4330e-02,
         -2.8714e-01,  3.5034e-01, -1.6002e+00,  4.8066e-01,  1.2347e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
worrytensor([[-0.3361,  0.5331, -0.2546, -0.6020, -2.4184,  1.2060, -0.1809,  0.2890,
         -0.7493, -0.6438]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Foreigntensor([[-1.4497,  0.4508,  1.8188, -0.4159,  1.1585, -2.1172,  1.1916,  0.6284,
         -0.1851,  0.0927]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Sciencetensor([[-0.2856,  0.7288, -0.5938,  0.5741, -1.6810, -0.7291,  1.2416, -0.7178,
         -0.1173,  1.4486]], device='cuda:0', grad_fn=<EmbeddingBackward>)
istensor([[-0.1309, -2.0963, -1.7979,  2.0474,  0.0625, -2.1684,  3.3659, -1.3878,
          0.3718, -0.6460]], device='cuda:0', grad_fn=<EmbeddingBackward>)
economictensor([[ 0.5478, -0.3480,  0.9285, -0.0750,  0.1399, -0.0148, -1.8945, -1.0261,
         -1.5285,  1.0218]], device='cuda:0', grad_fn=<EmbeddingBackward>)
highlytensor([[ 0.8620, -0.1543,  0.9689,  0.3376, -1.7198,  1.1968,  0.5883, -0.9385,
          0.3915,  2.4600]], device='cuda:0', grad_fn=<EmbeddingBackward>)
strugglingtensor([[-0.0082,  1.1786, -1.3537, -0.2669, -0.4284,  1.0912, -0.5287,  1.0210,
         -0.6557,  0.4792]], device='cuda:0', grad_fn=<EmbeddingBackward>)
unprecedentedtensor([[-1.0930, -0.2404, -0.0679,  0.3075,  0.3418, -1.0253,  1.0806, -0.3275,
          0.3075,  0.4098]], device='cuda:0', grad_fn=<EmbeddingBackward>)
allowtensor([[ 0.0797,  1.5274,  0.9002,  0.5515, -0.0766, -0.7345, -0.7994, -0.8917,
         -0.7924,  0.6742]], device='cuda:0', grad_fn=<EmbeddingBackward>)
diasporatensor([[ 1.8238, -0.7427,  0.2218,  0.0860, -1.3838, -0.8868,  0.8332, -0.1772,
         -0.3333, -1.4010]], device='cuda:0', grad_fn=<EmbeddingBackward>)
painfultensor([[-0.1792, -0.1114, -0.0828,  0.2893, -0.1380, -0.6715,  0.7426,  0.6034,
         -0.3123,  0.5308]], device='cuda:0', grad_fn=<EmbeddingBackward>)
positivetensor([[-2.1913e-03,  2.2434e+00,  2.2463e+00,  4.7414e-01,  1.1474e-01,
          5.0032e-01,  1.3112e+00,  5.1821e-01,  1.7768e-01,  1.3234e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
3:1tensor([[ 1.9810,  0.0711, -0.2900, -0.8704,  0.6215, -1.3990,  0.6468,  0.8788,
          0.6721,  1.0642]], device='cuda:0', grad_fn=<EmbeddingBackward>)
expropriatedtensor([[-1.4470, -1.2234, -1.5290,  0.6424, -0.2274,  0.4246,  1.3779,  0.7697,
         -0.7236, -0.5198]], device='cuda:0', grad_fn=<EmbeddingBackward>)
antensor([[ 0.5578, -0.3199,  0.2639,  1.1576, -1.1237,  0.3451, -1.6568,  0.0272,
          1.7353, -0.1587]], device='cuda:0', grad_fn=<EmbeddingBackward>)
threetensor([[ 0.8455,  0.8319,  0.1604,  2.1570,  0.0478,  1.6676,  2.0960, -0.5102,
          1.2450, -1.1951]], device='cuda:0', grad_fn=<EmbeddingBackward>)
growingtensor([[ 1.1871, -2.1896,  0.2541,  0.4768,  0.7285, -1.2053,  0.3650,  0.5732,
          0.4119,  0.9355]], device='cuda:0', grad_fn=<EmbeddingBackward>)
production,tensor([[ 0.7483,  0.3137, -1.6917,  0.5052,  2.2943,  1.1197, -0.9091,  1.5008,
          1.7595,  0.4640]], device='cuda:0', grad_fn=<EmbeddingBackward>)
transitiontensor([[ 0.6469,  1.0315, -2.0382,  0.5667,  1.6224, -0.9590,  1.3661,  0.5547,
         -0.0372, -1.0679]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Swedishtensor([[-1.8253, -0.7140,  1.1034,  0.1882, -1.2732, -1.2274, -0.4777,  0.0823,
          0.1095, -0.3422]], device='cuda:0', grad_fn=<EmbeddingBackward>)
toptensor([[-0.6848, -0.0472, -1.1159,  1.1349,  1.5396,  1.5137,  1.6841,  0.3729,
         -1.0584,  0.0551]], device='cuda:0', grad_fn=<EmbeddingBackward>)
expandingtensor([[-1.1449, -1.3833, -0.2694, -0.7518, -1.2139, -1.3430,  0.8809,  0.2348,
         -1.0344,  0.3742]], device='cuda:0', grad_fn=<EmbeddingBackward>)
IKEAtensor([[ 0.3545, -0.9952,  1.0099, -1.0538, -0.1436,  1.1771,  0.1788, -1.2248,
         -0.0692, -0.0087]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Leaguetensor([[ 1.3741,  0.9935, -0.7985, -1.1952, -1.9001, -0.6868, -0.4463, -0.2590,
         -1.5420,  0.7143]], device='cuda:0', grad_fn=<EmbeddingBackward>)
discussed,tensor([[-0.2343, -1.5456,  0.4515,  0.7332, -0.5931,  0.9851, -0.0284,  1.3931,
         -0.5586, -1.5887]], device='cuda:0', grad_fn=<EmbeddingBackward>)
warshipstensor([[ 2.0791,  0.4891,  0.1191, -0.0342, -0.9018,  0.4207, -0.3983,  0.4805,
         -0.9623, -1.3822]], device='cuda:0', grad_fn=<EmbeddingBackward>)
film,tensor([[-0.0249, -0.2576,  0.3139,  0.6562, -0.5409,  0.1608,  1.7058, -0.6472,
         -0.1970, -0.2700]], device='cuda:0', grad_fn=<EmbeddingBackward>)
2007),tensor([[-0.8508,  0.8254, -0.0686,  0.7347, -0.1643, -0.2023,  0.8954,  0.4201,
         -1.4364, -0.7955]], device='cuda:0', grad_fn=<EmbeddingBackward>)
commontensor([[-0.2758,  1.0743,  1.0084, -1.9463,  0.7952,  0.0145, -3.4618,  1.9945,
         -0.3257,  1.1813]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ontensor([[-0.5734, -1.5288,  0.8234, -0.5965,  1.0321, -1.1998, -1.2444,  1.4258,
         -2.2523, -2.0281]], device='cuda:0', grad_fn=<EmbeddingBackward>)
developingtensor([[-1.4542, -0.3071,  0.2401,  0.7421, -2.5745, -1.4867, -0.4426,  0.1843,
          1.5231, -0.0123]], device='cuda:0', grad_fn=<EmbeddingBackward>)
completedtensor([[ 1.2655,  0.8163, -1.4348,  0.1185, -0.6376,  1.0969,  1.7705,  1.1148,
          0.9646, -1.1793]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Stanevics,tensor([[ 0.0653,  0.2270,  0.3158, -0.5267, -2.0787, -1.5872,  0.7159, -1.8258,
          1.0401,  0.3813]], device='cuda:0', grad_fn=<EmbeddingBackward>)
development.tensor([[-0.7173, -0.7179, -1.7631,  0.4599,  0.1368, -1.2129,  0.6057, -1.3007,
         -0.0677, -2.1804]], device='cuda:0', grad_fn=<EmbeddingBackward>)
formattensor([[ 1.8835,  1.0876,  0.3646,  0.4637,  1.0275, -1.7666,  0.7176, -1.7367,
         -1.5518, -1.2022]], device='cuda:0', grad_fn=<EmbeddingBackward>)
letterstensor([[-1.1871, -1.0585,  0.3032,  0.3950,  0.0763, -0.2942, -0.2378, -0.0899,
          1.2404, -0.8954]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reforms,tensor([[-0.8645,  0.2841,  0.3281, -0.3408, -0.9160,  1.8307,  1.0689, -0.8794,
          0.7962, -0.0529]], device='cuda:0', grad_fn=<EmbeddingBackward>)
MPstensor([[-0.7631, -0.5932, -1.0363,  0.6682, -0.7758,  0.8169,  1.0665,  2.7432,
         -1.0936,  1.8505]], device='cuda:0', grad_fn=<EmbeddingBackward>)
tomorrow,tensor([[ 2.7403,  0.3830, -0.8173,  0.4048,  0.0633,  0.5558, -1.7451,  1.6040,
         -0.3339,  1.7141]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Brice.tensor([[ 2.2854,  2.1868,  1.0701, -0.9034,  2.0582,  0.4098, -1.0854,  0.8910,
          0.2935, -0.9932]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Foodtensor([[-0.7121,  0.5736,  1.7015,  0.2962,  0.5720,  1.2961, -1.6210, -0.4506,
          0.6030, -1.0229]], device='cuda:0', grad_fn=<EmbeddingBackward>)
9,000.tensor([[-1.4424, -1.0159,  0.3380, -0.9047,  0.9197, -0.5404,  1.2422,  0.3335,
          0.0099, -0.9787]], device='cuda:0', grad_fn=<EmbeddingBackward>)
region.tensor([[ 0.8372, -0.3714,  0.4217,  0.0755, -0.2853, -0.0408,  0.2556,  1.5028,
         -0.1562,  0.1981]], device='cuda:0', grad_fn=<EmbeddingBackward>)
organizationtensor([[ 0.4161, -0.1804, -1.7254,  1.1489, -0.3264, -0.1579, -0.8641, -0.7271,
          0.7773,  0.3741]], device='cuda:0', grad_fn=<EmbeddingBackward>)
bringtensor([[ 0.0096,  1.6118,  0.5152,  1.8639, -1.0278,  0.0034,  0.4288, -1.6342,
         -1.4836, -1.0110]], device='cuda:0', grad_fn=<EmbeddingBackward>)
believingtensor([[ 0.6118,  1.2625, -0.0792,  1.1480,  1.9363,  0.5732, -0.5701,  1.5276,
         -0.7144, -0.0297]], device='cuda:0', grad_fn=<EmbeddingBackward>)
state'stensor([[-1.0809, -0.0133,  1.2254,  1.6607,  0.8225,  0.8150,  0.3593,  0.5667,
          0.2231, -0.3755]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Keninstensor([[-1.6363,  0.6140,  2.3676, -0.5529, -1.2060, -0.6917,  0.0057,  0.7437,
          0.5784,  1.2479]], device='cuda:0', grad_fn=<EmbeddingBackward>)
assiststensor([[ 0.8037,  0.8436, -0.8683,  1.1876, -0.4510,  0.8463,  1.0954,  0.7370,
         -0.7081,  0.4907]], device='cuda:0', grad_fn=<EmbeddingBackward>)
coalitiontensor([[-0.0590,  0.3958,  0.8779,  0.2073, -0.0936, -1.7224,  1.0408, -1.8958,
          0.7133, -0.6059]], device='cuda:0', grad_fn=<EmbeddingBackward>)
planestensor([[ 0.7270, -0.7208,  0.3578, -0.5462,  0.5156,  1.7466,  0.0069, -0.5832,
          0.4089,  1.5021]], device='cuda:0', grad_fn=<EmbeddingBackward>)
uptensor([[-1.8790, -0.8061, -0.6682,  1.8037,  2.6241, -0.2937, -1.0598, -0.4985,
          1.1538, -0.5337]], device='cuda:0', grad_fn=<EmbeddingBackward>)
markstensor([[ 1.1628, -0.1185, -0.5407,  0.1114, -1.8742,  1.1962,  0.3855,  1.4985,
         -0.1755, -1.9052]], device='cuda:0', grad_fn=<EmbeddingBackward>)
bureaucrats,tensor([[ 0.8363,  0.4886,  0.4428,  0.6764, -2.0921, -0.3009, -0.5546, -0.1693,
          0.1228,  2.2194]], device='cuda:0', grad_fn=<EmbeddingBackward>)
festival'stensor([[-0.2920, -1.1320,  1.1524,  0.8467, -0.3881, -0.2420, -0.4996,  2.1880,
          0.3936, -0.4480]], device='cuda:0', grad_fn=<EmbeddingBackward>)
EUtensor([[ 0.1510,  0.1965,  2.4148,  0.6327, -1.1162, -0.1208, -1.0713, -1.4800,
         -1.0140, -0.6210]], device='cuda:0', grad_fn=<EmbeddingBackward>)
goodtensor([[ 0.9138,  0.5116,  1.4826, -0.5092, -0.2559, -2.0080, -1.5224, -1.1408,
         -1.3277,  1.6383]], device='cuda:0', grad_fn=<EmbeddingBackward>)
territorialtensor([[ 0.9974,  1.3490,  0.7060,  0.4975,  1.2188, -0.4051, -0.4123,  0.0347,
          0.2539,  0.3185]], device='cuda:0', grad_fn=<EmbeddingBackward>)
amtensor([[-1.0694, -0.4289, -0.8765,  0.8963,  0.2424, -0.4363, -0.3053, -0.8227,
          0.7942, -0.4083]], device='cuda:0', grad_fn=<EmbeddingBackward>)
quitetensor([[-0.7821,  1.1449,  0.6028,  0.0940, -0.1164, -2.0892,  0.9394, -0.0107,
          0.5585,  0.6302]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Riga,tensor([[-0.0685, -0.2237, -0.2777,  0.0801,  0.0880, -0.0428,  1.0176,  1.9244,
         -1.4450, -0.9833]], device='cuda:0', grad_fn=<EmbeddingBackward>)
mediatensor([[-0.1294, -0.9044, -1.4529,  0.4108,  1.3462,  0.4344,  0.6273, -0.7455,
          0.0475,  1.1478]], device='cuda:0', grad_fn=<EmbeddingBackward>)
transponderstensor([[-0.0427, -0.6078,  0.7242, -0.3091,  1.6732,  0.1545, -1.5722, -0.0552,
          2.1730, -0.1108]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Julytensor([[ 0.0032, -1.0563, -0.0500,  0.0969,  1.2073, -0.6406, -0.0026,  0.6050,
          1.1457,  1.5392]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Notensor([[ 0.1281,  2.4550,  0.8664, -1.5732,  1.0564,  0.8211, -0.7674,  1.5322,
         -0.3506, -0.7603]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Murniecetensor([[ 0.4647,  1.0637,  0.9502,  0.4345,  0.1558, -1.3103,  2.7415,  0.4003,
          0.6379, -0.9262]], device='cuda:0', grad_fn=<EmbeddingBackward>)
taxtensor([[-1.5796,  0.0459, -1.4962,  1.0781,  1.7376, -0.1447,  0.6680, -0.2980,
         -0.6145, -0.3129]], device='cuda:0', grad_fn=<EmbeddingBackward>)
28.5tensor([[-0.4622,  0.1605, -0.2845, -2.6980, -0.0885,  0.2965,  0.1952, -0.2980,
         -0.7295, -1.3545]], device='cuda:0', grad_fn=<EmbeddingBackward>)
decidedtensor([[ 0.7663,  0.0250,  0.3941,  0.5814,  2.1562,  0.2245, -0.6728, -0.3487,
          0.2023, -0.4100]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Tempstensor([[ 0.6136,  2.0158,  0.0990,  0.2374, -0.1609,  0.9155, -1.4768, -2.3428,
         -2.1726,  2.3418]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Solidaritytensor([[ 1.7369, -0.9436, -0.8571, -0.5933,  1.5638, -0.4525,  1.8857,  0.1367,
         -0.7702,  0.9695]], device='cuda:0', grad_fn=<EmbeddingBackward>)
optimal,tensor([[-0.6780, -0.8448, -0.4354,  1.0511, -0.2158,  0.4128,  1.3164,  0.6165,
         -1.0889,  0.1634]], device='cuda:0', grad_fn=<EmbeddingBackward>)
conductedtensor([[-1.0790, -1.7302, -2.0208,  0.0236, -0.7499,  0.5619, -0.2154,  2.5159,
         -1.0509,  0.7659]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reactingtensor([[-0.2938, -1.1987,  0.4400,  0.7900, -0.7930, -0.9536, -0.6622,  0.5963,
          0.2514,  1.3370]], device='cuda:0', grad_fn=<EmbeddingBackward>)
areastensor([[-0.6814, -0.1184, -0.1823, -2.3230, -0.0065,  1.0822,  0.1465,  2.0194,
          1.1033, -0.3951]], device='cuda:0', grad_fn=<EmbeddingBackward>)
movingtensor([[-0.4129,  0.9027,  0.2167,  1.7290, -0.7946, -0.8473,  0.4913, -0.0597,
          0.1664,  0.7065]], device='cuda:0', grad_fn=<EmbeddingBackward>)
startuptensor([[ 0.7834,  1.3659, -0.1023, -0.8820,  0.3013,  1.2473,  0.4344, -0.1986,
          0.5773, -0.5827]], device='cuda:0', grad_fn=<EmbeddingBackward>)
proposaltensor([[-0.2265,  0.9056,  0.1033,  0.6410,  1.1504, -0.4800, -1.1104, -1.3890,
          0.7835,  1.4080]], device='cuda:0', grad_fn=<EmbeddingBackward>)
company.tensor([[ 0.7587,  0.1650,  0.3519, -1.0492, -0.2514,  0.9870, -1.8257,  1.2669,
         -0.8413, -1.0958]], device='cuda:0', grad_fn=<EmbeddingBackward>)
world.tensor([[ 0.9171, -0.9039, -0.4533, -0.2219, -1.2373, -0.2403, -0.2521,  1.8549,
         -1.2061,  1.4700]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ambitionstensor([[ 0.2367,  0.4160, -0.4803, -0.4683, -0.1776, -0.2964,  0.1381, -0.1784,
         -0.0637,  0.3745]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Russiantensor([[ 0.8720, -1.4227, -0.0740,  0.6062, -0.6013,  1.6329, -0.0566, -1.5464,
          0.9653, -1.9596]], device='cuda:0', grad_fn=<EmbeddingBackward>)
transportation.tensor([[-0.4667, -0.5952, -0.2271, -0.2918,  0.5820,  0.6954,  2.3760,  1.6386,
         -0.4060,  0.2709]], device='cuda:0', grad_fn=<EmbeddingBackward>)
lesstensor([[ 0.2261,  1.0667,  0.1569, -0.4108,  2.2967, -0.5854,  0.3048,  1.8205,
         -0.7602, -0.1868]], device='cuda:0', grad_fn=<EmbeddingBackward>)
strictertensor([[-0.8873, -1.2380,  1.1309,  1.1035, -0.3445, -0.8088, -1.4434,  0.6133,
         -1.9354, -0.0671]], device='cuda:0', grad_fn=<EmbeddingBackward>)
referendumtensor([[-0.9594,  1.2987, -1.3467,  0.5677, -1.7215,  0.6953, -0.2483, -0.5858,
          0.7548, -0.3181]], device='cuda:0', grad_fn=<EmbeddingBackward>)
agreedtensor([[-2.0357,  0.9578, -0.8192,  0.0882, -0.5765,  0.6471, -0.2123,  0.0540,
          0.6043, -1.0076]], device='cuda:0', grad_fn=<EmbeddingBackward>)
2016tensor([[-0.0800, -0.2031,  0.6156,  0.3629, -1.7203, -0.1001,  0.5597,  1.3136,
          0.5452,  0.2708]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Valleytensor([[ 0.6278,  2.0655,  0.0848,  0.0319, -0.8271, -0.3753, -1.6003,  0.7354,
          1.1612,  0.7944]], device='cuda:0', grad_fn=<EmbeddingBackward>)
brands.tensor([[-0.0684,  0.7093, -0.1703, -0.4656, -0.0373,  0.0851,  1.1578,  0.8887,
          0.3734, -2.6865]], device='cuda:0', grad_fn=<EmbeddingBackward>)
(AFP)tensor([[ 0.0422,  0.1302, -1.3269, -1.6324, -0.4256,  0.2373, -0.3234,  1.3790,
         -1.1991,  1.5227]], device='cuda:0', grad_fn=<EmbeddingBackward>)
200tensor([[ 1.1656, -0.7818,  0.5101,  1.3302, -0.5847,  0.0507,  0.1468,  0.0585,
          0.9212,  1.2598]], device='cuda:0', grad_fn=<EmbeddingBackward>)
weretensor([[-0.2210, -0.5807,  0.4448,  0.1360, -2.5013, -0.4026, -0.3374, -0.7168,
         -0.2902,  1.1962]], device='cuda:0', grad_fn=<EmbeddingBackward>)
oncetensor([[-0.8031,  1.2551, -1.1595, -1.3498, -0.3753,  0.3321,  0.0873, -0.9931,
          0.3830,  0.1535]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ourtensor([[ 1.3996,  0.4993, -0.6946,  0.6426,  1.4355, -2.2194,  0.0735,  0.0887,
          0.5739,  1.9888]], device='cuda:0', grad_fn=<EmbeddingBackward>)
salariestensor([[ 1.4325, -0.8588,  1.1953, -0.9697,  1.1021,  0.2021,  0.6697, -0.4236,
          0.5491,  0.9963]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Everythingtensor([[-0.1302,  1.0110, -1.5566, -1.6991,  0.9287, -1.3227,  1.0193,  1.9055,
          0.1814, -0.5256]], device='cuda:0', grad_fn=<EmbeddingBackward>)
delvestensor([[-0.5102, -1.3158,  0.1878, -1.7808,  0.6208,  0.8085, -0.7176,  0.5403,
         -0.0392, -0.4321]], device='cuda:0', grad_fn=<EmbeddingBackward>)
memories.tensor([[ 0.3984, -0.7093,  0.2577,  1.2224,  1.3544, -1.7140,  0.5852,  0.6887,
          1.6770,  0.1990]], device='cuda:0', grad_fn=<EmbeddingBackward>)
skilltensor([[ 0.4180,  0.5488, -0.0980,  0.7022,  0.2296,  1.1359,  0.3331, -0.3667,
         -0.7943, -0.8698]], device='cuda:0', grad_fn=<EmbeddingBackward>)
representativetensor([[ 0.7441,  0.4478, -0.2775, -1.1556, -0.8515, -1.0816, -0.5414,  1.6513,
         -0.3530, -0.9392]], device='cuda:0', grad_fn=<EmbeddingBackward>)
foundationstensor([[ 1.2563,  0.4000,  0.7519, -0.6048,  1.3288, -0.6942, -0.2395, -0.6135,
         -0.1539,  0.9155]], device='cuda:0', grad_fn=<EmbeddingBackward>)
winnertensor([[ 1.3644, -0.7171, -1.2553,  0.0616, -0.7110, -0.9507, -1.1320, -0.4292,
         -0.6564, -2.3039]], device='cuda:0', grad_fn=<EmbeddingBackward>)
universities,tensor([[-0.4960, -0.7193, -0.1859,  1.3440, -1.1350, -0.9758, -0.1837,  0.1994,
         -1.3095, -0.0716]], device='cuda:0', grad_fn=<EmbeddingBackward>)
agreestensor([[ 0.9485,  0.4090, -0.5234,  0.3054, -0.6394, -0.1963,  1.0150, -1.4508,
          0.3416,  1.8633]], device='cuda:0', grad_fn=<EmbeddingBackward>)
northtensor([[-0.5355, -0.1066,  0.3631, -1.1141, -0.0822,  0.0540,  1.5876,  0.2251,
          0.7754,  0.8621]], device='cuda:0', grad_fn=<EmbeddingBackward>)
brothels,tensor([[ 0.7833,  1.6461, -1.4912, -2.0884,  0.0072, -1.4225, -0.5020,  0.4853,
          0.2085,  1.1259]], device='cuda:0', grad_fn=<EmbeddingBackward>)
lost.tensor([[ 1.0644, -0.1423, -0.2540,  0.3770, -0.6687, -1.8245,  0.5203, -0.9589,
          0.9990,  0.3611]], device='cuda:0', grad_fn=<EmbeddingBackward>)
extendtensor([[-0.5923, -1.4421,  0.7615, -1.5490, -1.2588, -1.1422, -1.5726,  0.8467,
          0.1862,  0.4881]], device='cuda:0', grad_fn=<EmbeddingBackward>)
4.2tensor([[-1.4763, -0.3573, -1.3644,  1.0663,  0.7982,  1.0149,  0.4133, -0.6138,
          1.2587, -0.5585]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Economic,tensor([[-1.0845, -0.9278, -1.2674, -0.2266,  1.7158, -0.9300,  1.0449,  0.9520,
         -2.4744,  0.4551]], device='cuda:0', grad_fn=<EmbeddingBackward>)
helpstensor([[-0.9593,  0.7832, -0.7097, -0.6007, -0.7307, -0.3972,  1.6951, -0.3382,
          0.4821,  1.4201]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"intensor([[-1.7425, -1.4250, -2.1230, -0.7210, -0.0912,  0.0985,  1.1724, -0.1688,
          0.1890,  0.0331]], device='cuda:0', grad_fn=<EmbeddingBackward>)
qualifytensor([[-0.7591,  0.2066,  0.1131, -0.7356,  1.1557, -0.5922, -0.2759, -0.0514,
          0.8564, -1.5140]], device='cuda:0', grad_fn=<EmbeddingBackward>)
residentstensor([[-1.5648,  0.5187, -1.3777, -1.0171,  0.7535, -0.3714, -1.5789, -0.1949,
          0.1937,  1.2147]], device='cuda:0', grad_fn=<EmbeddingBackward>)
885.tensor([[ 0.5226, -0.3817,  0.6033,  0.8610,  0.7244, -0.9901, -1.3689,  0.6097,
          0.7913,  1.3382]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Surnametensor([[-0.0682,  0.8452,  0.1055, -0.5017, -0.1131, -0.9323,  0.1085, -0.2414,
          2.0012,  0.8127]], device='cuda:0', grad_fn=<EmbeddingBackward>)
tempstensor([[-1.5135, -0.8711, -0.4067,  1.3068,  0.1578,  0.7436,  1.0633, -2.1033,
          0.3127,  1.1360]], device='cuda:0', grad_fn=<EmbeddingBackward>)
certifiedtensor([[-0.7875,  0.3384,  0.2947, -0.2124, -1.5578,  0.2710, -0.1941,  0.4060,
         -0.9195,  0.1956]], device='cuda:0', grad_fn=<EmbeddingBackward>)
performance.tensor([[ 0.1670, -1.5621,  1.9740,  0.5003, -0.6447, -0.0623, -0.0945, -0.3739,
         -0.4247,  3.1539]], device='cuda:0', grad_fn=<EmbeddingBackward>)
168.803tensor([[ 0.0105, -0.3319, -0.4590, -0.5023,  0.7940,  1.6554,  0.2815,  0.3147,
         -0.6440,  1.3166]], device='cuda:0', grad_fn=<EmbeddingBackward>)
periods,"tensor([[-0.6511, -0.7391,  0.2278, -0.7495,  1.6469,  0.9451,  1.6089,  1.0812,
          0.8174,  0.0699]], device='cuda:0', grad_fn=<EmbeddingBackward>)
preschools.tensor([[ 0.1024,  0.7010,  1.1963,  0.0844, -0.2491,  1.2923, -1.1440,  0.2672,
         -0.5197, -0.4972]], device='cuda:0', grad_fn=<EmbeddingBackward>)
totensor([[-0.0624,  2.4742, -1.1947,  1.6021,  1.0942,  1.8830,  1.5670,  0.7717,
          2.1229,  0.7779]], device='cuda:0', grad_fn=<EmbeddingBackward>)
level.tensor([[ 0.7020,  1.2233,  0.9913, -0.7129, -0.0771, -0.3181,  1.1466, -0.6380,
          0.0190,  0.5177]], device='cuda:0', grad_fn=<EmbeddingBackward>)
24tensor([[-0.6761,  0.8688, -0.7675,  0.4879,  1.9560,  0.3883, -1.3027,  1.2346,
         -0.8942,  1.3820]], device='cuda:0', grad_fn=<EmbeddingBackward>)
footballtensor([[ 1.0454, -1.0824, -0.2181,  0.1362, -1.5357, -0.1487,  0.0173, -1.7083,
         -1.4552,  0.5775]], device='cuda:0', grad_fn=<EmbeddingBackward>)
communitytensor([[ 0.4413, -0.0414,  0.2563,  1.2039,  1.8685, -1.3861, -0.5427, -0.4503,
         -0.0383,  0.2755]], device='cuda:0', grad_fn=<EmbeddingBackward>)
stipulatedtensor([[-0.0067, -2.1060, -0.2515,  1.0444, -0.0797, -0.5948, -0.5735, -0.2319,
         -0.3958, -1.7345]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Edgarstensor([[ 0.9882, -1.3490,  0.1153,  0.5894,  0.2136, -2.0622, -1.1429,  0.9596,
         -1.1131, -1.3453]], device='cuda:0', grad_fn=<EmbeddingBackward>)
upcomingtensor([[-0.3076, -1.3636,  0.8257, -1.4550, -0.3110, -0.0931, -0.7619, -0.0887,
          1.6935,  0.5132]], device='cuda:0', grad_fn=<EmbeddingBackward>)
communicationstensor([[-0.2444,  1.2823, -0.4902, -0.2828,  0.1579, -0.3350,  1.0633, -0.5045,
         -0.3487, -1.3179]], device='cuda:0', grad_fn=<EmbeddingBackward>)
drivetensor([[-1.4885, -0.2847, -1.1215,  1.9595, -0.3621,  0.9281,  1.6958,  0.2768,
         -0.2855,  0.3431]], device='cuda:0', grad_fn=<EmbeddingBackward>)
organizedtensor([[ 2.6675, -0.4712, -0.8972,  1.0089, -0.7647,  0.3121, -1.3130, -1.0939,
         -0.8674, -0.4702]], device='cuda:0', grad_fn=<EmbeddingBackward>)
0.03tensor([[ 1.2965,  0.3509, -0.9242, -1.7397, -0.5710, -0.2749, -0.7046, -0.4978,
         -1.3149,  0.7713]], device='cuda:0', grad_fn=<EmbeddingBackward>)
givetensor([[ 1.1629, -2.6208,  0.1305,  1.4006, -0.2659, -1.9979,  1.3830, -0.5509,
          0.4777,  0.1189]], device='cuda:0', grad_fn=<EmbeddingBackward>)
illegallytensor([[ 1.2928,  0.2143, -0.2654,  0.2627,  0.1080,  2.3603, -0.1430, -0.1462,
         -0.4682, -0.8248]], device='cuda:0', grad_fn=<EmbeddingBackward>)
drafttensor([[ 0.5263,  0.6947,  0.6129, -1.9583, -1.4020,  0.2898,  0.3363, -0.8158,
          1.6241, -1.1496]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ilzetensor([[ 1.0448,  0.1216,  1.0601, -0.0348,  0.2333, -0.7600, -1.5093, -1.7731,
         -0.5904,  0.4089]], device='cuda:0', grad_fn=<EmbeddingBackward>)
attensor([[-9.0879e-01, -1.5706e-03,  1.5713e+00,  3.7911e-01, -4.3612e-01,
         -4.9985e-01, -3.3735e+00, -6.5826e-01, -3.4080e-01, -1.3234e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
successtensor([[-0.8916,  0.4121, -0.1841,  0.5619, -1.0142, -1.1745, -1.0173, -1.7141,
          0.1750,  0.5551]], device='cuda:0', grad_fn=<EmbeddingBackward>)
10,979tensor([[ 0.6472,  0.6538, -0.0797,  1.5802,  0.2936,  1.2645, -0.5481, -1.5595,
         -0.0191,  0.3816]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Janistensor([[ 1.0152,  0.3865,  1.0556, -1.8245, -0.9045,  0.8364,  0.9067,  0.6270,
          0.8043,  1.1484]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Samoilovstensor([[-0.1160,  1.7544,  1.5823,  0.5964,  0.1385, -2.3914, -0.3111, -0.0138,
         -0.3369,  0.5725]], device='cuda:0', grad_fn=<EmbeddingBackward>)
militarytensor([[-0.5439,  0.4398, -0.4631,  1.6680, -0.3238, -0.6045, -0.1312, -0.2629,
          1.3266, -0.4278]], device='cuda:0', grad_fn=<EmbeddingBackward>)
authorities,tensor([[ 0.3674, -1.4518, -0.1917,  1.4792, -0.5079, -1.5223, -1.2479,  1.7364,
         -0.5066, -0.9789]], device='cuda:0', grad_fn=<EmbeddingBackward>)
pricetensor([[-0.8256,  2.5925, -2.0080, -2.1453, -0.5525,  0.4432,  0.1899, -0.3647,
         -1.1497,  2.1312]], device='cuda:0', grad_fn=<EmbeddingBackward>)
1,tensor([[-0.2693, -0.4861, -1.1111, -0.3430,  1.2721, -0.1106,  0.9629, -0.3207,
          0.0837,  0.2079]], device='cuda:0', grad_fn=<EmbeddingBackward>)
businesstensor([[-1.1674, -0.4381, -1.0241, -0.6560,  0.2411, -0.9461,  0.5767,  1.2317,
         -1.6661, -0.1687]], device='cuda:0', grad_fn=<EmbeddingBackward>)
activetensor([[ 0.4144, -1.8592,  0.4620,  0.5626,  2.0643, -1.0380,  0.4001, -0.9252,
          0.7978, -1.2526]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Finlandtensor([[ 0.3602, -0.4522, -1.0930,  0.6393,  0.4776, -1.1136,  0.0766, -0.7138,
         -0.5202, -0.1817]], device='cuda:0', grad_fn=<EmbeddingBackward>)
decisionstensor([[ 0.2346,  0.1493, -2.4864,  0.3046, -1.4099,  1.0030,  0.8351, -2.4602,
          0.7188, -0.5271]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Andristensor([[ 0.0567,  0.3722, -0.3862,  1.0739,  0.3836,  0.1432,  0.8262,  0.7634,
          2.2745,  0.9156]], device='cuda:0', grad_fn=<EmbeddingBackward>)
communiquetensor([[ 1.8158,  0.1684, -1.3835,  0.5049, -0.5309,  0.7839,  0.0563,  0.1303,
          0.2338, -0.2805]], device='cuda:0', grad_fn=<EmbeddingBackward>)
rivals.tensor([[ 0.1785, -0.3949, -0.2016, -0.5517,  0.0470, -0.7374, -1.0036,  0.7232,
         -0.3447,  1.6854]], device='cuda:0', grad_fn=<EmbeddingBackward>)
wenttensor([[ 0.2570, -0.7045,  0.9420,  1.3184,  1.0999,  1.7547,  0.3761, -0.6720,
         -1.1775,  0.2483]], device='cuda:0', grad_fn=<EmbeddingBackward>)
turningtensor([[ 0.1204, -0.7712, -1.3098, -0.8625,  0.2299,  1.5089,  0.6258, -0.7453,
          0.1399,  1.3213]], device='cuda:0', grad_fn=<EmbeddingBackward>)
appointment.tensor([[-0.5937, -0.6891,  0.1661,  0.9262,  0.0393,  0.2822, -0.2156,  0.1640,
          0.6664, -1.4388]], device='cuda:0', grad_fn=<EmbeddingBackward>)
amountedtensor([[ 0.5057, -0.3677,  0.0946, -1.2094, -0.6678, -0.3099, -1.4027,  0.2664,
         -1.5118,  0.0852]], device='cuda:0', grad_fn=<EmbeddingBackward>)
overtensor([[ 0.0271,  0.5847, -0.2053, -1.6431,  0.8906, -1.0748, -1.1163,  1.4121,
          1.7225,  0.5575]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Antetokounmpo,tensor([[ 0.3902, -0.4280, -0.0454,  0.9769,  0.4161,  0.7377,  0.0189, -0.4546,
          0.6634, -0.3527]], device='cuda:0', grad_fn=<EmbeddingBackward>)
industrialtensor([[-0.1811, -0.1608,  0.4404,  0.2425,  1.7156,  0.5988, -0.0743, -1.4764,
          0.8332,  1.1039]], device='cuda:0', grad_fn=<EmbeddingBackward>)
world,tensor([[-0.6148,  1.3078,  0.7771,  0.2995, -0.2748, -1.7592,  0.3560, -0.3510,
         -1.1404,  0.0774]], device='cuda:0', grad_fn=<EmbeddingBackward>)
sustainabletensor([[-0.4795,  1.5085, -0.1294, -1.1270,  0.4881,  2.6098,  0.5718, -0.6182,
          1.0125,  0.6802]], device='cuda:0', grad_fn=<EmbeddingBackward>)
year-roundtensor([[-0.4372, -2.6445, -0.6312, -2.5056, -0.0237, -0.8430,  1.0122,  0.3201,
          2.3023, -1.1150]], device='cuda:0', grad_fn=<EmbeddingBackward>)
shortages:tensor([[ 0.3367, -0.8156, -0.1857,  0.3604, -1.2899, -0.6808,  1.1452,  0.4427,
         -1.4176,  0.3153]], device='cuda:0', grad_fn=<EmbeddingBackward>)
probetensor([[ 0.3648, -0.4189,  0.4525,  0.0734,  0.3063,  1.6304, -0.1101, -0.2877,
         -0.9918, -1.0364]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ATHENS,tensor([[-0.7742, -0.1884,  0.6421,  0.2846, -0.3090, -1.7834, -1.1901,  0.0712,
         -0.2684, -0.1601]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Grouptensor([[ 0.1408, -2.6721, -0.3510,  0.5454, -0.1263,  0.4931, -0.2365,  0.8705,
          0.5600,  0.1076]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Hague,tensor([[ 1.3055,  0.4997,  1.9039,  0.7476,  0.6441, -1.0565,  0.2543, -1.6111,
         -0.2410,  0.6404]], device='cuda:0', grad_fn=<EmbeddingBackward>)
planningtensor([[-0.6200, -1.0509,  1.3911, -1.4083,  1.7162, -0.1265,  1.0149, -0.2352,
         -0.7188, -0.4661]], device='cuda:0', grad_fn=<EmbeddingBackward>)
U.S.tensor([[ 0.8199, -1.1456,  1.5804,  0.3667, -0.0191, -0.0894,  0.0363,  0.5904,
          1.6909,  1.4151]], device='cuda:0', grad_fn=<EmbeddingBackward>)
talkstensor([[ 6.7444e-02,  1.5439e+00,  1.5977e-01,  4.8651e-01,  2.1810e+00,
          1.5084e-03, -8.5728e-01, -1.1700e+00, -4.2445e-01,  1.7504e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
1.2tensor([[ 0.1917, -0.7889,  0.5680,  1.0772,  0.7198,  1.2597,  1.2357, -0.5981,
         -0.0535,  1.1282]], device='cuda:0', grad_fn=<EmbeddingBackward>)
prospectivetensor([[ 0.9227,  1.1252, -1.7207,  0.5920, -0.7505,  1.7613, -0.6901,  0.2892,
          1.7648, -0.4386]], device='cuda:0', grad_fn=<EmbeddingBackward>)
cleantensor([[ 0.3433,  1.2532, -0.7005,  0.3535,  0.7286, -1.1420, -0.7314,  0.0182,
          1.6395, -0.7061]], device='cuda:0', grad_fn=<EmbeddingBackward>)
2-1tensor([[-1.7228, -0.4652,  0.4525,  0.1483,  0.3616, -0.7304,  1.0657,  1.2873,
          0.5831,  0.0442]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ready,tensor([[-0.9534,  1.3856, -2.9304, -0.5794,  0.5496,  1.5480,  1.0049, -1.8724,
          3.4935, -0.3380]], device='cuda:0', grad_fn=<EmbeddingBackward>)
domestictensor([[ 0.2250,  1.9702, -1.1040,  0.5672,  0.2351, -1.1683, -0.1273,  0.5098,
         -0.5122, -0.0329]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Associationtensor([[ 0.2336, -0.4523,  1.4698,  0.2928, -0.0459,  0.7569, -0.8730,  1.6575,
         -1.1453, -0.1178]], device='cuda:0', grad_fn=<EmbeddingBackward>)
August,tensor([[ 1.7161,  0.1040, -1.3272,  0.6167,  1.3149, -2.2005, -1.7328, -0.1196,
         -2.0600, -1.7207]], device='cuda:0', grad_fn=<EmbeddingBackward>)
solutiontensor([[ 0.7888,  0.2345, -1.0694,  0.5698, -0.1901,  1.3805,  0.3670,  0.5050,
          1.3737,  0.6653]], device='cuda:0', grad_fn=<EmbeddingBackward>)
materialtensor([[-1.3766, -0.4165, -2.6165, -0.1451, -0.1674, -0.1699,  0.6325,  0.8903,
          0.9078, -0.8583]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Rivertensor([[ 1.3446, -0.8897,  1.3323, -1.9757,  0.5330,  0.5711,  2.9745,  0.4698,
          0.6138,  0.1497]], device='cuda:0', grad_fn=<EmbeddingBackward>)
proportional,tensor([[-1.5320,  0.2288,  0.2651, -0.8569, -0.2217,  0.4661, -0.5371, -1.4640,
         -0.4506,  0.1059]], device='cuda:0', grad_fn=<EmbeddingBackward>)
2012,tensor([[ 0.6729, -0.1080, -0.4630,  0.5665, -0.6246, -0.4598, -0.9680,  1.4299,
         -0.8171,  0.2798]], device='cuda:0', grad_fn=<EmbeddingBackward>)
statestensor([[ 1.2807,  0.8664,  0.8832, -2.1159,  0.0119, -1.2315, -0.1495, -0.7009,
          0.3398, -0.9693]], device='cuda:0', grad_fn=<EmbeddingBackward>)
0.4tensor([[ 1.0978,  0.6529,  0.5328,  0.8727,  0.6504, -0.6111,  0.5773,  0.7239,
         -0.1932, -0.5601]], device='cuda:0', grad_fn=<EmbeddingBackward>)
developmenttensor([[ 1.2331, -0.1768,  0.9578, -1.0036, -2.0660,  0.8263, -0.1025, -0.2208,
          0.3638, -0.1492]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Eurostat'stensor([[ 1.4790,  0.5595, -1.2523,  0.6569, -2.2675, -1.6920,  1.2986,  1.2110,
          0.7837,  0.5778]], device='cuda:0', grad_fn=<EmbeddingBackward>)
approach,tensor([[ 0.1251,  1.6226, -1.4742, -1.2873, -0.1349,  0.7364, -0.9398, -0.6586,
          1.0883, -0.3170]], device='cuda:0', grad_fn=<EmbeddingBackward>)
$700tensor([[-0.2584, -0.3573,  0.7469, -2.8395,  1.7039,  0.6053,  1.0484, -0.3693,
         -0.4268, -0.4079]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Securitytensor([[-1.9758,  0.0887, -0.1206,  0.5438,  0.2140, -0.4610,  0.0930, -0.2429,
          0.2241, -0.1062]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Driksna,tensor([[ 0.0646,  0.7863,  0.9072, -1.0996, -0.0723,  1.9978,  0.2462, -1.2383,
          0.6967,  0.5853]], device='cuda:0', grad_fn=<EmbeddingBackward>)
carriedtensor([[ 1.2958,  1.4885, -0.3162,  0.2087, -0.8033, -0.0470,  0.2868, -0.8196,
          0.0171,  0.2515]], device='cuda:0', grad_fn=<EmbeddingBackward>)
completetensor([[ 0.6254, -0.9697,  0.2287,  1.2702, -0.7751,  1.1057, -1.6066,  0.3131,
          1.2288,  1.8528]], device='cuda:0', grad_fn=<EmbeddingBackward>)
beginningtensor([[-5.1541e-01, -1.3039e+00, -1.3837e-03,  1.0789e+00, -5.3481e-01,
         -3.1803e-01, -1.1398e+00,  1.1451e+00,  1.8841e-01, -1.6219e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
Revenuetensor([[-1.1530, -0.1630,  0.7183, -1.4448,  1.3106,  1.1284, -1.6793, -1.7917,
         -1.0042, -1.2532]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Iraqitensor([[ 0.4266,  1.4767,  0.1640,  0.6703,  1.5222, -1.0557, -0.3522,  0.1966,
          0.9892, -0.2673]], device='cuda:0', grad_fn=<EmbeddingBackward>)
foodtensor([[ 0.3780, -0.7522,  2.0829, -0.1961, -0.6985, -1.4314, -0.9489, -0.0238,
         -0.7073,  0.0060]], device='cuda:0', grad_fn=<EmbeddingBackward>)
openingtensor([[-0.5731,  0.3462,  1.5307, -0.4365, -0.3355, -0.5912,  0.5380,  0.3406,
          0.1398,  1.6892]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Lewis,tensor([[ 1.6816,  2.0700,  1.1012,  1.5322, -0.0738,  0.2821,  1.6757,  0.5244,
          0.9275,  1.0187]], device='cuda:0', grad_fn=<EmbeddingBackward>)
universitytensor([[ 0.1479, -0.7219,  0.0373, -2.0582, -1.2543, -0.8445,  1.9970, -1.0292,
          0.7707,  0.9056]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Clevelandtensor([[-0.6371,  1.3282, -1.2783, -0.1222,  0.2967,  1.1047, -1.1869, -1.2888,
          1.5848, -1.2726]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Rosbergtensor([[ 1.3209, -0.8690,  1.5123, -0.2062, -0.2139, -1.3945, -0.1026, -1.4658,
          1.3625,  0.8317]], device='cuda:0', grad_fn=<EmbeddingBackward>)
economytensor([[ 0.4777,  0.9959,  1.6165, -0.2293,  0.3596, -0.7843, -0.5511, -0.3178,
          1.2661,  1.0652]], device='cuda:0', grad_fn=<EmbeddingBackward>)
voluntarytensor([[-0.0074, -0.5322,  0.8295,  1.2559, -1.2364, -0.8755, -0.9088, -0.4370,
         -0.8595, -0.8167]], device='cuda:0', grad_fn=<EmbeddingBackward>)
wishedtensor([[-0.3128, -0.6902,  0.1008, -0.5161, -0.5709, -0.0046,  2.6179, -0.3346,
          0.1628,  0.1298]], device='cuda:0', grad_fn=<EmbeddingBackward>)
adding:tensor([[-0.9632,  0.2483,  1.1438, -1.6418, -0.1254, -1.1125, -0.0754,  0.0810,
         -1.7657,  0.7679]], device='cuda:0', grad_fn=<EmbeddingBackward>)
0.3tensor([[ 1.1903, -0.4218, -1.3269,  1.1906,  0.6809, -0.0209, -0.0318, -0.4226,
         -0.1177, -1.6031]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ilmarstensor([[ 0.8158, -1.0366,  0.9311,  1.5532,  0.9154, -0.2052,  0.2284,  0.0648,
         -0.7995, -0.0426]], device='cuda:0', grad_fn=<EmbeddingBackward>)
inflationtensor([[-0.8908, -0.7532, -0.8407,  0.8049, -0.3291,  1.5081,  0.2168, -1.4369,
         -0.3464, -0.2810]], device='cuda:0', grad_fn=<EmbeddingBackward>)
he'stensor([[-0.0514, -1.7070, -0.7514,  0.2303,  0.1381, -1.6314,  1.1056, -0.4157,
         -0.0873,  1.2701]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Netherlands'tensor([[ 1.6475, -0.7651,  0.6320,  0.0366,  1.1349,  0.2103,  1.0856, -0.4463,
          1.2446,  0.7853]], device='cuda:0', grad_fn=<EmbeddingBackward>)
needytensor([[-0.0100,  0.7272, -0.7375, -0.1326, -1.5036,  1.1657,  0.5371, -0.1360,
          0.0991, -0.1899]], device='cuda:0', grad_fn=<EmbeddingBackward>)
lacktensor([[-0.4250, -1.6309, -0.8097,  0.1289,  0.3663,  0.0026,  0.1665,  0.6665,
         -1.3897,  1.0312]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ambassadortensor([[-0.1790,  0.5077,  0.2447,  1.3216, -0.3233, -1.4079,  0.0307, -0.3613,
         -1.1880, -0.1172]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reviewedtensor([[ 1.0995,  1.0891,  0.6562, -1.2304,  1.5765,  0.2217,  1.3857,  1.5539,
         -0.3963,  1.3720]], device='cuda:0', grad_fn=<EmbeddingBackward>)
worthtensor([[-0.7699, -0.8835, -0.3742,  0.8003,  1.6630, -0.4806,  0.4057, -0.2438,
          0.5108,  0.3962]], device='cuda:0', grad_fn=<EmbeddingBackward>)
providestensor([[-0.9381, -0.1939, -0.3948,  1.4602,  0.3264, -0.3478,  1.9463,  1.6593,
         -1.8554, -1.2959]], device='cuda:0', grad_fn=<EmbeddingBackward>)
railtensor([[-0.1873, -0.1222,  0.3603, -0.2129, -0.3005,  1.4479, -0.1852, -0.8524,
          0.2593, -0.7837]], device='cuda:0', grad_fn=<EmbeddingBackward>)
neutraltensor([[-0.0492,  2.0164,  1.1372, -0.9603,  0.4257, -0.7874,  0.0668,  1.8589,
         -1.0099, -2.4062]], device='cuda:0', grad_fn=<EmbeddingBackward>)
wagestensor([[ 1.1232, -0.8108, -1.0127, -0.4918,  0.4423, -0.2450, -0.8168,  0.8846,
          0.5982, -1.3671]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Canadatensor([[-0.1659,  0.2429,  2.1049,  0.1122,  0.0349,  1.9775, -2.3360,  1.8827,
          1.6748,  0.0614]], device='cuda:0', grad_fn=<EmbeddingBackward>)
4,030,tensor([[-0.1327,  1.6554, -1.5653, -0.4226,  0.9453, -0.2801, -1.1272, -0.2882,
          0.6365, -0.8955]], device='cuda:0', grad_fn=<EmbeddingBackward>)
dependedtensor([[ 0.2918, -0.0649,  1.6650,  1.1121, -0.7806, -0.5410,  0.8089,  0.2653,
         -0.6776, -0.5873]], device='cuda:0', grad_fn=<EmbeddingBackward>)
today.tensor([[-0.4630, -0.9668,  0.2644, -1.1310,  0.9364,  0.6688, -0.9517,  0.1309,
         -0.6269,  0.0370]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reviewtensor([[-0.7838, -1.8215,  0.1641, -0.8486,  0.4647,  0.3359,  0.6137, -0.2908,
         -1.6949, -1.7604]], device='cuda:0', grad_fn=<EmbeddingBackward>)
fighttensor([[ 0.1943, -0.3448,  1.0091, -0.1433, -0.0914, -1.1792, -1.8315, -0.2868,
          0.7411, -0.6688]], device='cuda:0', grad_fn=<EmbeddingBackward>)
13tensor([[ 0.4381,  1.5180,  0.5053,  0.0400, -0.8363, -1.0491, -0.4587, -1.5543,
          0.4112, -0.3465]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Bothtensor([[ 1.9894, -1.0773, -1.2867, -0.6683,  0.1118,  0.1083,  0.4267, -0.0883,
          0.1661, -0.7367]], device='cuda:0', grad_fn=<EmbeddingBackward>)
0:2,tensor([[ 1.8650,  0.2850, -0.6354, -1.1200, -0.6042,  1.2640,  2.1238,  1.5162,
          0.9513,  0.0449]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Accordingtensor([[ 3.1342e-01,  5.3365e-01, -4.6206e-02, -9.2058e-01,  2.0128e+00,
          3.6391e-03, -2.2078e+00, -2.1647e+00,  1.6017e+00,  8.5436e-04]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
individualtensor([[ 0.2105,  1.0421,  0.0831,  1.0713, -0.1633, -0.1451,  0.5966, -0.7335,
         -0.1100, -0.6115]], device='cuda:0', grad_fn=<EmbeddingBackward>)
congratulatedtensor([[ 0.3218,  0.6268,  0.4877, -0.6497,  0.8358,  1.9389,  0.6275,  0.3172,
          1.4141, -0.5036]], device='cuda:0', grad_fn=<EmbeddingBackward>)
opportunitiestensor([[ 1.9320e-01, -1.3893e-01, -5.2450e-01, -7.9546e-01,  3.0430e-01,
         -1.4285e+00, -9.9065e-01,  8.1816e-01,  7.3302e-04,  3.9711e-01]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
rights.tensor([[ 1.0336, -0.7931, -1.0935, -0.1233,  0.3496,  0.1091, -0.4734,  0.6072,
          0.5066, -0.2013]], device='cuda:0', grad_fn=<EmbeddingBackward>)
morning.tensor([[-1.1331, -0.3019,  2.0740,  0.3778,  0.5336, -1.6337, -0.1902,  2.2102,
          0.5425,  0.4417]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Worldtensor([[-0.0705,  1.7292,  1.2655,  0.6786,  1.4740,  0.3159, -0.4591,  0.7913,
          1.4406,  0.2575]], device='cuda:0', grad_fn=<EmbeddingBackward>)
furthertensor([[-0.2836, -0.4398, -0.0567, -1.7603,  0.4115,  0.6091,  0.6990,  0.4614,
          0.3675,  0.2704]], device='cuda:0', grad_fn=<EmbeddingBackward>)
tacklingtensor([[ 0.0305,  2.0970, -0.1374,  0.8332, -0.1141,  1.2687, -0.9788,  1.7361,
          2.5698, -0.6818]], device='cuda:0', grad_fn=<EmbeddingBackward>)
consumerstensor([[-1.3936,  0.6352,  0.2282,  1.0025,  1.7543,  0.5348,  1.6241, -0.5343,
         -0.6091,  0.5577]], device='cuda:0', grad_fn=<EmbeddingBackward>)
21,tensor([[ 1.2979,  1.1436, -0.7454, -0.5615,  1.0824, -0.0740, -2.2250, -0.8525,
         -0.7969,  0.6841]], device='cuda:0', grad_fn=<EmbeddingBackward>)
processtensor([[-0.4316, -1.1741, -0.2088, -0.9304,  0.0540, -0.4806, -1.2548,  2.1580,
          0.3891, -0.0162]], device='cuda:0', grad_fn=<EmbeddingBackward>)
nationaltensor([[ 0.0089,  0.1800,  1.1581, -0.9299, -1.2172, -0.1289, -1.7683,  1.8994,
         -0.3359,  2.4285]], device='cuda:0', grad_fn=<EmbeddingBackward>)
countries'tensor([[-0.0458,  1.8144, -0.8814, -0.1480, -0.3226,  1.1797,  1.0999,  0.0487,
         -1.0324, -0.9978]], device='cuda:0', grad_fn=<EmbeddingBackward>)
someonetensor([[ 0.1596, -0.3627, -0.8762,  1.6269,  1.6923,  0.3074, -0.8362,  1.5737,
          0.5707, -0.8944]], device='cuda:0', grad_fn=<EmbeddingBackward>)
UEFAtensor([[ 1.6916,  0.0174,  1.5453,  0.8662,  1.8948, -0.1430, -0.9543, -0.1811,
         -0.3248, -1.2614]], device='cuda:0', grad_fn=<EmbeddingBackward>)
closertensor([[ 1.5742,  3.2283, -1.2241, -0.9706, -0.1719, -0.0499,  0.6776, -0.7827,
          0.0477, -1.4667]], device='cuda:0', grad_fn=<EmbeddingBackward>)
1.tensor([[ 1.0916, -0.0412,  1.7731,  0.2953,  0.6821,  0.0153,  1.0460, -0.5019,
         -0.0944,  2.0885]], device='cuda:0', grad_fn=<EmbeddingBackward>)
increasingtensor([[ 0.4217, -1.2141, -0.3157, -0.1843, -1.7599,  0.3288, -1.3933,  0.5693,
          1.5117,  1.2698]], device='cuda:0', grad_fn=<EmbeddingBackward>)
governmentstensor([[ 1.0795,  0.6513, -0.0280, -1.7256, -1.1145, -0.8913, -1.5651,  0.0705,
          0.2776,  0.4142]], device='cuda:0', grad_fn=<EmbeddingBackward>)
15tensor([[-0.8045, -0.0556,  0.9863, -1.8992, -0.2798,  0.4500, -1.2093,  0.1366,
         -0.3410, -1.4649]], device='cuda:0', grad_fn=<EmbeddingBackward>)
transporttensor([[-1.1013, -1.2657,  0.2991, -0.1248, -1.4305, -1.5008,  1.9278,  0.1286,
          0.7311, -0.3849]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Latvia'stensor([[ 0.6188,  0.4332,  2.1483,  1.1783,  0.4886,  1.9225, -1.1522, -1.5156,
          0.2311, -1.7485]], device='cuda:0', grad_fn=<EmbeddingBackward>)
regardtensor([[-0.2445, -1.0371,  0.2121, -1.5259,  0.7104,  0.7542,  0.4684,  0.7440,
          0.1623, -0.1658]], device='cuda:0', grad_fn=<EmbeddingBackward>)
histensor([[-0.6005, -0.6558, -1.2085,  0.2185, -2.1118, -0.4126, -1.2406,  1.9034,
          2.0272, -0.2817]], device='cuda:0', grad_fn=<EmbeddingBackward>)
deflation,tensor([[-1.2351,  0.0789, -1.1301,  0.4047, -0.6985,  1.4089,  1.6244, -0.7702,
          1.7195,  0.1043]], device='cuda:0', grad_fn=<EmbeddingBackward>)
retailerstensor([[-0.2491, -1.0801, -1.9059, -0.1622,  0.4340, -0.2380,  0.4795,  0.6909,
         -1.2011, -0.8599]], device='cuda:0', grad_fn=<EmbeddingBackward>)
occupiedtensor([[-1.2064,  0.6179, -0.1504,  0.0459, -0.9174, -0.5264,  0.8280, -1.1071,
         -1.2487, -0.5295]], device='cuda:0', grad_fn=<EmbeddingBackward>)
supervisiontensor([[ 2.2465, -0.3572, -0.5660,  0.9764, -1.7813,  0.5527, -1.7716,  0.1228,
         -0.2915, -0.7568]], device='cuda:0', grad_fn=<EmbeddingBackward>)
schoolstensor([[-0.3369,  0.1456,  2.2956,  3.4372,  0.5180,  1.8201,  0.2468, -1.2993,
          1.9962, -0.6333]], device='cuda:0', grad_fn=<EmbeddingBackward>)
foreigners.tensor([[ 0.1804, -1.0749, -3.5471,  0.3152,  0.3140,  0.2680,  0.2865, -0.1892,
          1.4548,  1.1015]], device='cuda:0', grad_fn=<EmbeddingBackward>)
bordertensor([[-0.2156, -0.1839,  0.4110,  0.8236, -1.2470, -0.2935, -0.2920,  0.0656,
          1.0991,  0.4214]], device='cuda:0', grad_fn=<EmbeddingBackward>)
embarktensor([[-0.9153, -1.9676, -0.8064, -1.1700, -0.2119, -0.0043,  0.9061,  0.2506,
         -0.0178,  0.1092]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Spain,tensor([[ 1.0271, -0.1468,  1.7695, -1.4186,  0.2687,  0.8359,  0.8937,  0.8048,
          0.8486, -0.7507]], device='cuda:0', grad_fn=<EmbeddingBackward>)
canneries.tensor([[-0.6480,  1.1259,  0.0700,  0.6696,  0.1213, -0.6281, -1.2534,  0.9821,
         -1.0925, -0.7646]], device='cuda:0', grad_fn=<EmbeddingBackward>)
moderntensor([[ 0.4995,  1.5594,  0.0430, -0.4680, -0.5136, -0.4048, -0.8400, -0.4015,
         -1.8303,  2.3470]], device='cuda:0', grad_fn=<EmbeddingBackward>)
short-termtensor([[ 3.0870, -1.4258,  0.0748,  1.3937,  0.2608, -0.4606,  1.5967,  0.7975,
         -0.8357,  1.2164]], device='cuda:0', grad_fn=<EmbeddingBackward>)
issuestensor([[ 0.7277,  1.4846,  0.3512, -0.4677, -0.4402,  1.3629,  0.6479, -1.3333,
         -0.7155,  0.2309]], device='cuda:0', grad_fn=<EmbeddingBackward>)
carryingtensor([[ 1.7090, -0.3318,  1.2705, -0.7186,  0.0254,  0.2169, -0.6751,  0.0976,
          0.4425, -1.0461]], device='cuda:0', grad_fn=<EmbeddingBackward>)
justice,"tensor([[-1.0936,  1.6728, -0.9975, -0.6850, -0.3923,  0.9097,  2.0926, -0.4864,
          0.7275,  0.4095]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reading,tensor([[-1.3995,  0.3823, -0.9594, -1.2855, -0.3514, -1.5889,  0.8114, -0.5839,
          0.5993,  1.2268]], device='cuda:0', grad_fn=<EmbeddingBackward>)
follytensor([[ 0.4085, -1.1418,  0.8324, -0.2889,  0.7855,  0.7654, -0.0229,  0.0518,
         -0.3168, -0.5927]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"Ittensor([[-0.5029,  0.4136, -0.3118,  0.0234, -1.2148, -1.1940,  1.0750, -0.1823,
          1.8986, -0.2975]], device='cuda:0', grad_fn=<EmbeddingBackward>)
kilogram.tensor([[ 2.9881, -0.3570,  0.1600,  1.6586, -0.0619,  0.0093,  1.1505,  0.4227,
         -0.9690, -0.9143]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Finland'stensor([[-2.5671,  1.4578, -0.6909,  1.6983,  0.8904,  0.6247, -0.8698, -0.0967,
          0.3278, -0.2982]], device='cuda:0', grad_fn=<EmbeddingBackward>)
grouptensor([[ 0.5473, -1.2572,  0.4712,  1.5559, -0.2425,  0.7072, -2.3757, -1.1879,
         -0.2476,  1.3317]], device='cuda:0', grad_fn=<EmbeddingBackward>)
meteorologiststensor([[-1.3311,  0.7348,  0.5266, -0.7957, -0.6617,  0.5495, -0.6169,  1.5063,
          0.3669,  0.1898]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Defensetensor([[ 0.0597, -0.0828,  0.8929,  1.3852, -1.1854,  0.9580,  1.7459,  1.2167,
         -0.0740,  0.4737]], device='cuda:0', grad_fn=<EmbeddingBackward>)
results.tensor([[-2.5690,  0.5552,  0.1461, -0.2496, -0.2492, -1.0792,  0.6687,  1.3370,
          0.9861,  0.4615]], device='cuda:0', grad_fn=<EmbeddingBackward>)
sewagetensor([[-0.0351,  1.4754, -1.1024,  0.1692,  0.9536,  0.0681, -1.0417,  0.1170,
         -0.1702,  0.1692]], device='cuda:0', grad_fn=<EmbeddingBackward>)
flexiblytensor([[-0.4992,  0.5828,  1.0400, -0.3763,  0.8029, -1.3429, -0.1934,  1.6579,
         -0.1106, -0.4753]], device='cuda:0', grad_fn=<EmbeddingBackward>)
emphasized.tensor([[-0.0240, -0.5808, -0.3568, -1.3673, -0.1965,  0.6484, -0.0951, -1.1273,
         -1.1493, -0.1077]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Btensor([[ 0.2130,  0.5090,  0.9355, -0.3711, -1.3431, -0.3535, -0.6252,  0.4805,
         -0.0382,  1.2307]], device='cuda:0', grad_fn=<EmbeddingBackward>)
suspicioustensor([[ 0.3076,  1.3648, -0.6099, -0.6750, -0.2206, -0.8376, -1.6598,  1.0984,
          0.1885,  1.2172]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Langnautensor([[ 0.7791, -0.0174,  0.0308,  1.0043,  0.0538, -0.3277,  0.4096, -1.6892,
         -0.1756,  0.5412]], device='cuda:0', grad_fn=<EmbeddingBackward>)
dramaticallytensor([[-1.2352, -1.4093, -0.6479, -0.4881,  0.9144, -0.6349,  0.3602,  0.2192,
          1.5627, -0.5462]], device='cuda:0', grad_fn=<EmbeddingBackward>)
product,tensor([[-0.5744, -1.1561,  0.1688,  1.1162, -0.6608, -0.4923,  0.8433, -1.3083,
         -0.6824,  0.3148]], device='cuda:0', grad_fn=<EmbeddingBackward>)
million,tensor([[-0.1063,  0.0847, -1.3268,  0.1327, -0.0999, -0.4977,  0.5103, -0.9343,
         -0.0685, -0.5970]], device='cuda:0', grad_fn=<EmbeddingBackward>)
endtensor([[-1.2988,  0.9662,  0.7658, -1.0608,  0.5629, -1.8119,  0.1070, -0.1989,
          3.1110, -0.8230]], device='cuda:0', grad_fn=<EmbeddingBackward>)
analysistensor([[-0.6782, -0.1003,  1.7752, -0.3368,  1.4512,  2.7838,  0.0583,  1.3699,
          1.1699,  0.7290]], device='cuda:0', grad_fn=<EmbeddingBackward>)
programmes,tensor([[ 0.1467,  1.1202,  0.4514, -0.9504, -0.5708, -0.8979, -0.2690, -1.1059,
          0.3065,  0.4532]], device='cuda:0', grad_fn=<EmbeddingBackward>)
investigationstensor([[-0.7450,  0.7101, -0.0730, -0.0121,  0.0275, -0.9228,  0.6126,  2.1747,
          0.4233, -0.2350]], device='cuda:0', grad_fn=<EmbeddingBackward>)
terms"tensor([[-0.5575,  0.0995, -1.6476,  0.2982, -0.2141, -0.6252,  0.3449,  1.1311,
          2.2893,  0.1765]], device='cuda:0', grad_fn=<EmbeddingBackward>)
links.tensor([[-2.1606,  0.1070,  0.5109,  0.7241, -1.6622, -0.7846,  0.1409,  1.2491,
         -0.5173,  0.7256]], device='cuda:0', grad_fn=<EmbeddingBackward>)
presentedtensor([[ 0.0030,  0.7649,  0.3260, -1.5755,  2.4070,  1.1119, -0.8196, -0.2629,
          0.4956, -1.1433]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Vejonistensor([[-0.5224,  2.3897,  0.1376, -0.6384,  0.0067,  0.2897, -0.5488,  0.4512,
          0.5381,  0.3413]], device='cuda:0', grad_fn=<EmbeddingBackward>)
fundstensor([[-0.6004,  0.5743, -0.4797,  0.4282,  0.3272, -0.1485, -0.4804, -0.5015,
          1.6152,  0.3564]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Inctensor([[ 1.1272,  1.3553, -0.3560,  1.3377,  1.0662,  0.0096,  0.9925,  0.5555,
          1.1392,  1.1755]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ongoing,tensor([[-0.1835,  0.5236, -0.7399,  1.7850,  0.5486,  0.2321, -0.8048,  0.5436,
          1.2535,  0.4727]], device='cuda:0', grad_fn=<EmbeddingBackward>)
presencetensor([[-0.5841,  0.0331, -0.7788,  0.0336, -2.0821,  1.2266, -2.8689,  0.1414,
          0.9685,  1.0559]], device='cuda:0', grad_fn=<EmbeddingBackward>)
sensitivetensor([[ 1.3760, -0.8177, -1.9043,  1.8524,  0.0702, -0.2697,  0.3579, -0.4933,
         -0.6258,  1.9471]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ascertainedtensor([[-0.2983, -0.9916,  1.5022, -0.6342, -0.5946, -1.3725,  0.5343,  1.1592,
          0.4470, -0.1160]], device='cuda:0', grad_fn=<EmbeddingBackward>)
centstensor([[ 0.2982,  1.0995,  0.5415,  0.4087, -0.0265, -0.6803,  0.7244, -0.0857,
         -1.2077,  0.2081]], device='cuda:0', grad_fn=<EmbeddingBackward>)
150tensor([[ 1.0181,  1.2770, -0.1772,  1.1332,  1.0272, -0.6553,  1.4306, -1.0904,
          0.7520,  0.5739]], device='cuda:0', grad_fn=<EmbeddingBackward>)
investtensor([[ 0.3125,  1.0819,  0.3486,  0.4554,  0.3497, -2.2697,  1.1336,  1.3654,
          0.7470,  0.1255]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Brouwertensor([[ 0.1450, -0.2181,  0.5892,  1.5007, -0.0796,  0.3435, -0.4003,  0.3307,
         -1.1832,  1.3463]], device='cuda:0', grad_fn=<EmbeddingBackward>)
hetensor([[ 1.9440,  0.4558, -1.1388,  0.3418, -0.0348,  1.8823,  0.0106, -2.9368,
         -0.3825, -1.1038]], device='cuda:0', grad_fn=<EmbeddingBackward>)
maytensor([[-1.2662,  0.7837, -0.2509,  0.2101,  0.0964, -0.2908,  0.6563, -0.6802,
          0.4640,  0.7763]], device='cuda:0', grad_fn=<EmbeddingBackward>)
saidtensor([[ 2.2847, -2.2074,  0.0581, -0.6203,  1.1653, -0.5273,  0.0845,  0.1943,
          0.8792, -1.1698]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Independenttensor([[ 0.2665,  0.0404, -0.2499, -1.5507, -0.2564,  1.2460,  0.1877, -0.7521,
          0.1082,  0.6384]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"catastrophic"tensor([[ 1.8257,  0.1777, -0.1128,  1.5990, -1.3964, -0.8371,  1.4276, -0.0590,
         -1.5566, -1.1714]], device='cuda:0', grad_fn=<EmbeddingBackward>)
27tensor([[-0.0756, -0.4883, -0.7278, -2.2452, -0.8505, -0.8407,  0.2696, -0.1117,
         -0.3131,  2.6052]], device='cuda:0', grad_fn=<EmbeddingBackward>)
moneytensor([[ 0.2015,  0.2161,  0.7248,  0.0535, -0.3002,  0.5854, -0.6527, -1.9835,
         -1.3106, -0.9018]], device='cuda:0', grad_fn=<EmbeddingBackward>)
production.tensor([[-1.1034, -0.5618,  1.2230, -1.3792,  0.8528, -0.5972, -0.5818, -1.2282,
         -1.4433, -0.7327]], device='cuda:0', grad_fn=<EmbeddingBackward>)
survivedtensor([[-0.4107,  0.7174, -0.4331, -0.2192, -0.3261, -1.2876,  0.3154, -0.3462,
          0.2326, -1.0769]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Rigatensor([[ 0.0942,  1.5263, -0.4094, -0.1036, -1.7560, -0.7640,  0.3215,  1.7245,
          0.2312,  0.4071]], device='cuda:0', grad_fn=<EmbeddingBackward>)
re-establishedtensor([[ 1.3037,  0.9895, -0.5254,  1.0577, -0.7411, -0.3456,  0.6842, -0.3752,
         -1.4721,  0.1854]], device='cuda:0', grad_fn=<EmbeddingBackward>)
relativelytensor([[ 0.4362,  1.0978, -0.6193, -0.4607, -2.2824, -0.1782,  1.0584, -0.9982,
         -1.1678,  0.0534]], device='cuda:0', grad_fn=<EmbeddingBackward>)
receivestensor([[-1.6936, -0.9358, -0.0188, -1.4765, -0.5620,  0.3051,  0.3512, -0.7695,
          1.2152, -0.8986]], device='cuda:0', grad_fn=<EmbeddingBackward>)
synchronizationtensor([[-1.0429,  0.4952,  0.2304,  0.1781,  2.3530, -0.3558, -0.0296,  2.2465,
         -0.6356, -0.6563]], device='cuda:0', grad_fn=<EmbeddingBackward>)
relationstensor([[ 0.1070, -0.1711,  2.5552,  0.8688, -0.3324,  1.1306, -0.5509,  2.6601,
         -0.5208, -0.4899]], device='cuda:0', grad_fn=<EmbeddingBackward>)
17tensor([[-0.3993, -2.0413, -1.2734, -2.0647,  1.9643,  0.6152,  1.2602,  1.6551,
         -0.6654, -0.2924]], device='cuda:0', grad_fn=<EmbeddingBackward>)
protecttensor([[-0.5173, -1.2570,  0.5565, -0.6232,  0.8335,  1.0712,  0.2160,  0.7951,
         -0.8471,  0.0642]], device='cuda:0', grad_fn=<EmbeddingBackward>)
steepertensor([[-0.5736, -0.1498,  1.7185,  1.3870, -0.3402,  1.0462, -0.5339,  0.7969,
          0.6471,  2.0735]], device='cuda:0', grad_fn=<EmbeddingBackward>)
livedtensor([[ 0.0685,  0.5715,  1.0412,  0.2911,  0.0741, -1.1436,  1.6492,  0.9588,
          0.5765,  1.1254]], device='cuda:0', grad_fn=<EmbeddingBackward>)
minerstensor([[-1.9143, -0.0035,  0.0698,  0.0553, -0.2322,  0.4826,  0.8532,  0.6858,
         -1.1358,  1.4729]], device='cuda:0', grad_fn=<EmbeddingBackward>)
facilitatetensor([[-0.6222, -1.1633,  1.4835, -1.9129, -0.1449,  1.0691,  1.0801,  1.3137,
          1.0204, -0.1035]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Competitiontensor([[-0.1650,  1.0193, -2.0914, -1.0162,  0.8533, -0.1561,  0.1562, -0.2167,
          1.1981, -1.2565]], device='cuda:0', grad_fn=<EmbeddingBackward>)
canneriestensor([[-0.6472,  0.3364,  0.5514,  1.1595,  0.1604,  1.0840,  0.5619,  0.2528,
         -0.8368, -0.1915]], device='cuda:0', grad_fn=<EmbeddingBackward>)
borderingtensor([[ 0.9579,  1.0987,  1.5691,  0.6482, -0.5730,  0.6607,  1.1882,  1.0275,
          0.7843,  0.0964]], device='cuda:0', grad_fn=<EmbeddingBackward>)
SITEtensor([[ 0.3862, -0.8346,  2.1375,  0.7831,  0.2844,  1.1580, -0.9748,  0.3206,
         -0.0348, -1.4443]], device='cuda:0', grad_fn=<EmbeddingBackward>)
''Wetensor([[-0.0557,  0.4680, -0.3968, -1.3561,  1.5054,  0.5060,  0.0387,  0.7692,
          0.8915,  0.3448]], device='cuda:0', grad_fn=<EmbeddingBackward>)
wontensor([[ 0.8318, -0.3760, -0.7960, -0.7254, -1.1733, -0.0824, -1.1132, -0.9996,
          2.4151,  0.7474]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Belgium,tensor([[-0.1710, -1.2361, -1.1211, -0.6348,  0.2334, -0.5957, -0.0947,  1.0097,
          1.4849,  0.8178]], device='cuda:0', grad_fn=<EmbeddingBackward>)
centennialtensor([[ 0.9283,  1.8363,  1.5633, -0.3004, -2.0329, -0.6289,  1.9467, -0.2917,
          2.8233, -1.1715]], device='cuda:0', grad_fn=<EmbeddingBackward>)
stops.tensor([[-0.9381,  1.9123, -1.4698,  1.1884,  2.1042,  0.8522,  0.3749, -1.7991,
          0.1895, -0.1187]], device='cuda:0', grad_fn=<EmbeddingBackward>)
(Unity)tensor([[ 1.0143,  0.9258, -0.6169, -0.4148,  0.6864,  0.0248, -1.5912,  0.2636,
         -1.4190,  0.3499]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"Hetensor([[ 0.3239, -0.3858, -0.7375, -0.0187, -0.8682,  0.6720, -0.5530, -1.8529,
          1.0146, -0.2071]], device='cuda:0', grad_fn=<EmbeddingBackward>)
weeks,tensor([[ 0.1596, -0.3145,  0.2535,  0.9913,  1.2854, -0.2945,  0.1165, -0.3313,
          0.1308,  0.8947]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ensuretensor([[ 0.1646, -1.0871,  0.0245,  0.7687, -2.3842,  0.6803,  1.3498, -1.1860,
         -1.3070, -1.4910]], device='cuda:0', grad_fn=<EmbeddingBackward>)
confidentialtensor([[-0.8764,  0.8117, -0.1656, -2.2796,  1.6414, -1.3296, -0.5869,  1.6477,
          0.9969, -0.0692]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Tourtensor([[ 0.3163,  2.9172,  0.5220,  0.3031, -0.8873,  1.5117, -1.1566, -0.0864,
         -1.5265,  1.5030]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reformed,tensor([[ 0.8372, -0.9908, -0.3398,  0.7963,  1.3361,  0.6869,  0.2656, -1.1091,
         -1.7208,  0.6467]], device='cuda:0', grad_fn=<EmbeddingBackward>)
centurytensor([[-1.9512,  2.1897, -0.9590, -1.7686,  1.4775,  1.1486, -1.3784,  0.1842,
          1.0531, -0.6914]], device='cuda:0', grad_fn=<EmbeddingBackward>)
stricttensor([[-1.3365, -0.2580, -1.4034, -0.5469,  0.7919, -0.4102,  1.2582, -0.4125,
          0.4938,  1.3081]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Twotensor([[ 1.0838, -0.7145,  0.9453, -1.9938, -0.6834, -0.2768,  0.4844,  0.6492,
         -0.9598, -0.6014]], device='cuda:0', grad_fn=<EmbeddingBackward>)
operatestensor([[-1.0882,  0.9710,  0.7395,  0.8874,  0.7305,  0.2545,  0.6821,  1.3860,
         -0.7306,  1.6345]], device='cuda:0', grad_fn=<EmbeddingBackward>)
informedtensor([[-0.8469, -0.6869,  1.6982, -0.5124,  2.0088,  1.2271,  0.8063, -0.9336,
          0.7162, -1.6152]], device='cuda:0', grad_fn=<EmbeddingBackward>)
soldtensor([[-0.5587, -0.3913,  0.6672, -0.7355,  0.2079,  0.2672, -0.6855,  0.3663,
         -0.9504, -0.1669]], device='cuda:0', grad_fn=<EmbeddingBackward>)
receivedtensor([[ 0.5523, -0.6576,  1.1617, -0.7112, -0.4038,  0.1544,  0.2496, -0.4145,
          0.6645, -0.3285]], device='cuda:0', grad_fn=<EmbeddingBackward>)
provisiontensor([[-0.7040,  0.2591,  0.2915,  0.0183,  2.0977,  0.4058, -0.5880, -0.4319,
         -1.5972, -0.4509]], device='cuda:0', grad_fn=<EmbeddingBackward>)
compromised.tensor([[-1.1656, -1.0726,  1.1366,  0.5014,  0.9054, -0.2967,  1.2680,  0.9332,
         -1.2399, -1.2687]], device='cuda:0', grad_fn=<EmbeddingBackward>)
SEBtensor([[-1.2895, -0.3719, -1.6496,  0.8559, -1.4994, -1.3035, -0.1646,  1.5993,
          0.1362,  0.2955]], device='cuda:0', grad_fn=<EmbeddingBackward>)
suggeststensor([[ 2.1403, -0.3827, -1.3853, -0.7499,  0.1704, -0.1649,  0.2546,  0.3634,
         -0.4196, -1.2638]], device='cuda:0', grad_fn=<EmbeddingBackward>)
meaningtensor([[-0.2295, -0.9209,  0.2721,  0.2763, -0.4483,  1.1355,  0.4749, -0.2068,
         -1.9797, -0.2600]], device='cuda:0', grad_fn=<EmbeddingBackward>)
twotensor([[-0.4245,  1.9192,  0.0456, -1.2249, -1.2893, -0.7945,  0.0272,  0.7441,
         -1.3572,  0.2846]], device='cuda:0', grad_fn=<EmbeddingBackward>)
URGENT:tensor([[ 0.9146, -0.7663, -0.5490,  0.8990,  0.2874,  0.8325,  0.3680, -0.4370,
         -2.9534, -0.7468]], device='cuda:0', grad_fn=<EmbeddingBackward>)
helptensor([[-0.7894, -0.0071, -0.2667,  0.1223,  1.1100, -0.7517,  0.0720, -0.4732,
         -1.0155,  1.0650]], device='cuda:0', grad_fn=<EmbeddingBackward>)
theytensor([[-1.3518,  1.3405, -0.6099,  0.2933,  3.0492,  1.7848, -1.0587,  1.5407,
         -1.6943,  2.2054]], device='cuda:0', grad_fn=<EmbeddingBackward>)
story,tensor([[-1.3272, -0.8229,  1.7720, -1.7022,  0.1017, -1.2973, -0.6492, -1.4274,
          0.5214,  0.7228]], device='cuda:0', grad_fn=<EmbeddingBackward>)
challengestensor([[ 1.3637,  0.5493,  0.4678, -1.5095,  2.0557,  0.4606,  0.2702,  0.5109,
         -1.0306, -0.1022]], device='cuda:0', grad_fn=<EmbeddingBackward>)
basictensor([[ 1.0176,  1.0189,  0.9793, -1.3513, -1.9644,  1.5313, -1.3106, -0.9636,
         -1.0029,  1.0966]], device='cuda:0', grad_fn=<EmbeddingBackward>)
today,tensor([[-0.5768,  0.0578,  0.2016,  0.0274, -0.2303,  0.5986,  1.1647,  0.3043,
         -0.8174, -1.2897]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Taxtensor([[ 0.4857, -0.2547,  0.1616,  0.6924,  0.0768,  0.2025, -0.0052, -0.3263,
         -0.0088,  0.6232]], device='cuda:0', grad_fn=<EmbeddingBackward>)
accordingtensor([[ 2.3488, -2.7684, -1.5267,  0.7236,  2.4021,  0.1034, -1.8486,  1.3625,
         -0.0320, -0.3705]], device='cuda:0', grad_fn=<EmbeddingBackward>)
animaltensor([[ 0.5252, -1.1799, -1.1464,  0.3661,  0.9897, -0.6267,  0.5488, -1.3190,
         -0.2957,  1.5839]], device='cuda:0', grad_fn=<EmbeddingBackward>)
10tensor([[-0.2329,  1.1680,  0.4733,  0.4464, -0.8532, -1.1301, -1.7944,  0.5287,
         -1.2162,  0.6986]], device='cuda:0', grad_fn=<EmbeddingBackward>)
19%tensor([[ 0.3324, -0.7992, -0.3644, -1.0138, -2.0655,  1.1330,  1.0178, -0.1626,
         -1.7205,  0.5117]], device='cuda:0', grad_fn=<EmbeddingBackward>)
thesetensor([[ 0.7802, -0.8217, -1.2253,  1.1302, -1.6049,  0.0383, -0.6492,  0.9492,
         -0.3585,  0.7478]], device='cuda:0', grad_fn=<EmbeddingBackward>)
council.tensor([[ 0.9433, -2.7320,  0.6381,  1.4523, -1.1997,  1.8622, -0.4704,  1.3059,
         -0.8088,  0.9849]], device='cuda:0', grad_fn=<EmbeddingBackward>)
targettensor([[-1.0317, -0.3801, -0.2006, -1.2340, -0.0032,  0.6954, -0.0269,  2.1863,
          0.0499, -1.0317]], device='cuda:0', grad_fn=<EmbeddingBackward>)
aretensor([[ 0.8080,  1.1317, -1.1888,  0.2223,  1.0350,  1.2707, -0.1125,  2.0047,
         -0.7202,  0.9615]], device='cuda:0', grad_fn=<EmbeddingBackward>)
particularlytensor([[ 0.3748,  0.6495, -1.0302,  0.0880,  0.1339,  1.3146,  0.4492,  0.6863,
          1.6017,  0.3848]], device='cuda:0', grad_fn=<EmbeddingBackward>)
namedtensor([[ 0.7298,  0.1853,  0.1450,  0.4309, -1.7226, -0.9646, -0.5437, -1.3912,
         -0.0268,  0.6698]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Slovakiatensor([[ 0.9354,  0.7302, -0.9207,  0.2132,  0.1916, -0.3191, -0.7265,  0.2429,
          1.6293,  0.4889]], device='cuda:0', grad_fn=<EmbeddingBackward>)
approachingtensor([[ 0.3245,  0.9012, -0.2753, -0.2045, -0.2084, -0.7964, -0.1563, -1.6121,
         -0.9941, -1.0020]], device='cuda:0', grad_fn=<EmbeddingBackward>)
relationshiptensor([[-1.1857, -0.2868, -1.1945,  0.7998,  1.2689, -0.0324, -0.3378,  1.7778,
         -2.3275, -0.8292]], device='cuda:0', grad_fn=<EmbeddingBackward>)
acquiretensor([[-1.3422,  0.3001,  0.0323, -1.7382,  1.5580, -2.5493, -0.7066, -0.2755,
          0.8902,  0.0427]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Pyongyang'stensor([[ 0.6580,  0.3076,  0.5301,  1.3522,  0.0567,  0.9359, -0.4865,  1.0680,
         -0.5870, -0.0889]], device='cuda:0', grad_fn=<EmbeddingBackward>)
academictensor([[ 1.5111,  0.7180, -1.4472,  0.3728, -2.2491,  1.8865, -0.2682, -0.7470,
         -0.1690, -0.1559]], device='cuda:0', grad_fn=<EmbeddingBackward>)
belongstensor([[-0.0652, -0.1690, -1.6716,  0.1773, -0.1647,  0.1160,  0.4105,  1.6138,
          1.0522, -2.3540]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Localtensor([[-0.5810,  1.1349,  0.0462, -0.8680,  0.9429, -1.2862, -0.5185, -0.0674,
          0.5460,  2.5794]], device='cuda:0', grad_fn=<EmbeddingBackward>)
cametensor([[-0.2172,  1.5349, -1.8710,  0.8997, -1.0339,  0.1488,  0.2799,  1.9233,
          0.7143,  0.1327]], device='cuda:0', grad_fn=<EmbeddingBackward>)
alongtensor([[ 1.4055,  0.0740, -1.2368, -0.2173,  0.1740, -0.8366, -0.2439,  0.5502,
         -0.4432, -1.4886]], device='cuda:0', grad_fn=<EmbeddingBackward>)
anytensor([[-0.2314, -0.9211, -1.9929, -1.2195, -0.5549, -1.1959,  1.4384, -0.6702,
          0.1460,  0.0920]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Furthermore,tensor([[-1.3032, -0.4755, -0.4003,  0.8665, -0.5741,  0.0101,  0.0380, -0.6931,
         -0.0113, -0.0977]], device='cuda:0', grad_fn=<EmbeddingBackward>)
month-on-month,tensor([[-0.2223, -0.6792,  0.3651,  0.2102, -0.7529,  1.5027, -0.1840,  0.4325,
          0.4164,  3.3526]], device='cuda:0', grad_fn=<EmbeddingBackward>)
theretensor([[ 1.1662,  0.9801, -0.0929,  1.0811,  1.5922,  0.0517, -1.7641,  1.0858,
         -0.6806,  0.4911]], device='cuda:0', grad_fn=<EmbeddingBackward>)
hashtaggedtensor([[-0.1826, -0.5941,  0.7235, -0.4818, -0.1972, -0.3124,  0.4548, -0.6978,
          2.1105,  0.1969]], device='cuda:0', grad_fn=<EmbeddingBackward>)
talkingtensor([[ 0.1691, -0.5832, -0.1240, -0.2800, -0.5604, -0.1354,  1.8120,  1.6378,
         -0.3591,  0.2118]], device='cuda:0', grad_fn=<EmbeddingBackward>)
informtensor([[-0.4238, -0.4255,  0.6403,  1.7316, -0.2422,  1.3353,  1.4364,  1.0325,
          1.1096,  0.8291]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ceremonytensor([[-0.0729,  0.0519, -1.1982, -1.9412, -0.6410,  0.1174, -0.2595,  0.1389,
          0.4440, -0.1689]], device='cuda:0', grad_fn=<EmbeddingBackward>)
want.tensor([[ 0.2492, -1.4903,  0.7253, -0.1051, -1.2807, -0.2563, -0.2617,  2.0070,
          0.5135, -1.5805]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Septtensor([[-0.0151,  1.3351,  0.2902, -0.0615,  0.6348, -1.3132,  0.7517, -0.6216,
          0.9043, -1.9943]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Litatensor([[-0.1122,  0.2156, -0.5231,  1.2386, -0.0657,  0.1157, -0.3916,  0.5934,
          0.4121, -0.5197]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Mohamedtensor([[ 1.0594, -0.8848, -0.4817,  0.6684, -0.9737,  0.1347, -0.8368, -1.2185,
         -0.3773,  0.2951]], device='cuda:0', grad_fn=<EmbeddingBackward>)
presentationstensor([[ 1.1352, -0.0695, -0.8702,  0.7924,  0.0484, -0.4667, -0.6316,  0.0346,
          1.5797,  0.0125]], device='cuda:0', grad_fn=<EmbeddingBackward>)
coaltensor([[ 0.6859,  0.0191,  0.0857,  1.4921, -0.8628, -0.5579,  0.2164, -0.7751,
         -0.5913,  0.7038]], device='cuda:0', grad_fn=<EmbeddingBackward>)
joinedtensor([[-0.3768, -0.1092, -0.0970,  1.1014, -1.1822,  0.0069, -0.2294,  1.5803,
          1.4563,  1.6402]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ross,tensor([[-1.8947,  0.1324,  2.1483, -1.4012,  1.2112,  0.6503,  0.0083, -0.1699,
          0.8946,  0.4227]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Rpaxtensor([[ 0.5989,  0.0427,  0.1543,  2.8188,  1.1574,  0.6268,  0.1385, -0.0937,
         -1.2745,  1.5129]], device='cuda:0', grad_fn=<EmbeddingBackward>)
freedom,tensor([[ 1.5242,  0.2864, -1.1778, -0.7968, -2.4005, -0.4761, -0.1158,  1.1116,
          1.5159,  0.8560]], device='cuda:0', grad_fn=<EmbeddingBackward>)
operatortensor([[ 0.2102, -1.3673,  1.1554,  0.8592,  1.6877,  0.0876,  1.1845,  0.4212,
         -0.8547,  1.6310]], device='cuda:0', grad_fn=<EmbeddingBackward>)
anniversary.tensor([[ 0.1777,  0.1675, -0.2221,  1.4355, -0.4849, -0.5239, -1.8874, -0.0039,
         -0.0959,  0.3169]], device='cuda:0', grad_fn=<EmbeddingBackward>)
defendtensor([[-2.9679, -0.0552,  2.3809, -0.2345,  1.8975,  0.7863,  0.6440, -0.0434,
          0.3933, -1.1143]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reboundstensor([[-1.0441, -0.3009, -0.1971,  0.6943,  0.8627, -0.1528,  2.2028, -0.3020,
          1.4954, -0.0030]], device='cuda:0', grad_fn=<EmbeddingBackward>)
groupstensor([[ 0.2044,  0.7973,  0.8302,  1.2209,  1.4565, -1.0860,  1.6518, -1.4927,
          0.2719,  0.8206]], device='cuda:0', grad_fn=<EmbeddingBackward>)
increasetensor([[ 0.2563, -1.2338, -0.5428,  0.8657,  1.1796,  0.5262,  1.2077,  0.3421,
          1.5242, -0.1903]], device='cuda:0', grad_fn=<EmbeddingBackward>)
language,tensor([[ 0.9863,  0.0804, -0.7012, -0.4810,  0.5915, -0.7195,  3.1518,  1.0075,
         -1.7919,  0.8387]], device='cuda:0', grad_fn=<EmbeddingBackward>)
'Mosultensor([[-0.6611, -0.5830,  0.4725,  1.0241,  0.6046, -0.9519, -0.5115,  0.2218,
         -0.0860,  0.8791]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Europoltensor([[ 0.3226,  1.2385, -0.5757, -0.0608,  1.1360,  1.7895, -0.7627, -0.6848,
          1.5878,  0.3993]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Funderful,tensor([[ 1.4279,  1.3663,  1.4451, -0.4651,  1.0818, -0.8816, -0.1412,  0.4599,
         -0.8852,  2.2305]], device='cuda:0', grad_fn=<EmbeddingBackward>)
memorandumtensor([[-0.3480, -0.0142, -0.0080,  0.9754, -0.5501, -1.4590, -1.2374,  0.6065,
          0.4976,  0.1139]], device='cuda:0', grad_fn=<EmbeddingBackward>)
declinedtensor([[ 0.7884,  0.4772, -2.0689, -0.3359, -2.1940, -1.0216, -1.1842,  0.4888,
         -0.9808, -0.7106]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Tuesday,tensor([[ 1.9470,  0.3927,  2.2897, -0.2457, -0.0218, -0.1106, -2.0950,  0.8264,
          1.2091,  2.2447]], device='cuda:0', grad_fn=<EmbeddingBackward>)
sincetensor([[-0.1297,  0.2373, -1.5099,  0.5434, -1.7869, -1.3170, -0.4190,  0.5137,
         -0.5974, -1.5541]], device='cuda:0', grad_fn=<EmbeddingBackward>)
currenttensor([[ 0.7643,  0.1582,  0.2751,  0.8819,  3.5597,  1.6141, -1.6838,  0.1951,
          0.7434, -1.6999]], device='cuda:0', grad_fn=<EmbeddingBackward>)
itstensor([[-0.3501, -0.2669, -0.2403,  1.7666, -1.1184, -0.3988, -0.1385,  1.0110,
          1.6858,  0.5009]], device='cuda:0', grad_fn=<EmbeddingBackward>)
regulationstensor([[-0.3732,  0.0502, -0.4535, -0.1375, -1.3301, -1.4736, -0.2653, -1.8612,
         -0.3855, -1.3012]], device='cuda:0', grad_fn=<EmbeddingBackward>)
saying.tensor([[ 1.9215, -0.3919,  1.5645,  0.1935,  0.2998,  0.4265,  2.4996,  0.9028,
         -0.4870,  1.2714]], device='cuda:0', grad_fn=<EmbeddingBackward>)
gettensor([[-1.1489,  0.6182,  0.0887,  0.1828, -0.7510, -1.0977,  0.5304,  0.4877,
         -0.0902,  0.1519]], device='cuda:0', grad_fn=<EmbeddingBackward>)
servicetensor([[ 2.3275,  0.6576,  1.3940,  0.7525,  1.2305,  0.1286,  0.5896, -1.0143,
          0.1712, -0.9654]], device='cuda:0', grad_fn=<EmbeddingBackward>)
othertensor([[ 0.7782,  1.0223, -0.5132, -0.7697, -0.3019,  1.1851,  0.2334,  1.4301,
          0.5987, -1.0927]], device='cuda:0', grad_fn=<EmbeddingBackward>)
consolidatedtensor([[ 2.2190,  1.2155, -1.1224, -0.6540,  1.0645,  0.0902,  0.4613,  2.0887,
          0.8818, -0.5377]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"disastrous".tensor([[ 0.5960,  0.6947, -0.8842,  0.7092, -0.6989, -0.9702,  0.3566, -0.2232,
          1.5831, -1.6539]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"Whentensor([[-1.8895,  0.3793,  0.4715,  1.1867,  1.7040,  1.4803, -0.2342,  0.8260,
          0.2592,  1.8450]], device='cuda:0', grad_fn=<EmbeddingBackward>)
offeredtensor([[-1.8388, -1.1953, -1.9719, -0.3464, -0.4461,  0.0460,  1.6635,  0.4822,
         -1.1570, -0.7371]], device='cuda:0', grad_fn=<EmbeddingBackward>)
combinedtensor([[-0.5635, -1.3253, -0.0495,  1.3402, -1.6109,  1.2202,  0.1022, -0.3453,
         -0.1180,  1.0329]], device='cuda:0', grad_fn=<EmbeddingBackward>)
decline.tensor([[-1.3068,  1.0735,  1.2883, -0.0946,  0.1042,  1.1531,  1.2605,  1.3628,
         -0.6429, -1.3898]], device='cuda:0', grad_fn=<EmbeddingBackward>)
possibilitytensor([[ 1.1784, -0.5572,  1.4424, -1.4942, -1.7349,  0.9836, -0.6154, -1.1449,
          1.6662,  0.6902]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Russiatensor([[ 1.7105, -0.6428,  0.5368, -0.2210,  0.2481,  0.2744,  0.5865,  0.2084,
          0.8233, -0.3198]], device='cuda:0', grad_fn=<EmbeddingBackward>)
enoughtensor([[ 0.2400,  0.2840, -0.1919,  2.4850, -0.4916, -0.5421,  1.0260,  1.0374,
          0.7273,  1.2800]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Cavaliers.tensor([[-0.9659,  0.4097,  0.4908,  0.2345,  1.4432,  0.5417, -0.2195,  0.3495,
         -0.5891,  0.7382]], device='cuda:0', grad_fn=<EmbeddingBackward>)
dream,tensor([[-0.5486,  1.2430, -1.5902,  0.6518, -0.0928, -0.0099,  0.2776,  0.5812,
         -1.1451,  0.3266]], device='cuda:0', grad_fn=<EmbeddingBackward>)
month.tensor([[ 0.2724,  0.5259, -1.5391,  1.6136, -0.4251,  0.3780, -1.0758, -1.7315,
         -1.4956, -0.5157]], device='cuda:0', grad_fn=<EmbeddingBackward>)
financetensor([[ 0.9177, -1.0977, -0.5609,  0.5658, -0.2955,  0.9943,  0.3910,  0.1456,
          0.4508,  1.4764]], device='cuda:0', grad_fn=<EmbeddingBackward>)
14.3tensor([[ 0.5207,  0.7290,  1.2444, -0.2996,  0.5371,  0.3845,  1.1693, -0.9046,
         -1.2403, -2.0643]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ievatensor([[-1.2272, -0.1662,  1.2339, -0.0298,  0.0614, -0.5745, -0.7609,  1.3915,
         -0.6530, -0.0921]], device='cuda:0', grad_fn=<EmbeddingBackward>)
degreestensor([[-0.5229, -0.0741, -1.0875,  0.6183,  0.8217,  0.8503,  0.5271,  2.3065,
          0.4722, -0.6108]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Euro-Atlantictensor([[-0.7886,  1.0897, -0.9102,  0.4786, -0.4028,  0.0224, -0.0609, -0.9865,
         -1.7771, -1.1607]], device='cuda:0', grad_fn=<EmbeddingBackward>)
informstensor([[ 1.1759,  1.7589, -0.0249, -0.4476,  0.2454,  0.9721, -0.5670, -0.3574,
          0.1586,  1.0156]], device='cuda:0', grad_fn=<EmbeddingBackward>)
inspectionstensor([[-1.4013,  2.4468, -0.0310, -0.1880, -1.6579, -1.3413,  1.5839,  0.3219,
          0.8636, -0.2137]], device='cuda:0', grad_fn=<EmbeddingBackward>)
India,tensor([[-1.1755,  1.2717, -0.4098,  0.7993, -1.5824,  0.2134, -1.0561, -2.5130,
         -1.1355,  0.3368]], device='cuda:0', grad_fn=<EmbeddingBackward>)
aspectstensor([[-0.8484,  0.9564,  2.5982,  1.4659,  0.7387,  0.1379,  2.2035, -0.5216,
          0.0054, -0.2424]], device='cuda:0', grad_fn=<EmbeddingBackward>)
57%tensor([[ 0.0402, -0.1414, -0.0326,  0.2685, -0.1949,  0.2276, -1.1378,  1.4054,
         -0.4364,  1.6216]], device='cuda:0', grad_fn=<EmbeddingBackward>)
regionstensor([[-0.2732,  1.0473, -0.7811,  0.1103, -0.7784,  0.3811,  0.0295,  0.7240,
         -1.0928, -0.0263]], device='cuda:0', grad_fn=<EmbeddingBackward>)
homeworktensor([[ 0.6818,  1.1375,  0.4572, -0.9774, -0.3847, -0.0824,  0.0577,  1.9088,
         -0.2535,  0.2395]], device='cuda:0', grad_fn=<EmbeddingBackward>)
contacttensor([[ 0.5845, -1.5941, -0.5542,  0.6618,  0.5379,  1.3861, -1.3925,  0.7192,
         -0.0962, -0.5985]], device='cuda:0', grad_fn=<EmbeddingBackward>)
dramatictensor([[ 2.3989, -0.9488,  0.8097,  1.0562, -0.1053, -1.1798,  0.8556, -0.2688,
         -0.4519, -0.0658]], device='cuda:0', grad_fn=<EmbeddingBackward>)
humanitariantensor([[-0.0324,  0.4711,  0.4487,  0.4318,  0.3978,  0.2708,  0.4298,  1.1889,
          0.1113, -1.1915]], device='cuda:0', grad_fn=<EmbeddingBackward>)
decisiontensor([[-0.1291, -0.8474, -0.5625, -2.1468, -0.6691, -1.1112,  0.8106, -1.3006,
          1.0260,  1.1670]], device='cuda:0', grad_fn=<EmbeddingBackward>)
September,tensor([[ 0.7726,  0.2123,  0.2371,  0.4571,  2.9991,  0.3888,  0.4544, -1.2349,
         -0.4778, -0.2832]], device='cuda:0', grad_fn=<EmbeddingBackward>)
urgenttensor([[ 2.8447e-01,  1.1018e+00,  1.6761e+00,  5.2685e-02, -5.9124e-01,
          2.7938e+00,  1.6130e-01,  3.0978e-01, -1.4777e+00, -9.9757e-04]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
disputedtensor([[-1.2846, -0.1023, -0.2930,  1.1218,  0.5916, -0.8646,  0.1644, -0.1602,
          0.5285,  3.0135]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Elzbietatensor([[-0.2339,  0.4226,  0.5600, -0.6293, -1.3874,  0.1475,  0.6628,  1.0272,
         -0.2247, -0.3246]], device='cuda:0', grad_fn=<EmbeddingBackward>)
airspacetensor([[ 1.7198, -0.9491, -0.6312, -0.4887, -0.8929, -0.1007, -0.4917,  0.7047,
         -0.8809, -0.7720]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Budapest.tensor([[-1.2990, -0.4445,  1.5762,  0.0593, -0.6071,  1.2291,  2.0188, -1.1600,
          0.0551,  2.0495]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reportingtensor([[ 0.4205,  0.9643, -0.4494,  0.2862,  0.6685, -1.4505, -1.1295, -1.3312,
          0.9846, -0.5773]], device='cuda:0', grad_fn=<EmbeddingBackward>)
macroeconomictensor([[-1.2444, -0.1250, -1.3092,  2.2028, -0.9941, -1.1972,  0.2799, -0.7299,
         -0.5454, -0.9321]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Belarustensor([[ 0.1006, -2.0303, -0.5265, -0.2039, -0.3866, -1.2401, -0.8867,  1.8519,
         -1.0762, -1.2967]], device='cuda:0', grad_fn=<EmbeddingBackward>)
yeartensor([[ 0.4564,  0.8515, -0.8345, -0.0145,  0.5728,  0.0205,  0.7776,  0.6256,
          0.0796, -0.1047]], device='cuda:0', grad_fn=<EmbeddingBackward>)
riskstensor([[-0.9853, -0.8737, -0.4539,  0.1513, -0.4218,  0.8338, -0.1498,  0.5131,
         -0.3846, -0.9138]], device='cuda:0', grad_fn=<EmbeddingBackward>)
pitchingtensor([[-0.9707, -0.6308, -0.6864, -0.4599,  2.0641, -0.1872, -0.8327, -0.3298,
         -0.7507,  0.0207]], device='cuda:0', grad_fn=<EmbeddingBackward>)
titletensor([[-0.8889,  0.0219, -0.6799,  1.1637, -1.0087, -0.6231, -0.5158, -0.8634,
         -0.4007, -1.4221]], device='cuda:0', grad_fn=<EmbeddingBackward>)
collectiontensor([[-0.0357, -0.2149,  1.7081,  1.2325,  1.4304, -1.1136, -2.7818,  1.1437,
         -0.8673,  0.5966]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Citytensor([[-0.8343,  0.3005,  0.2421, -1.2890,  0.9501, -0.8598,  0.1271, -0.8764,
          0.0346, -0.6066]], device='cuda:0', grad_fn=<EmbeddingBackward>)
povertytensor([[-0.2097, -1.5221,  0.6664,  0.1546,  1.1780,  0.2178,  0.0527,  0.8060,
         -0.0533, -0.2989]], device='cuda:0', grad_fn=<EmbeddingBackward>)
pimpingtensor([[-1.0869e+00,  4.1345e-01,  9.6161e-01,  8.9389e-04,  1.0420e+00,
          7.4563e-01,  4.9450e-01, -8.5534e-01,  6.3704e-01,  2.7976e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
15:9)tensor([[ 0.5513, -1.4106,  0.2443,  0.5525, -1.1195, -1.1287, -0.1608, -0.6088,
          0.4660,  0.0602]], device='cuda:0', grad_fn=<EmbeddingBackward>)
milk;tensor([[-0.3394,  0.3375,  1.5685, -0.2185, -0.0336, -0.9957,  0.5387, -0.0423,
          1.0847, -0.6375]], device='cuda:0', grad_fn=<EmbeddingBackward>)
LItensor([[ 1.6184, -0.3248, -1.0753,  1.6158,  1.9808, -1.3932, -0.0560,  0.7056,
          0.6566,  0.7391]], device='cuda:0', grad_fn=<EmbeddingBackward>)
forwardedtensor([[-0.9033,  1.2352, -0.3645, -0.9178, -0.5689, -1.0239, -0.7101, -1.1820,
          0.7565,  1.5514]], device='cuda:0', grad_fn=<EmbeddingBackward>)
partners,tensor([[ 0.2883,  0.7172,  0.2717, -1.8740,  1.5878, -1.4624, -2.3279, -0.8253,
          0.6843, -1.4294]], device='cuda:0', grad_fn=<EmbeddingBackward>)
potentiallytensor([[-0.6245,  0.3429,  2.1951,  0.6895, -0.1993, -0.1832, -1.3696, -0.0901,
         -1.3843, -1.2390]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Publictensor([[ 1.1195e+00, -2.1541e-01, -5.1540e-01,  1.2486e-03,  4.3132e-01,
         -1.3079e+00, -1.3941e+00,  2.0140e+00,  6.0828e-01, -6.6062e-01]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
positive,tensor([[-0.0235,  0.3731,  0.5665,  0.4893, -0.4926,  0.3678,  0.7931, -0.6042,
         -0.2409,  0.6874]], device='cuda:0', grad_fn=<EmbeddingBackward>)
dependtensor([[-2.0979,  1.3959, -0.6720,  2.3117, -0.0244,  1.0194,  0.3243,  2.6745,
         -0.6299,  0.4952]], device='cuda:0', grad_fn=<EmbeddingBackward>)
increased.tensor([[ 1.5176,  0.6875,  0.2333, -0.6606, -0.2262,  0.4396,  0.3909, -0.1548,
          0.1729,  0.6092]], device='cuda:0', grad_fn=<EmbeddingBackward>)
importanttensor([[-1.2407, -1.7620,  1.4600, -1.3297, -0.8637,  0.4776, -0.1940, -1.6676,
          0.2220,  0.1776]], device='cuda:0', grad_fn=<EmbeddingBackward>)
extendedtensor([[ 1.2299, -0.6326, -0.3710,  0.6071,  0.5723,  0.7094, -0.4101,  2.1673,
          0.9859, -0.6153]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ozolstensor([[-0.8245,  1.3197,  0.8139,  0.8315, -2.3444,  0.5694,  1.0159,  0.2201,
          0.9075, -0.3589]], device='cuda:0', grad_fn=<EmbeddingBackward>)
''Littletensor([[ 1.1134,  0.2983, -1.5585,  0.1924,  1.3696,  1.2847, -1.6184, -1.3206,
         -1.9585, -0.4798]], device='cuda:0', grad_fn=<EmbeddingBackward>)
excellenttensor([[-0.6658, -0.6003, -2.0311, -0.8274, -2.0675, -1.4073,  2.3362, -0.2646,
         -1.3654,  0.5253]], device='cuda:0', grad_fn=<EmbeddingBackward>)
opportunities.tensor([[ 1.1481, -0.5256, -0.9886, -0.6069, -0.9007, -0.7426, -0.6210, -1.1914,
         -1.1155, -0.8600]], device='cuda:0', grad_fn=<EmbeddingBackward>)
primetensor([[-1.2020, -1.1479,  0.6097, -0.3717, -0.1527,  1.5878,  0.7731, -0.9528,
         -0.6905,  0.6685]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Baskakovtensor([[ 1.1018, -0.3566,  0.2286,  0.7638,  0.3396,  1.0220,  0.3851,  0.2091,
         -0.0550, -0.0960]], device='cuda:0', grad_fn=<EmbeddingBackward>)
actuallytensor([[ 0.5831, -0.7241,  0.6721,  1.4376, -0.4195,  0.3457,  1.2548,  0.4604,
          1.4446,  0.5159]], device='cuda:0', grad_fn=<EmbeddingBackward>)
(out)tensor([[-0.2209, -0.2529,  0.0699, -1.5015, -0.6593, -0.8767,  0.8225, -1.4858,
          2.0203, -1.4792]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Productions,tensor([[ 0.5016,  0.4464,  0.3348, -0.0049, -0.9265,  0.1351, -0.5512,  0.7454,
          0.1062, -0.0437]], device='cuda:0', grad_fn=<EmbeddingBackward>)
educationtensor([[-2.1451,  0.9430,  0.7529, -0.3485,  0.9153,  2.0397, -0.2117,  1.6768,
          0.2435,  1.0362]], device='cuda:0', grad_fn=<EmbeddingBackward>)
settensor([[ 1.6965, -0.2956, -0.8622, -1.1418,  0.1758,  0.7766, -0.4654,  0.3928,
         -1.5138, -0.6769]], device='cuda:0', grad_fn=<EmbeddingBackward>)
chain,tensor([[ 1.0061,  1.4360, -1.2724,  0.6578, -1.1798, -0.5523,  0.4829,  1.7044,
         -0.5542,  0.6302]], device='cuda:0', grad_fn=<EmbeddingBackward>)
''Ittensor([[-0.0599,  0.3847,  0.5318,  1.7890, -0.3550, -0.8601, -0.8222, -0.5681,
          0.9107, -1.1526]], device='cuda:0', grad_fn=<EmbeddingBackward>)
creditingtensor([[ 0.6944, -1.5161,  0.9595, -0.0066, -0.9790, -0.1385, -0.5989,  0.3939,
         -1.0289,  0.2868]], device='cuda:0', grad_fn=<EmbeddingBackward>)
1:1,tensor([[-0.1252, -0.0191,  0.0775, -0.6013,  0.0353, -0.9957, -0.3240,  2.0841,
          0.4213, -0.1831]], device='cuda:0', grad_fn=<EmbeddingBackward>)
upontensor([[-0.4635, -1.8339, -1.1035,  0.2829,  0.4652,  0.9036,  1.2792,  0.8260,
         -0.4974, -0.5514]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Riotensor([[ 1.3934,  0.8233,  0.2338, -0.4570,  0.5374,  0.2335, -0.7703, -0.6028,
          0.4388,  0.6252]], device='cuda:0', grad_fn=<EmbeddingBackward>)
electiontensor([[-0.3664,  2.3945, -0.3503,  0.9744, -1.9727, -0.5349,  1.5943, -1.4656,
          0.5012, -0.2649]], device='cuda:0', grad_fn=<EmbeddingBackward>)
teamtensor([[ 0.9458, -0.3820, -0.4691,  0.2063,  1.9083, -0.9488, -0.8643, -0.6347,
          1.2493,  0.5543]], device='cuda:0', grad_fn=<EmbeddingBackward>)
River,tensor([[ 2.0017,  0.8102, -1.0971,  0.7314,  0.4357,  0.0760, -0.7937,  0.3830,
          0.7193, -0.0969]], device='cuda:0', grad_fn=<EmbeddingBackward>)
eurotensor([[-0.1575, -1.6537,  1.7366,  0.5182, -0.8536,  0.1861, -0.5550,  0.7627,
          0.8884, -1.2191]], device='cuda:0', grad_fn=<EmbeddingBackward>)
civiltensor([[-1.0401,  0.4047,  0.1095,  0.4887,  0.9111,  1.3611,  0.3636,  2.8846,
         -0.1577,  0.1578]], device='cuda:0', grad_fn=<EmbeddingBackward>)
escape.tensor([[-0.6505, -1.1725, -1.2850,  1.6063, -0.1715, -1.2103, -3.0860, -0.5231,
         -0.7950, -1.2067]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Viennatensor([[-0.2836,  1.5807,  0.5730,  0.2176,  0.9636, -1.0946, -1.2158,  0.1904,
          0.5189, -1.3963]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Baltic-Beneluxtensor([[ 0.6116, -0.2932, -0.9755, -1.8380, -2.3397,  0.6816,  0.4410,  0.5168,
          1.7877, -0.9698]], device='cuda:0', grad_fn=<EmbeddingBackward>)
broketensor([[-1.5946, -0.6346,  0.0940, -0.2567,  1.6082,  0.8182, -0.6474,  2.3938,
          0.4246,  0.6826]], device='cuda:0', grad_fn=<EmbeddingBackward>)
general-secretarytensor([[ 1.1808,  0.5794, -1.7818,  0.6739,  0.1856,  0.4258,  1.6108,  0.2070,
         -3.5839, -0.9829]], device='cuda:0', grad_fn=<EmbeddingBackward>)
water.tensor([[-0.8897,  1.0924, -0.8251,  1.1603,  0.6183,  0.3962,  0.1646,  0.5246,
          1.0459,  1.4442]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Welfaretensor([[-1.3711, -1.4358, -0.6848, -1.3517,  0.6298, -0.6801,  0.6831, -0.3334,
         -1.7922,  0.8902]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Andatensor([[-0.6418,  2.2757, -0.1585,  0.1932, -1.0153, -1.8681, -0.6770, -0.9664,
         -0.9699, -1.8358]], device='cuda:0', grad_fn=<EmbeddingBackward>)
technologytensor([[ 2.0396,  1.6807, -0.6362,  0.3969, -2.2580,  0.0683, -2.0846, -0.9089,
         -0.2898, -0.0663]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Sometensor([[-0.2014,  0.4755, -1.6320, -0.4641, -0.9640,  1.3721, -1.0072, -0.5088,
         -1.0479,  0.6579]], device='cuda:0', grad_fn=<EmbeddingBackward>)
facttensor([[-0.6893, -1.5230,  1.1046,  1.1214, -1.2647,  1.6723,  1.5677,  0.4245,
         -1.2396, -1.0516]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Footballtensor([[-0.5297, -0.8817, -0.3840, -0.0284, -0.1388,  0.4658,  0.9909, -0.6385,
          0.9997,  1.1733]], device='cuda:0', grad_fn=<EmbeddingBackward>)
cooler,tensor([[-1.0730, -1.1866, -0.6208, -1.8513, -0.8639, -1.0543,  0.1553, -0.5190,
         -1.1580, -1.3894]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Normundstensor([[-0.9049, -0.8258, -2.4141,  0.4957,  1.1963, -1.0231,  1.9099,  1.6601,
          0.4099,  0.4367]], device='cuda:0', grad_fn=<EmbeddingBackward>)
looktensor([[ 0.3133,  0.5914, -1.6009, -0.4941,  1.0518,  1.2985,  1.5217, -0.1726,
          0.6004, -0.3780]], device='cuda:0', grad_fn=<EmbeddingBackward>)
localtensor([[ 0.7530, -1.3130,  0.6451, -0.4126,  0.0600, -0.0016, -0.5268, -1.2209,
         -0.8326,  0.7268]], device='cuda:0', grad_fn=<EmbeddingBackward>)
1,000tensor([[-0.2155, -0.0538,  2.1296,  1.3429, -0.8576,  0.1685, -0.8526, -0.8763,
         -2.0759,  1.2506]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Tuesdaytensor([[ 0.8885, -0.5945, -1.0608, -0.7488,  0.5813, -0.4609,  1.1677, -0.0697,
         -1.8113,  0.7287]], device='cuda:0', grad_fn=<EmbeddingBackward>)
9.tensor([[ 0.8873, -0.6217, -0.4996,  0.4210,  0.3725, -0.3340, -1.3435,  0.9735,
         -0.6785, -0.3524]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Westerntensor([[ 0.4898,  1.4041, -0.8904,  1.9910,  1.3422, -2.2858, -1.2807,  0.2923,
         -0.6588,  1.0926]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Seneca'stensor([[ 0.9273,  2.9150, -0.2087,  1.0348, -0.1841, -1.8784, -2.3436,  1.5951,
          0.6036, -0.9921]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Unitedtensor([[-0.1236,  1.2244,  0.2343, -0.3805, -0.6524, -0.9253,  0.8971, -0.3918,
          0.1070, -0.3725]], device='cuda:0', grad_fn=<EmbeddingBackward>)
findingtensor([[-1.9665, -0.6365,  1.4296,  0.6099,  0.9289,  1.0637,  0.0317,  2.2114,
         -0.1629,  0.6836]], device='cuda:0', grad_fn=<EmbeddingBackward>)
balltensor([[-0.5634,  0.8687, -0.8110,  0.9852,  1.5657, -1.5164,  0.2965, -0.2463,
         -2.2842,  0.7204]], device='cuda:0', grad_fn=<EmbeddingBackward>)
especiallytensor([[-1.0506, -0.0314, -2.0631, -0.9341, -0.5983, -1.1292, -0.1213,  0.9391,
         -0.9471,  0.8797]], device='cuda:0', grad_fn=<EmbeddingBackward>)
newtensor([[ 2.5200,  1.5975,  1.2410, -0.1018, -0.4948, -0.2939, -0.0751, -1.3794,
         -1.6113,  0.4636]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Samoilovs/Smedinstensor([[ 1.1348,  0.7145,  0.1507,  0.2949, -1.5945,  0.7153,  0.1098,  0.9159,
         -1.5450, -0.0928]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Federaltensor([[ 1.8044, -0.6466, -1.3266, -1.0843,  1.0908,  0.2508,  0.4329,  0.3754,
         -0.5591,  0.5478]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Speakingtensor([[-1.3885,  0.4862,  2.0163,  0.5993,  2.8424, -0.9173,  0.2838,  0.5275,
         -1.0407,  0.0677]], device='cuda:0', grad_fn=<EmbeddingBackward>)
17.2tensor([[-0.8120, -1.0182, -0.6106, -0.0437, -0.9416,  1.1701,  0.8650,  1.4443,
         -0.6497,  0.7492]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Petrtensor([[-0.8251, -0.9060,  1.4645, -0.4769, -0.4835,  0.5079,  0.3552, -0.1721,
          1.4356, -1.7778]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Dumatensor([[-0.0153,  0.2067,  1.2826, -1.6996,  0.7621, -1.1992,  0.1578,  1.2566,
          1.5843, -0.1692]], device='cuda:0', grad_fn=<EmbeddingBackward>)
billion.tensor([[-0.5040,  0.3546, -0.9619, -0.0090,  1.2644,  0.5377, -0.6615,  0.0270,
         -0.5528, -2.2054]], device='cuda:0', grad_fn=<EmbeddingBackward>)
guardtensor([[-1.7617,  0.7779, -2.4138, -0.0452,  2.0054,  1.0739,  0.7921,  0.4893,
         -3.1587, -0.1076]], device='cuda:0', grad_fn=<EmbeddingBackward>)
GribuTeviAtpakaltensor([[-0.8776,  0.3159, -0.8123, -0.5062,  0.0201,  1.7204, -0.5192,  1.4496,
          0.6612, -0.6820]], device='cuda:0', grad_fn=<EmbeddingBackward>)
parents,"tensor([[ 1.0323, -0.6967,  1.0457,  0.8974, -0.3798, -0.1521, -0.4136,  0.9260,
          0.0861, -0.5824]], device='cuda:0', grad_fn=<EmbeddingBackward>)
crashtensor([[ 0.1987, -0.3201,  0.8937,  0.3999,  0.5789,  0.2898,  0.2731, -0.7244,
          0.9686, -0.0806]], device='cuda:0', grad_fn=<EmbeddingBackward>)
mighttensor([[-1.0488,  0.0692,  0.5848, -1.2472, -0.6052, -0.7243,  0.3998,  1.0754,
          0.4430, -1.5900]], device='cuda:0', grad_fn=<EmbeddingBackward>)
underground,tensor([[ 0.3393, -0.0801, -1.7078,  0.3351, -1.3004, -0.8871,  0.7252,  1.0947,
          0.2738,  0.6743]], device='cuda:0', grad_fn=<EmbeddingBackward>)
disturbedtensor([[-0.8591, -0.7995, -0.2407,  0.2593,  0.0366, -2.0006,  0.3367, -0.1539,
          0.1199, -0.0508]], device='cuda:0', grad_fn=<EmbeddingBackward>)
internationaltensor([[-0.1681, -0.2048, -1.3614, -0.7020,  0.0761,  0.2966,  0.1116,  0.4909,
         -0.9777,  1.0523]], device='cuda:0', grad_fn=<EmbeddingBackward>)
casetensor([[-0.7651, -1.1085, -1.9622,  0.9200, -0.5261,  0.4148, -0.7360,  1.9955,
         -0.4112,  1.1691]], device='cuda:0', grad_fn=<EmbeddingBackward>)
debtstensor([[-1.1403,  0.2058, -2.0418,  0.3856, -2.3669, -0.6825, -2.4382,  0.9634,
          0.7866,  0.2733]], device='cuda:0', grad_fn=<EmbeddingBackward>)
severaltensor([[-1.2585, -0.6319,  0.9573, -0.9421, -0.8229, -0.3655,  0.5595, -0.8621,
         -1.1445,  0.3881]], device='cuda:0', grad_fn=<EmbeddingBackward>)
presentstensor([[-0.9326,  0.0212,  0.0427, -0.7984, -0.7069,  0.6983, -0.7478,  2.9553,
          1.6009,  2.3473]], device='cuda:0', grad_fn=<EmbeddingBackward>)
system.tensor([[-0.2396, -0.7771,  0.7265, -1.0823,  0.5526, -2.0405,  0.5833,  0.1076,
          0.8411, -0.0434]], device='cuda:0', grad_fn=<EmbeddingBackward>)
transportation,tensor([[-1.1101,  0.0889,  0.5591, -0.3860, -0.9479, -1.0486, -0.2461,  0.8650,
         -1.8844, -0.2021]], device='cuda:0', grad_fn=<EmbeddingBackward>)
embassytensor([[ 0.7345,  0.4911, -0.8291, -1.3154,  0.5589,  0.0533,  0.7499, -0.2666,
          1.0855,  2.1427]], device='cuda:0', grad_fn=<EmbeddingBackward>)
sidestensor([[-0.6408,  0.2598,  0.9448,  1.0606,  0.5248,  1.2649,  1.2336,  1.0803,
         -0.3480,  1.2137]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Inaratensor([[-0.2858,  0.1440,  0.0671,  0.2645,  1.5530, -1.0818, -1.7189,  0.2540,
          0.4078, -1.4989]], device='cuda:0', grad_fn=<EmbeddingBackward>)
contributiontensor([[ 1.6446, -1.0181,  0.8628, -0.8436,  0.3205,  0.2886, -0.6245, -1.7994,
         -0.6496, -1.4132]], device='cuda:0', grad_fn=<EmbeddingBackward>)
systemtensor([[ 1.5406, -0.4027, -0.2610,  0.5454, -2.0848, -1.0130,  1.4242,  0.9816,
          1.3144, -0.1766]], device='cuda:0', grad_fn=<EmbeddingBackward>)
promisedtensor([[-1.2531,  0.7379, -1.5262,  1.1498, -1.4043, -0.4557, -1.4163, -0.2334,
         -0.9406, -0.3453]], device='cuda:0', grad_fn=<EmbeddingBackward>)
permittensor([[-0.1719, -1.2490, -0.8370, -1.7062,  1.0173, -0.8970,  1.0901,  1.3254,
          0.3575,  1.5303]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Statetensor([[ 0.0594, -0.1865, -1.1827, -2.6820, -1.9998, -0.0172, -2.9071, -0.0417,
         -1.5116, -0.4933]], device='cuda:0', grad_fn=<EmbeddingBackward>)
employees'tensor([[-2.3904,  1.8967,  0.0970, -1.1516, -0.6370,  0.4738, -1.6654,  2.1410,
         -0.6092, -0.1646]], device='cuda:0', grad_fn=<EmbeddingBackward>)
sidetensor([[ 0.1550, -0.5504, -0.5165,  0.2333, -0.0368, -0.7217,  0.4126, -0.9053,
          0.8110,  0.1855]], device='cuda:0', grad_fn=<EmbeddingBackward>)
findtensor([[-0.7998,  0.5251, -0.5908,  0.9557,  0.6514,  0.8840, -0.1973, -0.0548,
         -0.3340,  0.0237]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Oxfordtensor([[ 0.0028,  1.0872,  0.4438,  0.3423, -0.0443, -0.4641, -0.2145, -2.1286,
          0.4813, -0.5119]], device='cuda:0', grad_fn=<EmbeddingBackward>)
children,tensor([[ 1.5446, -1.2777,  1.4602,  0.5042, -0.7513,  0.6377,  1.3421, -0.3879,
         -0.2085,  0.7568]], device='cuda:0', grad_fn=<EmbeddingBackward>)
diversificationtensor([[ 1.0182, -0.1953, -0.7177,  0.9957,  0.5772,  0.3128,  0.9936, -0.6448,
          0.9411,  0.6947]], device='cuda:0', grad_fn=<EmbeddingBackward>)
havetensor([[-0.3194,  2.1041,  1.5644, -0.6287, -1.4339,  1.6643,  0.2869,  1.6483,
          0.3085,  0.2396]], device='cuda:0', grad_fn=<EmbeddingBackward>)
clientstensor([[-0.7789, -0.1992,  1.2253, -1.4240, -1.0172,  1.0857, -1.6305,  0.9251,
         -0.3842,  0.1700]], device='cuda:0', grad_fn=<EmbeddingBackward>)
closetensor([[ 0.7541, -0.2127,  1.1657, -2.4009, -1.1692,  0.7689, -0.5159, -1.5054,
          0.3870, -0.3094]], device='cuda:0', grad_fn=<EmbeddingBackward>)
benefittensor([[ 1.2234, -0.4083, -0.8862, -1.4057, -1.8117,  1.3421,  0.4224, -2.0390,
         -1.4242,  0.9338]], device='cuda:0', grad_fn=<EmbeddingBackward>)
hightensor([[-0.7932,  0.6830,  1.1221, -0.8296,  1.1798, -0.9428, -0.2038, -0.2393,
         -0.9152, -0.2944]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Polandtensor([[-1.0503,  0.1363,  2.0863,  0.7013,  1.1147,  0.9581,  2.0271,  1.4108,
         -1.7257, -0.1508]], device='cuda:0', grad_fn=<EmbeddingBackward>)
postponedtensor([[-0.3755, -0.0374,  2.0272, -0.8469, -0.1401,  0.3003, -0.4817,  0.5840,
          0.7482, -1.1820]], device='cuda:0', grad_fn=<EmbeddingBackward>)
technology,tensor([[-1.9800, -0.7763, -1.3175,  0.0781, -0.0828, -1.2555,  1.2210,  0.8332,
          0.1556,  1.1308]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Remunerationtensor([[ 0.7427,  0.8381, -1.2732,  1.3964, -1.3653, -0.1354, -1.3743, -0.8200,
         -0.3654, -1.3558]], device='cuda:0', grad_fn=<EmbeddingBackward>)
June,tensor([[-1.8286,  1.3372, -0.9993, -0.7454,  0.8958,  1.2683, -2.2881,  1.5633,
         -0.7428, -0.4264]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Commonwealthtensor([[-0.0422,  0.0138, -0.3398,  0.7831, -2.3442, -0.7605,  0.2287, -0.2018,
         -0.0946,  0.4326]], device='cuda:0', grad_fn=<EmbeddingBackward>)
radiotensor([[-0.7257, -0.9433, -0.1807, -0.5602, -1.3279,  1.4087, -0.8378,  1.1269,
          0.3300,  0.0284]], device='cuda:0', grad_fn=<EmbeddingBackward>)
801tensor([[ 1.7907,  0.6627,  0.0372, -0.1843,  0.5082, -1.3513,  0.4349, -1.1393,
          0.5499,  0.9470]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Martinstensor([[-1.8122, -1.0979, -0.8426,  2.5883,  2.1659, -0.2747, -0.4263, -1.0298,
          1.0483,  0.2817]], device='cuda:0', grad_fn=<EmbeddingBackward>)
submarinestensor([[-0.1762,  0.1085, -0.5092, -1.2489, -2.0681,  0.4301,  0.8585, -0.5558,
          1.7469,  1.0034]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Heroes’tensor([[-1.3599, -0.8498, -0.2965,  0.0167, -0.0591,  0.8284, -0.1810, -0.5815,
         -2.1979,  0.7874]], device='cuda:0', grad_fn=<EmbeddingBackward>)
strengthenstensor([[-0.3716, -0.0586, -0.7183,  0.4740,  1.4307, -0.0094, -1.6022,  0.5828,
         -0.5906,  0.2370]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Wednesday.tensor([[-2.4622,  0.6128,  0.5479,  0.7136,  0.3235,  0.0821, -0.8659,  0.1306,
          0.1617,  0.2019]], device='cuda:0', grad_fn=<EmbeddingBackward>)
percent.tensor([[-1.4346,  1.2572,  0.0371,  0.0776,  0.3035, -0.9175,  2.5241, -1.6819,
          0.8711, -0.4658]], device='cuda:0', grad_fn=<EmbeddingBackward>)
speaktensor([[-0.8208,  1.4692,  1.9640,  0.7070,  0.5462, -0.8636, -0.5249,  0.3982,
          0.3810,  0.2654]], device='cuda:0', grad_fn=<EmbeddingBackward>)
IKEA'stensor([[ 1.4490,  0.3545, -0.4951, -1.7557,  1.0943, -0.9414,  0.1675, -0.2833,
         -1.2448,  0.5678]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Presstensor([[ 0.3319, -0.5313, -1.1525, -0.3290,  2.1839, -1.2034, -0.5270,  0.7408,
         -0.7312, -1.2056]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Mazunas,tensor([[-0.9858,  0.4451, -1.7300,  0.9783, -0.1103,  0.5830,  0.2368,  0.2582,
         -1.0287, -0.4722]], device='cuda:0', grad_fn=<EmbeddingBackward>)
bankerstensor([[-1.0436,  0.8077, -0.4983, -0.8946,  0.8299, -1.8057, -0.0223,  1.1884,
         -0.8996,  0.2007]], device='cuda:0', grad_fn=<EmbeddingBackward>)
facetensor([[-0.6916, -0.2647, -0.1009,  1.4304,  0.1890, -0.2872, -0.3291, -1.1979,
          0.4247,  0.3778]], device='cuda:0', grad_fn=<EmbeddingBackward>)
planes,tensor([[ 0.2891, -0.3595,  0.9331, -0.8504, -0.3499,  0.6949,  0.4051,  0.4817,
          0.8196,  0.3161]], device='cuda:0', grad_fn=<EmbeddingBackward>)
collectedtensor([[-2.9296,  0.3303, -0.7340,  0.4409, -0.8052, -0.3568,  0.3922, -0.8174,
         -0.3503, -0.8467]], device='cuda:0', grad_fn=<EmbeddingBackward>)
followedtensor([[ 0.1957, -0.8974, -1.2568, -0.5516,  0.6873, -0.2944, -0.8765,  2.4506,
          0.4430,  0.9735]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Foundationtensor([[-0.4904, -1.2893, -1.0795,  0.0192,  0.5500, -1.7921, -0.0378,  1.3377,
         -1.6332,  0.6197]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Exportingtensor([[-0.7388,  1.5655,  0.6628, -0.2362, -0.2291, -1.9056, -0.7745, -0.5905,
         -1.1317,  1.0865]], device='cuda:0', grad_fn=<EmbeddingBackward>)
later,tensor([[-0.3005, -0.6564, -0.2839,  1.6143, -1.7250, -0.4695,  0.6425,  1.1801,
          1.3018,  0.5029]], device='cuda:0', grad_fn=<EmbeddingBackward>)
recenttensor([[-0.1432,  0.0822,  0.4981, -1.1781,  0.4405, -0.5917,  1.3907, -1.1778,
          0.4032, -1.9665]], device='cuda:0', grad_fn=<EmbeddingBackward>)
reopenedtensor([[-0.2127, -0.0658, -0.1426, -0.5799,  0.5415,  0.7891,  1.2527,  0.5462,
         -1.3562,  1.6290]], device='cuda:0', grad_fn=<EmbeddingBackward>)
undercuttensor([[-2.3417,  0.5926,  0.1319, -0.6235,  0.1566, -0.9041, -0.1599, -1.6504,
         -0.3810, -0.4860]], device='cuda:0', grad_fn=<EmbeddingBackward>)
future,"tensor([[-1.5087,  0.4771, -0.5249,  1.2706,  2.3299, -0.1153, -0.2292, -2.2115,
          1.3953, -0.2033]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Record,tensor([[ 0.6437, -1.0338,  2.2658, -0.8854, -0.6349,  0.3254,  0.8678, -1.5181,
         -1.1059, -0.5376]], device='cuda:0', grad_fn=<EmbeddingBackward>)
feelstensor([[ 1.4264,  0.5150,  1.0021, -0.5930,  1.4990, -0.5644, -1.2467,  0.6105,
         -1.1012, -0.4645]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Shetensor([[-0.0612, -0.4233,  2.7161,  0.0914, -1.3157,  0.6283,  0.5714, -1.2234,
         -1.5316,  0.5879]], device='cuda:0', grad_fn=<EmbeddingBackward>)
against.tensor([[-1.3261, -0.3138, -0.5785,  0.2633,  1.0934, -0.9274,  0.0298, -0.1599,
          0.2954, -0.1197]], device='cuda:0', grad_fn=<EmbeddingBackward>)
are,"tensor([[ 2.7707, -1.3477, -0.6709, -0.0188,  0.7324, -0.7799, -1.0206, -1.4722,
          0.3857,  0.8812]], device='cuda:0', grad_fn=<EmbeddingBackward>)
totaltensor([[-1.7261, -0.2170, -1.8661, -0.5296,  0.7018, -0.5968,  0.9174, -1.7045,
         -0.0827,  0.3209]], device='cuda:0', grad_fn=<EmbeddingBackward>)
warmtensor([[ 0.2773,  1.3615, -2.4416, -0.5370,  0.3121,  0.9347,  1.0864, -0.3760,
         -0.9015,  0.7185]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Marijatensor([[-0.3455, -2.8377,  0.0244, -0.3377,  0.5725, -1.4709,  1.6276, -0.1339,
         -0.0041, -0.1657]], device='cuda:0', grad_fn=<EmbeddingBackward>)
(dpa)tensor([[-0.5197,  0.1903, -0.9227,  1.0842,  0.5456,  0.2962,  0.2021,  1.1629,
         -0.8570,  1.5638]], device='cuda:0', grad_fn=<EmbeddingBackward>)
ministry'stensor([[-0.2705,  0.9287, -0.5380, -2.7935,  0.1506, -0.4839,  1.5110, -0.3245,
         -2.0068,  1.3483]], device='cuda:0', grad_fn=<EmbeddingBackward>)
oldtensor([[ 0.4446,  1.5663, -0.8051,  1.7910, -0.9772, -0.2610, -2.2895, -1.2683,
          1.7879,  0.4546]], device='cuda:0', grad_fn=<EmbeddingBackward>)
(Hosöktensor([[-1.5969,  0.1116, -0.1105,  1.2161,  0.5519, -0.6155, -0.8877,  0.0099,
          0.2328,  1.0540]], device='cuda:0', grad_fn=<EmbeddingBackward>)
coordinatortensor([[-0.5844,  0.1337, -1.1640,  1.9536,  0.2584,  0.0124,  2.1023,  3.0775,
          0.5925, -0.7064]], device='cuda:0', grad_fn=<EmbeddingBackward>)
votingtensor([[ 0.0164, -0.2135, -0.9241, -0.0772, -0.7461,  1.5886, -1.2978,  1.3247,
          0.5838,  0.3334]], device='cuda:0', grad_fn=<EmbeddingBackward>)
extremists.tensor([[-0.0419,  0.5357, -0.7391, -1.9198,  0.1319,  1.4409, -1.1635, -1.2198,
         -0.0425,  0.2708]], device='cuda:0', grad_fn=<EmbeddingBackward>)
people,tensor([[-0.9565, -1.4050, -0.0387,  0.4033, -0.7241,  0.9252, -0.0538,  0.8508,
         -0.9300, -0.7632]], device='cuda:0', grad_fn=<EmbeddingBackward>)
strengtheningtensor([[-0.5280,  0.3790,  0.1600, -0.2187, -2.4553,  0.4369, -1.2147, -2.4931,
          1.1221,  0.9591]], device='cuda:0', grad_fn=<EmbeddingBackward>)
minetensor([[-1.4685,  0.4850,  0.6101,  1.4239, -0.7862,  0.2306,  1.5224,  0.6077,
          0.0503, -1.3803]], device='cuda:0', grad_fn=<EmbeddingBackward>)
goalietensor([[-2.1004,  0.0278,  0.8458, -1.0418,  0.1764, -1.3307, -0.6173, -1.1508,
          0.8747,  1.1807]], device='cuda:0', grad_fn=<EmbeddingBackward>)
efficient.tensor([[-2.1075, -0.8051, -0.1524, -0.8334,  0.5375, -0.9903, -0.3445,  1.4898,
          0.3455,  0.7949]], device='cuda:0', grad_fn=<EmbeddingBackward>)
versiontensor([[ 0.1579, -0.2036,  0.4154,  0.4082, -0.1064, -0.1606,  0.0374, -0.5612,
          0.8713, -0.2873]], device='cuda:0', grad_fn=<EmbeddingBackward>)
fastertensor([[ 0.0107, -0.8329,  1.2812, -0.7093, -0.3107,  0.2707,  0.1274, -0.3021,
         -1.8384,  1.4346]], device='cuda:0', grad_fn=<EmbeddingBackward>)
warnedtensor([[-0.8405,  0.7281,  1.0871,  1.6612,  0.9311,  2.1421,  1.0865, -0.4855,
          2.3680,  1.4503]], device='cuda:0', grad_fn=<EmbeddingBackward>)
that'stensor([[-0.3157, -0.3403, -0.1771,  0.5299, -0.1164,  0.8276, -0.4687, -1.6099,
          0.8044,  0.5826]], device='cuda:0', grad_fn=<EmbeddingBackward>)
brand.tensor([[ 0.2896, -2.2488,  2.2330,  0.7811,  0.2542, -3.1762, -0.2691, -1.4117,
         -0.5162, -0.5666]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Europe.tensor([[-0.8002, -0.6640,  1.2449, -0.5521, -1.8196, -0.8703,  1.0415, -0.4504,
         -1.8227,  0.4475]], device='cuda:0', grad_fn=<EmbeddingBackward>)
tradetensor([[-0.5410, -1.4514, -0.2363,  0.0269,  0.0804,  1.2292,  0.6434, -0.7893,
          1.0546, -0.7019]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Service.tensor([[-0.5426, -0.5834,  0.9080,  1.5384,  0.5866, -1.4790, -1.2267,  1.4902,
         -1.2287,  0.7259]], device='cuda:0', grad_fn=<EmbeddingBackward>)
sovereigntytensor([[-1.4167,  1.1294,  0.6278,  0.3686, -2.2435,  1.1074,  2.1723,  0.3886,
          0.5300, -1.2474]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Augulistensor([[-0.1834, -0.8198,  1.4180,  0.6414, -0.5440, -0.5145, -0.0587,  0.7587,
          0.6795,  1.1842]], device='cuda:0', grad_fn=<EmbeddingBackward>)
resolvetensor([[-0.9167,  0.3473,  0.2232, -0.4043,  0.0038,  0.9655,  0.3108, -2.2725,
         -2.6973,  0.4182]], device='cuda:0', grad_fn=<EmbeddingBackward>)
unchanged.tensor([[-0.9537, -0.1200, -2.8217, -1.2882,  0.0108,  0.3530, -0.0196, -0.5590,
         -0.4675,  1.2335]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Kim,tensor([[-0.2370,  0.5236,  2.1762, -0.3692, -1.2240, -1.0085, -1.2287, -0.1022,
          0.6654,  0.1143]], device='cuda:0', grad_fn=<EmbeddingBackward>)
contradictiontensor([[-0.8454,  1.1320,  0.8092,  1.6479, -0.2371, -0.7268,  1.1333, -0.3915,
          0.3781, -0.8066]], device='cuda:0', grad_fn=<EmbeddingBackward>)
plantensor([[ 0.7038,  0.1728, -1.3518,  1.0754, -2.7984,  1.2323,  0.4468,  0.9039,
          0.6246,  0.4620]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Switzerland'stensor([[ 0.6861, -0.8657,  2.9675, -0.0062,  0.8304, -2.1433,  0.7704, -0.6775,
         -0.5963, -0.2535]], device='cuda:0', grad_fn=<EmbeddingBackward>)
soldierstensor([[ 1.5967, -0.8530,  1.6244, -0.5779,  0.1820,  0.3559,  0.1986,  0.0401,
          1.6259, -0.2459]], device='cuda:0', grad_fn=<EmbeddingBackward>)
off,tensor([[-0.3418, -0.2346,  1.5953, -0.9541,  0.9137, -0.0687,  0.1157, -0.6782,
          0.0206, -0.2991]], device='cuda:0', grad_fn=<EmbeddingBackward>)
2016,tensor([[ 0.7926,  1.4341,  0.1559, -1.5840, -0.6187, -0.8356, -0.2864, -0.3546,
          0.0546,  0.0441]], device='cuda:0', grad_fn=<EmbeddingBackward>)
accidentallytensor([[ 0.3227, -1.9288, -1.0417, -0.8687, -0.2638,  0.6940,  1.4489,  0.4234,
         -0.2995, -1.3645]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Michaeltensor([[-1.0590, -0.5110, -0.1028,  0.1304, -0.8638, -1.8650, -2.4642,  0.6364,
         -0.4825,  0.9311]], device='cuda:0', grad_fn=<EmbeddingBackward>)
politicaltensor([[-1.4926, -1.1312,  0.8140,  0.5398,  1.4450, -0.6132, -0.4547, -0.3490,
          0.4643,  0.0470]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Twenty-twotensor([[ 0.2918,  1.1498, -0.7466, -2.1465, -0.0928, -0.7262, -2.3549,  1.4457,
         -0.1763, -0.0803]], device='cuda:0', grad_fn=<EmbeddingBackward>)
622,tensor([[-0.7739,  1.4630,  1.3285, -1.5123, -0.5848,  0.7179, -0.3253, -0.1406,
          0.7209,  0.5485]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Europe,tensor([[-1.1442, -1.3805,  0.1856,  1.2366,  0.2768, -0.2774,  1.4965, -0.1224,
          1.7386, -0.0403]], device='cuda:0', grad_fn=<EmbeddingBackward>)
solelytensor([[-0.9969,  1.3724, -1.6880,  1.1482,  1.8095, -1.0195,  0.5235,  1.5608,
          0.3462, -0.9655]], device='cuda:0', grad_fn=<EmbeddingBackward>)
boardtensor([[-1.0265,  0.0046, -0.1288, -0.2058, -1.3496,  1.1403,  1.7660, -0.0567,
          0.2626, -0.0100]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Radiotensor([[ 2.2591, -0.7814,  0.2346, -2.2319, -0.2127,  0.8114, -0.7007,  0.6760,
          0.3446, -2.1189]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Policytensor([[ 0.1252,  1.8207,  1.1314,  0.0456, -0.6207, -1.3396,  0.0167, -0.0735,
         -1.9279,  0.9729]], device='cuda:0', grad_fn=<EmbeddingBackward>)
shouldtensor([[ 1.0870,  0.2945,  1.4975,  1.2493, -1.0130, -1.0008, -1.4312,  0.3392,
          0.3560, -1.5120]], device='cuda:0', grad_fn=<EmbeddingBackward>)
citizenstensor([[-1.3219,  0.0923, -0.7024,  0.5321, -0.0952, -0.7709, -1.2358,  1.6246,
         -1.2514, -0.2063]], device='cuda:0', grad_fn=<EmbeddingBackward>)
governmenttensor([[ 0.5620, -1.2995, -1.2787,  0.5065,  2.0411, -1.4676, -0.5383,  0.7046,
         -0.0925,  0.7753]], device='cuda:0', grad_fn=<EmbeddingBackward>)
downtensor([[-1.6254, -1.1509,  1.2430,  0.6999, -0.3933, -1.9403,  0.6389,  0.0794,
         -0.8166, -1.9687]], device='cuda:0', grad_fn=<EmbeddingBackward>)
billiontensor([[-0.3814,  0.6935,  0.0262,  0.1759, -0.3143, -0.4139,  0.4487, -0.1100,
         -1.5844, -1.0028]], device='cuda:0', grad_fn=<EmbeddingBackward>)
citizens'tensor([[-0.5795, -2.5383,  1.9798,  0.0513,  0.7233, -0.1699, -0.4044,  1.0425,
         -1.6551, -1.3343]], device='cuda:0', grad_fn=<EmbeddingBackward>)
that"wetensor([[ 0.6599,  0.0776, -1.5949,  0.2100, -1.1389, -1.8395, -1.9940, -0.1749,
          0.4839,  0.8721]], device='cuda:0', grad_fn=<EmbeddingBackward>)
implementtensor([[-0.3452, -1.3064,  1.4535, -0.6452, -0.5726, -0.3095,  0.7762, -1.9467,
          1.8754, -2.1216]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Nationalitytensor([[ 5.9052e-01, -1.9264e+00, -1.7898e-01, -2.3284e-01,  2.7285e+00,
         -3.6168e-01,  1.7744e+00, -1.7539e-03, -2.4326e-01, -2.0350e-01]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
origin.tensor([[ 0.4118, -0.1637,  0.1298, -0.6552,  1.3615, -1.3041,  0.5037, -0.5528,
          0.8020,  1.2347]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Irantensor([[-0.1514,  0.8525, -0.9970, -0.0949,  1.6790, -0.3615, -1.9624,  1.3274,
          0.2234, -0.7207]], device='cuda:0', grad_fn=<EmbeddingBackward>)
beforetensor([[-0.4947,  0.0279, -0.1355, -0.7080, -1.5012,  1.0066, -0.3354, -1.4475,
          1.3414,  0.3143]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Prudeltensor([[-1.1406,  1.3537, -0.4580, -1.4730,  1.3652,  1.4006, -0.3262, -0.1249,
         -0.2698, -1.6194]], device='cuda:0', grad_fn=<EmbeddingBackward>)
organizations.tensor([[-0.5863, -1.1555, -1.0802, -0.3681, -1.1813,  1.2258,  0.6687, -0.4772,
          1.3002, -0.7961]], device='cuda:0', grad_fn=<EmbeddingBackward>)
undertensor([[ 0.0939, -1.7622,  0.3227, -0.6286,  0.2802, -1.1462, -1.5180, -0.1627,
         -0.2036, -0.2232]], device='cuda:0', grad_fn=<EmbeddingBackward>)
August.tensor([[ 0.4756, -1.1893,  1.3450, -1.0392, -0.2865, -0.1151,  0.3815,  0.1117,
          1.6773, -2.6353]], device='cuda:0', grad_fn=<EmbeddingBackward>)
muchtensor([[ 0.9840,  0.0205, -1.8018, -0.3888,  1.6964,  0.1628, -0.2669,  1.0088,
          0.0786,  0.4165]], device='cuda:0', grad_fn=<EmbeddingBackward>)
countriestensor([[-0.1426, -0.8610,  0.1749,  0.6218,  0.4025,  1.4345,  1.2404, -0.0699,
          0.5599, -0.7023]], device='cuda:0', grad_fn=<EmbeddingBackward>)
conditionstensor([[ 0.2768, -0.5112, -1.6681, -0.3323,  1.1959,  0.4801,  0.9621,  1.7961,
         -1.3073,  0.9746]], device='cuda:0', grad_fn=<EmbeddingBackward>)
growthtensor([[ 0.9750,  0.7127, -1.2595,  0.2137, -1.0123,  0.5409,  0.5698,  0.9882,
          1.5399, -0.4721]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Dainiustensor([[-0.6482,  0.4346, -0.1887,  0.0377, -0.7548,  0.2863, -1.8780,  1.1632,
         -1.9555,  0.6086]], device='cuda:0', grad_fn=<EmbeddingBackward>)
fixtensor([[ 1.1994,  0.5690,  0.0193,  0.7891, -1.4936, -0.8226, -0.0595,  0.0709,
         -0.0376,  0.9723]], device='cuda:0', grad_fn=<EmbeddingBackward>)
spenttensor([[ 5.3646e-04, -1.8968e-01,  5.3326e-01,  2.9083e-01, -5.9885e-01,
          8.3738e-01, -1.7170e+00, -2.2412e+00, -5.6935e-01, -1.3428e+00]],
       device='cuda:0', grad_fn=<EmbeddingBackward>)
property,tensor([[ 0.1033,  0.3601, -2.1008,  0.0234, -0.5329, -0.2604, -0.1439,  1.4112,
          0.6721,  0.4344]], device='cuda:0', grad_fn=<EmbeddingBackward>)
provetensor([[-0.4468, -0.3754,  0.2197,  0.6209, -1.5835, -0.5792, -1.2780, -0.8844,
         -0.9998,  1.4293]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Organizationtensor([[ 1.0739, -0.7299, -1.5161, -0.3745, -0.0297,  1.1664,  0.0493, -1.1855,
         -1.8753,  0.2578]], device='cuda:0', grad_fn=<EmbeddingBackward>)
headtensor([[-0.2469, -0.1574, -1.6028,  0.2634,  0.1787,  0.5049, -1.0204, -0.1314,
          0.2187, -1.4244]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Russia,tensor([[-2.2215, -1.1199,  0.5145,  0.1016, -0.3564, -0.3044, -0.1839, -0.8697,
          1.7269, -0.1798]], device='cuda:0', grad_fn=<EmbeddingBackward>)
moment,tensor([[-0.0503,  1.2058,  1.3750, -1.5814, -0.5229,  0.6033,  0.4684,  0.0087,
          1.2810,  1.2380]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Funderfuntensor([[-1.3863, -1.9428,  1.2803, -0.5594, -0.5777, -0.7193, -0.3923, -1.0308,
          0.1752,  0.0841]], device='cuda:0', grad_fn=<EmbeddingBackward>)
namestensor([[-0.9400,  0.8391,  0.8460, -0.3193, -0.4446,  1.4778, -0.4978, -1.2418,
         -0.5463, -0.9195]], device='cuda:0', grad_fn=<EmbeddingBackward>)
previouslytensor([[-0.3998, -1.1514,  0.1605, -0.6438,  0.0348,  0.6262, -0.1628,  0.5201,
          0.3328,  0.6329]], device='cuda:0', grad_fn=<EmbeddingBackward>)
todaytensor([[ 0.0290,  1.1068, -1.1921, -0.7510, -0.9722,  0.8923,  1.2224,  1.2777,
          0.1370,  1.7006]], device='cuda:0', grad_fn=<EmbeddingBackward>)
possibletensor([[ 0.4877,  0.2891, -1.0847, -1.6555,  0.3104, -0.4870, -1.7538, -0.3762,
         -1.9144,  0.3118]], device='cuda:0', grad_fn=<EmbeddingBackward>)
eurozonetensor([[-0.5717, -1.0151,  1.9525, -1.0440, -1.2115, -0.2354,  0.9758, -0.8608,
          0.1201, -0.7636]], device='cuda:0', grad_fn=<EmbeddingBackward>)
disastrous,tensor([[ 0.3614, -0.3905,  0.7849,  0.3833,  0.2479,  0.9665, -0.8604, -0.0299,
          0.2397,  0.5739]], device='cuda:0', grad_fn=<EmbeddingBackward>)
supervisorytensor([[ 0.4008, -1.2781, -0.5192, -0.0510, -0.2973,  1.8523, -0.5013, -1.5987,
         -1.4901,  0.0996]], device='cuda:0', grad_fn=<EmbeddingBackward>)
abletensor([[ 0.2240, -1.5661, -2.6708, -0.7027,  1.4864,  0.3670,  2.0357, -0.0359,
         -0.1900, -0.9803]], device='cuda:0', grad_fn=<EmbeddingBackward>)
amounttensor([[-1.6953, -0.7088, -0.1900,  1.0881, -2.7757,  1.1150, -1.8712, -0.0379,
          0.2301, -0.1328]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Squaretensor([[-1.2762,  0.0893,  0.0359,  0.6674,  1.4476,  0.3489,  0.8271,  0.8567,
          1.0585,  0.7933]], device='cuda:0', grad_fn=<EmbeddingBackward>)
normstensor([[-0.1328,  0.9965, -2.3205,  1.8358, -1.2645, -0.4583,  1.0025, -0.0755,
         -0.3571, -0.5190]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Eiropastensor([[ 0.1305, -1.7222, -0.4618, -0.6933,  0.1840,  0.5865, -0.8057, -0.2927,
         -0.3857, -1.5296]], device='cuda:0', grad_fn=<EmbeddingBackward>)
iftensor([[ 0.2512,  0.7540,  1.7955, -1.0268,  0.1054,  0.1074,  0.0372,  0.9131,
         -0.0040,  0.8009]], device='cuda:0', grad_fn=<EmbeddingBackward>)
temperaturestensor([[-0.0086,  0.0908,  0.0120,  0.3360,  0.3685,  0.3540, -0.2202,  0.1809,
          1.1026,  1.2107]], device='cuda:0', grad_fn=<EmbeddingBackward>)
tightentensor([[ 0.8704,  2.1449, -0.1151, -0.7408,  0.2911, -0.6055,  0.4926,  0.5573,
          0.0818, -0.0331]], device='cuda:0', grad_fn=<EmbeddingBackward>)
acceleratortensor([[-0.7941, -0.4340,  1.2598, -1.5762,  0.3055,  0.8268,  1.5026,  0.6850,
         -0.9870, -0.1863]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Authoritiestensor([[-0.3895, -1.1316, -0.7954,  0.7939, -1.3760,  1.2299, -0.7643,  1.3229,
         -1.0636,  0.7764]], device='cuda:0', grad_fn=<EmbeddingBackward>)
public.tensor([[ 1.7284, -1.6998,  1.0173,  0.8362, -1.7708, -0.5280,  1.2234, -0.5091,
         -0.1439, -0.9174]], device='cuda:0', grad_fn=<EmbeddingBackward>)
railwaytensor([[-2.2582, -0.0227, -0.3929,  0.0145, -1.4287, -1.6929,  1.0933,  0.5307,
          0.9341,  0.6144]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Marijustensor([[ 1.5506,  0.5912, -0.9593, -1.1453,  0.7131, -0.8819, -2.4637, -1.0201,
          1.3650,  0.2506]], device='cuda:0', grad_fn=<EmbeddingBackward>)
leadstensor([[ 0.2247,  0.8075,  0.6733, -0.1282,  0.8810, -0.5903, -0.6355,  0.1742,
         -1.0571,  1.3511]], device='cuda:0', grad_fn=<EmbeddingBackward>)
SkenarioLabtensor([[-0.5362,  0.0844,  1.0864,  2.1098, -1.1740, -0.7326,  0.4515,  0.2290,
         -0.5038,  0.2458]], device='cuda:0', grad_fn=<EmbeddingBackward>)
connectionstensor([[-0.2715, -1.1627, -1.0916,  0.1884, -0.8914, -1.6568, -0.7509, -0.9693,
          0.9044, -1.4178]], device='cuda:0', grad_fn=<EmbeddingBackward>)
relations.tensor([[-1.3719, -0.0195, -0.6288,  0.6021, -0.9875,  0.2262,  1.2604,  0.4837,
         -0.2637,  2.0031]], device='cuda:0', grad_fn=<EmbeddingBackward>)
zerotensor([[-0.1961,  1.1776, -1.8122, -0.0583, -0.2707, -0.6396, -0.8131,  0.8538,
          1.1149,  0.8285]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Kindercatering,tensor([[-0.4483, -1.2179,  0.2574, -0.4878, -0.8164, -0.4878, -0.4297, -0.0722,
         -0.1704, -1.0984]], device='cuda:0', grad_fn=<EmbeddingBackward>)
wanttensor([[ 1.6346, -0.8768,  1.3459, -0.1183, -0.0461,  0.2779,  1.5634,  0.4063,
          0.0406, -1.6175]], device='cuda:0', grad_fn=<EmbeddingBackward>)
procurements.tensor([[-0.0424,  1.2814, -0.2194,  1.6386,  0.6631,  1.1804,  0.1043, -1.6247,
         -0.7272, -0.1268]], device='cuda:0', grad_fn=<EmbeddingBackward>)
signedtensor([[ 0.6946,  0.2180, -0.4099, -0.9189, -1.4344, -1.4193,  0.2833, -0.2829,
         -1.0656,  0.2707]], device='cuda:0', grad_fn=<EmbeddingBackward>)
regardingtensor([[-0.4139,  0.4777, -0.0700,  0.6942,  0.0915, -0.6413,  1.8214,  1.4695,
          0.8395,  0.8338]], device='cuda:0', grad_fn=<EmbeddingBackward>)
regimetensor([[-0.4731,  0.2229, -1.7988,  0.1052,  1.2775, -0.6673, -0.4523,  0.1905,
         -0.1642,  0.0554]], device='cuda:0', grad_fn=<EmbeddingBackward>)
milk,tensor([[ 1.1553,  2.1691,  0.5884, -0.2629,  1.1546,  0.6610,  0.3088,  1.1614,
         -1.4138,  0.4624]], device='cuda:0', grad_fn=<EmbeddingBackward>)
deliberationtensor([[ 0.7298,  1.4728,  1.6314,  0.8243,  0.4172,  0.6387,  0.8011, -0.2177,
         -1.4094, -0.2817]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Lithuaniatensor([[ 1.0054, -1.2336,  0.4405,  0.1066,  0.3526, -0.6685, -0.2510, -0.8258,
          0.3130, -0.1279]], device='cuda:0', grad_fn=<EmbeddingBackward>)
company'stensor([[-0.6953,  0.1539,  1.5795,  1.0189, -0.3020, -1.4061, -1.0091, -0.8144,
         -0.6498, -0.8416]], device='cuda:0', grad_fn=<EmbeddingBackward>)
economy,"tensor([[ 1.1715,  0.4177,  0.4489, -0.7515,  1.4445,  0.2464,  2.7412,  0.5532,
         -0.8522,  0.3070]], device='cuda:0', grad_fn=<EmbeddingBackward>)
him,"tensor([[-0.3639, -1.3400,  0.1643, -1.8856,  0.5802,  1.0109, -1.7024,  1.1890,
         -0.1064, -1.0369]], device='cuda:0', grad_fn=<EmbeddingBackward>)
301tensor([[-1.8539, -1.0752,  0.5047,  0.3236, -1.0698,  0.3469,  1.1404,  0.7536,
         -0.5679,  0.8884]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Mosultensor([[-0.1594,  0.2532,  1.0975, -0.2044, -0.8213, -1.8922,  0.2004,  1.6647,
         -1.0833,  0.7026]], device='cuda:0', grad_fn=<EmbeddingBackward>)
agreement,"tensor([[ 0.5278,  2.3643, -0.5956, -0.1678, -0.5250,  0.0770, -0.7737,  0.0115,
          0.7038,  0.1560]], device='cuda:0', grad_fn=<EmbeddingBackward>)
budgetstensor([[-0.3974, -1.0740, -1.2450,  0.1604, -0.4290,  1.6800,  0.2052,  0.4632,
         -1.0103,  0.2128]], device='cuda:0', grad_fn=<EmbeddingBackward>)
officialtensor([[-0.5241, -0.8607, -1.9731,  0.0292,  1.0580, -0.2590, -0.8835,  0.6549,
         -1.3237, -0.5351]], device='cuda:0', grad_fn=<EmbeddingBackward>)
cuttensor([[ 0.0612, -0.6021, -0.5932,  0.7835,  0.6135,  0.1218,  0.5753,  0.6605,
          0.8096,  0.5110]], device='cuda:0', grad_fn=<EmbeddingBackward>)
acceptedtensor([[ 0.8548,  0.1045,  1.4075,  0.1958, -0.6567,  0.5091, -1.1342,  0.7871,
          0.5592, -1.0572]], device='cuda:0', grad_fn=<EmbeddingBackward>)
wastensor([[-0.0920,  0.5300, -1.1186, -0.1318,  0.0115,  0.4535, -1.4894,  0.9765,
          0.1395,  2.0356]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Bankatensor([[ 1.1354,  1.2046,  1.5893, -0.1712, -1.3965, -0.6546, -0.4547,  0.4673,
         -1.2283, -1.3196]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Ronaldstensor([[-0.6758,  0.9692,  0.4925, -0.5599, -0.7956,  0.1597,  1.1214,  1.8896,
          0.5558, -1.6453]], device='cuda:0', grad_fn=<EmbeddingBackward>)
servedtensor([[-0.0888,  2.5613, -1.2025, -0.6846,  2.0211, -0.3378, -1.0045, -0.1912,
         -1.2455,  0.1949]], device='cuda:0', grad_fn=<EmbeddingBackward>)
time,tensor([[ 0.3503, -0.4319,  0.2234,  1.6211,  2.8050,  0.6141,  0.9330, -1.0765,
          0.2837,  0.0306]], device='cuda:0', grad_fn=<EmbeddingBackward>)
percent)tensor([[-0.3806, -0.0519, -1.2168,  2.2754, -0.7235,  0.9109,  1.7946, -0.1401,
          2.5036, -0.1561]], device='cuda:0', grad_fn=<EmbeddingBackward>)
32tensor([[-1.2694,  0.7172,  1.4509,  0.6959, -0.6232, -0.9208,  1.4057,  0.9964,
         -1.2210, -0.9823]], device='cuda:0', grad_fn=<EmbeddingBackward>)
proposalstensor([[-0.6769,  2.4627,  1.1883,  0.7864,  0.2829,  1.7105, -0.7555, -1.7400,
          0.1612,  1.0863]], device='cuda:0', grad_fn=<EmbeddingBackward>)
paymenttensor([[-0.0865, -0.9664, -1.9881,  1.4422,  0.6260, -1.7030,  0.2234,  1.0306,
         -1.7559,  0.0317]], device='cuda:0', grad_fn=<EmbeddingBackward>)
spokeswomantensor([[-0.7811, -0.4851,  1.6193, -1.0983,  0.0048, -1.7699, -2.5605,  0.8332,
          1.1460, -0.2928]], device='cuda:0', grad_fn=<EmbeddingBackward>)
remainedtensor([[ 1.1220,  0.6923, -0.3818, -0.9716,  0.0431,  0.1980, -0.3827,  0.0839,
          0.7085, -0.4332]], device='cuda:0', grad_fn=<EmbeddingBackward>)
electricity.tensor([[-1.3764,  0.4017,  0.3442, -1.0140, -0.6065,  0.2856,  0.3172,  0.1665,
          0.2689, -0.0265]], device='cuda:0', grad_fn=<EmbeddingBackward>)
modeltensor([[-0.4630,  0.6709,  2.0046, -0.5250,  0.6780, -1.3508,  0.3943,  1.1747,
         -2.3303,  0.9231]], device='cuda:0', grad_fn=<EmbeddingBackward>)
debttensor([[-1.1197, -0.3979,  1.3692, -1.1597, -1.7699,  0.2352, -1.9007,  1.1422,
          0.7024, -0.5073]], device='cuda:0', grad_fn=<EmbeddingBackward>)
law,"tensor([[-1.7279, -0.7280,  0.7080,  0.5544,  0.1890,  0.2881, -0.6135,  0.2317,
          1.5709,  1.1393]], device='cuda:0', grad_fn=<EmbeddingBackward>)
NATO’stensor([[-0.2317, -0.8569,  1.7380, -0.4945, -0.1051,  1.2239, -2.6426,  0.1874,
          1.0663,  0.3672]], device='cuda:0', grad_fn=<EmbeddingBackward>)
pacetensor([[-0.2275,  1.1761,  1.4107,  0.9432,  0.5970,  0.4561,  0.5278,  1.0768,
          1.3408,  0.4870]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"Latvian".tensor([[ 0.2194, -3.0493,  0.8110,  0.0945, -0.6101,  0.1513,  0.1380, -0.5902,
         -0.6116, -1.1819]], device='cuda:0', grad_fn=<EmbeddingBackward>)
states,tensor([[ 0.3434,  1.0342, -0.2342, -0.3431,  1.4781,  0.8270,  0.0151, -1.3062,
         -0.7283, -1.2780]], device='cuda:0', grad_fn=<EmbeddingBackward>)
Overtensor([[ 0.8989, -0.9648, -2.1518,  0.3027,  1.0996, -0.8424, -0.2513,  0.5360,
         -0.8293,  1.5400]], device='cuda:0', grad_fn=<EmbeddingBackward>)
providedtensor([[-0.3547, -0.4184, -0.2357, -1.6942,  0.2940,  0.0350,  0.8618,  0.0017,
         -0.5455,  0.2872]], device='cuda:0', grad_fn=<EmbeddingBackward>)
notchestensor([[ 2.4852,  2.0046, -0.7296,  1.0542,  0.8488,  1.1047,  0.1826,  0.4899,
         -1.2254, -0.3779]], device='cuda:0', grad_fn=<EmbeddingBackward>)
cabletensor([[-1.5127,  0.4857, -0.3613, -0.2651,  0.3511,  0.0755, -0.9495, -0.7553,
         -0.5973,  0.9055]], device='cuda:0', grad_fn=<EmbeddingBackward>)
pharmaceuticals,tensor([[ 0.2134,  0.1858,  0.4674, -0.9803,  0.4170, -0.6226, -0.9938,  0.4151,
         -0.7204,  0.9689]], device='cuda:0', grad_fn=<EmbeddingBackward>)
againsttensor([[-0.8359, -0.2889,  0.4774,  0.2863,  2.2486, -0.8350, -0.3062,  1.3891,
          0.3690, -2.2203]], device='cuda:0', grad_fn=<EmbeddingBackward>)
500,000tensor([[-1.0608, -0.6693,  0.3067,  0.1513, -2.1264,  0.8917,  1.0874, -0.3763,
         -0.8388, -1.0124]], device='cuda:0', grad_fn=<EmbeddingBackward>)
rantensor([[-0.7912, -0.4009,  1.7936,  1.2702, -0.4857,  0.1373, -0.3793, -0.0896,
          0.4200,  0.4612]], device='cuda:0', grad_fn=<EmbeddingBackward>)
"Nearlytensor([[-2.2177, -1.5844,  0.7694,  0.6307,  0.1940, -2.1708, -0.1031, -0.7351,
          1.2926, -0.7989]], device='cuda:0', grad_fn=<EmbeddingBackward>)
transatlantictensor([[-0.6128, -0.0193, -0.7505,  1.0155,  0.5126,  0.8005,  0.7663, -0.9025,
         -0.9095,  0.4857]], device='cuda:0', grad_fn=<EmbeddingBackward>)
day,tensor([[-0.5770,  0.8220, -0.2045, -0.8468, -0.1695,  0.6077, -0.2182, -1.3839,
         -0.5772, -0.4245]], device='cuda:0', grad_fn=<EmbeddingBackward>)
programtensor([[-0.8254,  1.8446, -0.5164, -0.2657,  0.2935, -0.4267, -2.7521, -0.9892,
         -0.3566, -1.1817]], device='cuda:0', grad_fn=<EmbeddingBackward>)
adequatetensor([[ 3.1427, -1.1159,  1.2172,  0.4961,  0.8400, -0.9199, -1.7153, -1.2899,
          0.3331,  0.2570]], device='cuda:0', grad_fn=<EmbeddingBackward>)
latesttensor([[-0.5768,  1.7837,  1.3221,  0.9327, -0.6505, -0.0091, -0.9213,  0.0603,
          0.2173, -1.0000]], device='cuda:0', grad_fn=<EmbeddingBackward>)
